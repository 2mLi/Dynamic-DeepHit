# first, fit a model with selected_var
Train_sub <- Train_sub[, c(selected_var, "Status", "Times")]
mod <- coxph(Surv(Times, Status) ~ ., data = Train_sub)
proba <- predict(mod, Train_sub, type="risk")
Train_sub$risk <- proba
#选择最优阈值, at this time slice
res_cut <- surv_cutpoint(Train_sub, time = "Times", event = "Status",variables = c("risk"))
cutoff <- res_cut$risk$estimate
thr_step_3[[i]] <- cutoff
# find c-index, which is hidden in mod
c_idx_3[[i]] <- summary(mod)$concordance
# finally, the ultimate challenge...
# assign groupings based on cutoff, then loop back
group_name <- paste("Group", i, sep = "")
Train_sub[, group_name]<- ifelse(Train_sub$risk >= cutoff, "High", "Low")
}
}
}
c_idx_3
qnorm(0.70)
0.8182 - 0.6392
0.5714 - 0.3444
54/(54 + 70)
# library(survival)
source("Yat_Sung.R")
library(survminer)
library(survival)
Train <- read.csv("data/precar_Train_WGS_plus.csv", header = T)
Test <- read.csv("data/precar_Test_WGS_plus.csv", header = T)
# Train <- read.csv("data/PBC2_Train_rnd.csv", header = T)
# Test <- read.csv("data/PBC2_Test_rnd.csv", header = T)
interv <- 6
PBC2_vars <- c("serBilir", "serChol", "albumin",
"alkaline",
"SGOT",
"platelets",
"prothrombin",
"Status",
"Times",
"ID")
PreCar_vars <- c("Age", "Alb", "Plt", "Tb", "Afp", "HIFI",
"Alp", "Alt", "Inr",
"Status",
"Times",
"ID")
Train_s <- data_slicer(Train, interv,
"Time",
"ID",
PreCar_vars
)
Test_s <- data_slicer(Test, interv,
"Time",
"ID",
PreCar_vars
)
# for each time slice ...
time_slice <- seq(from = min(Train$Time), to = max(Train$Time),
by = interv)
selected_predictors_step_1 <- vector(mode = "list", length = 1)
selected_predictors_step_3 <- vector(mode = "list", length = 1)
thr_step_3 <- vector(mode = "list", length = 1)
c_idx_3 <- vector(mode = "list", length = 1)
Grp_1 <- rep(NA, length(unique(Train$Patient)))
for (i in 1:1){
Train_sub <- as.data.frame(Train_s[, i, ])
for (k in 1:ncol(Train_sub)){
Train_sub[, k] <- as.numeric(Train_sub[, k])
}
# adjust for landmark time
Train_sub[, "Times"] <- Train_sub[, "Times"] - time_slice[i]
# apply f_step_1
predictors <- names(Train_sub)
predictors <- predictors[predictors != "mi"]
for (pred in predictors){
Train_sub[, pred] <- as.numeric(Train_sub[, pred])
}
# remove Times, Status and ID
predictors <- predictors[predictors != "Status" & predictors != "ID" & predictors != "Times"]
cat("Step 1: \n")
selected_predictors <- f_step_1(Train_sub,
predictor = predictors,
times = "Times",
status = "Status",
p_thr = 0.5
)
if (length(selected_predictors) > 0){
selected_predictors_step_1[[i]] <- selected_predictors
# proceed to step 2
cat("Step 2: \n")
# next, step 2
# its just a condition: does sample size meet 20 * selected_predictors?
if (nrow(Train_sub[, selected_predictors]) >= 20* length(selected_predictors)){
# proceed to step 3
ID <- Train_sub[, "ID"]
Train_sub <- Train_sub[, c(selected_predictors, "Status", "Times")]
# use a custom function
cat("Step 3: \n")
selected_var <- f_step_3(Train_sub, "Times", "Status")
# this is our final decision for this time slice
selected_predictors_step_3[[i]] <- selected_var
# assuming all above were proceeding as normal, we should find a best threshold here
# first, fit a model with selected_var
Train_sub <- Train_sub[, c(selected_var, "Status", "Times")]
mod <- coxph(Surv(Times, Status) ~ ., data = Train_sub)
proba <- predict(mod, Train_sub, type="risk")
Train_sub$risk <- proba
#选择最优阈值, at this time slice
res_cut <- surv_cutpoint(Train_sub, time = "Times", event = "Status",variables = c("risk"))
cutoff <- res_cut$risk$estimate
thr_step_3[[i]] <- cutoff
# find c-index, which is hidden in mod
c_idx_3[[i]] <- summary(mod)$concordance
# finally, the ultimate challenge...
# assign groupings based on cutoff, then loop back
group_name <- paste("Group", i, sep = "")
Grp_1<- ifelse(Train_sub$risk >= cutoff, 1, 0)
}
}
}
table(Grp1\_1)
table(Grp1)
table(Grp_1)
Grp <- data.frame(ID = unique(Train$ID), Grp1 = NA, Grp2 = NA, Grp3 = NA)
memory.limit()
memory.limit(102400)
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Event) ~ ",x))
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- all_list
dat <- Train_id
UniVar<-lapply(varNames, UniCox)
UniVar<-ldply(UniVar,dat)
library(survival)
library(survminer)
library(survcomp)
library(plyr)
source("my_functions.R", encoding = "UTF-8")
Train <- read.csv("data/precar_Train_WGS_plus.csv")
Test <- read.csv("data/precar_Test_WGS_plus.csv")
# variables used by DDH
bin_list <- c("Gender", "CNV_score")
cont_list <- c("Afp", "Age", "Alt", "Alb", "Plt", "Tb", "Inr", "NF_CT", "Fragment_CT", "motif_CT", "Comb_CT", "score")
all_list <- c(bin_list, cont_list)
log_transform <- c("Afp", "Alt", "Alb", "Plt", "Tb", "Inr", "Comb_CT", "score")
Train <- Train[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
Test <- Test[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
# log-transform
for (var in log_transform){
Train[, var] <- log1(Train[, var], base = 10)
Test[, var] <- log1(Test[, var], base = 10)
}
# to cox data
Train_id <- toSurv(Train, "ID", "Time", "Times")
Test_id <- toSurv(Test, "ID", "Time", "Times")
# fit coxph
# univariate
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Event) ~ ",x))
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- all_list
dat <- Train_id
UniVar<-lapply(varNames, UniCox)
UniVar<-ldply(UniVar,dat)
library(survival)
library(survminer)
library(survcomp)
library(plyr)
source("my_functions.R", encoding = "UTF-8")
Train <- read.csv("data/precar_Train_WGS_plus.csv")
Test <- read.csv("data/precar_Test_WGS_plus.csv")
# variables used by DDH
bin_list <- c("Gender", "CNV_score")
cont_list <- c("Afp", "Age", "Alt", "Alb", "Plt", "Tb", "Inr", "NF_CT", "Fragment_CT", "motif_CT", "Comb_CT", "score")
all_list <- c(bin_list, cont_list)
log_transform <- c("Afp", "Alt", "Alb", "Plt", "Tb", "Inr", "Comb_CT", "score")
Train <- Train[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
Test <- Test[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
# log-transform
for (var in log_transform){
Train[, var] <- log1(Train[, var], base = 10)
Test[, var] <- log1(Test[, var], base = 10)
}
# to cox data
Train_id <- toSurv(Train, "ID", "Time", "Times")
Test_id <- toSurv(Test, "ID", "Time", "Times")
# fit coxph
# univariate
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Event) ~ ",x))
dat <- Train_id
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- all_list
UniVar<-lapply(varNames, UniCox)
UniVar<-ldply(UniVar,dat)
library(survival)
library(survminer)
library(survcomp)
library(plyr)
source("my_functions.R", encoding = "UTF-8")
Train <- read.csv("data/precar_Train_WGS_plus.csv")
Test <- read.csv("data/precar_Test_WGS_plus.csv")
# variables used by DDH
bin_list <- c("Gender", "CNV_score")
cont_list <- c("Afp", "Age", "Alt", "Alb", "Plt", "Tb", "Inr", "NF_CT", "Fragment_CT", "motif_CT", "Comb_CT", "score")
all_list <- c(bin_list, cont_list)
log_transform <- c("Afp", "Alt", "Alb", "Plt", "Tb", "Inr", "Comb_CT", "score")
Train <- Train[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
Test <- Test[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
# log-transform
for (var in log_transform){
Train[, var] <- log1(Train[, var], base = 10)
Test[, var] <- log1(Test[, var], base = 10)
}
# to cox data
Train_id <- toSurv(Train, "ID", "Time", "Times")
Test_id <- toSurv(Test, "ID", "Time", "Times")
# fit coxph
# univariate
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Status) ~ ",x))
dat <- Train_id
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- all_list
UniVar<-lapply(varNames, UniCox)
UniVar<-ldply(UniVar,dat)
library(survival)
library(survminer)
library(survcomp)
library(plyr)
source("my_functions.R", encoding = "UTF-8")
Train <- read.csv("data/precar_Train_WGS_plus.csv")
Test <- read.csv("data/precar_Test_WGS_plus.csv")
# variables used by DDH
bin_list <- c("Gender", "CNV_score")
cont_list <- c("Afp", "Age", "Alt", "Alb", "Plt", "Tb", "Inr", "NF_CT", "Fragment_CT", "motif_CT", "Comb_CT", "score")
all_list <- c(bin_list, cont_list)
log_transform <- c("Afp", "Alt", "Alb", "Plt", "Tb", "Inr", "Comb_CT", "score")
Train <- Train[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
Test <- Test[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
# log-transform
for (var in log_transform){
Train[, var] <- log1(Train[, var], base = 10)
Test[, var] <- log1(Test[, var], base = 10)
}
# to cox data
Train_id <- toSurv(Train, "ID", "Time", "Times")
Test_id <- toSurv(Test, "ID", "Time", "Times")
# fit coxph
# univariate
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Status) ~ ",x))
dat <- Train_id
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- all_list
dat <- Train_id
UniVar<-lapply(varNames, UniCox)
UniVar<-ldply(UniVar,dat)
UniCox("Afp")
lapply(seq(1, 5, 5), cat)
lapply(list(seq(1, 5, 5)), cat)
x <- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE))
# compute the list mean for each list element
lapply(x, mean)
x <- list(a = seq(1, 5, 5))
lapply(x, mean)
library(survival)
library(survminer)
library(survcomp)
library(plyr)
source("my_functions.R", encoding = "UTF-8")
Train <- read.csv("data/precar_Train_WGS_plus.csv")
Test <- read.csv("data/precar_Test_WGS_plus.csv")
# variables used by DDH
bin_list <- c("Gender", "CNV_score")
cont_list <- c("Afp", "Age", "Alt", "Alb", "Plt", "Tb", "Inr", "NF_CT", "Fragment_CT", "motif_CT", "Comb_CT", "score")
all_list <- c(bin_list, cont_list)
log_transform <- c("Afp", "Alt", "Alb", "Plt", "Tb", "Inr", "Comb_CT", "score")
Train <- Train[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
Test <- Test[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
# log-transform
for (var in log_transform){
Train[, var] <- log1(Train[, var], base = 10)
Test[, var] <- log1(Test[, var], base = 10)
}
# to cox data
Train_id <- toSurv(Train, "ID", "Time", "Times")
Test_id <- toSurv(Test, "ID", "Time", "Times")
# fit coxph
# univariate
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Status) ~ ",x))
dat <- Train_id
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- as.list(all_list)
dat <- Train_id
UniVar<-lapply(varNames, UniCox)
UniVar<-ldply(UniVar,dat)
varNames
lapply(list(a = "Afp", b = "Plt"), UniCox)
UniVar<-lapply(varNames, UniCox)
UniVar
UniVar<-ldply(UniVar,dat)
UniVar<-ldply(UniVar,dat)
UniVar[[1]]
UniVar[[1]]$P.value
ldplr(Univar, function(x){return(x$P.value <= 0.05 / length(UniVar))})
ldply(Univar, function(x){return(x$P.value <= 0.05 / length(UniVar))})
ldply(UniVar, function(x){return(x$P.value <= 0.05 / length(UniVar))})
UniVar_res <- ldply(UniVar, function(x){return(x$P.value <= 0.05 / length(UniVar))}) # result of univariate analysis
selected_predictors <- all_list[UniVar_res]
selected_predictors
class(UniVar_res)
class(all_list)
all_list
selected_predictors <- all_list[UniVar_res[, 1]]
selected_predictors
mod <- coxph(Surv(Times, Status) ~ Afp + Age + Alb + Plt + Inr + score,
data = Train_id)
# predict (Train)
tr_risk <- predict(mod, Train_id, type="risk")
Train_id$risk <- tr_risk
#选择最优阈值
res.cut <- surv_cutpoint(Train_id, time = "Time", event = "Status",variables = c("risk"))
cutoff <- res.cut$risk$estimate
Train_id$Group <- ifelse(Train_id$risk >= cutoff,"High","Low")
sum.surv <- summary(mod)
c_index_se <- sum.surv$concordance
c_index <- c_index_se[1]
c_index.ci_low <- c_index - c_index_se[2]
c_index.ci_upp <- c_index + c_index_se[2]
ggsurvplot(mod, # 创建的拟合对象
data = Train_id,  # 指定变量数据来源
conf.int = TRUE, # 显示置信区间
pval = TRUE, # 添加P值
fun = "event",
pval.size = 5,
title = paste0("Derivation Cohort(cutpoint: ",round(cutoff,3),", ","C-index: ",round(c_index,3),")"),
#surv.median.line = "hv",  # 添加中位生存时间线
risk.table = TRUE, # 添加风险表
xlab = "Follow up time(Month)", # 指定x轴标签
ylab = "Cumulative risk of hepatocellular carcinoma",
legend = c(0.15,0.8), # 指定图例位置
legend.title = "aMAP-plus Score", # 设置图例标题，这里设置不显示标题，用空格替代
legend.labs = c("High-risk group", "Low-risk group"), # 指定图例分组标签
break.x.by = 3,
xlim = c(0,36),
#ylim = c(0,0.4)
)  # 设置x轴刻度间距
# whatever, on test set...
te_risk <- predict(mod, Test_id, type="risk")
Test_id$risk <- te_risk
Test_id$Group <- ifelse(Test_id$risk >= cutoff,"High","Low")
idx <- !is.na(te_risk)
c_index_te <- concordance.index(x = te_risk[idx], surv.time = Test_id$Times[idx],
surv.event = Test_id$Status[idx])$c.index
# with baseline data,
c_index
c_index_te
summary(mod)
UniVar
all_list
library(survival)
library(survminer)
library(survcomp)
library(plyr)
source("my_functions.R", encoding = "UTF-8")
Train <- read.csv("data/precar_Train_WGS_plus.csv")
Test <- read.csv("data/precar_Test_WGS_plus.csv")
# variables used by DDH
bin_list <- c("Gender", "CNV_score")
cont_list <- c("Afp", "Age", "Alt", "Alb", "Plt", "Tb", "Inr", "NF_CT", "Fragment_CT", "motif_CT", "Comb_CT", "score")
all_list <- c(bin_list, cont_list)
log_transform <- c("Afp", "Alt", "Alb", "Plt", "Tb", "Inr", "Comb_CT", "score")
Train <- Train[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
Test <- Test[, c(bin_list, cont_list, "Time", "Times", "ID", "Status")]
# log-transform
for (var in log_transform){
Train[, var] <- log1(Train[, var], base = 10)
Test[, var] <- log1(Test[, var], base = 10)
}
# to cox data
Train_id <- toSurv(Train, "ID", "Time", "Times")
Test_id <- toSurv(Test, "ID", "Time", "Times")
# fit coxph
# univariate
UniCox<-function(x){
FML<-as.formula(paste0("Surv(Times, Status) ~ ",x))
dat <- Train_id
Cox<-coxph(FML,data = dat)
Sum<-summary(Cox)
CI<-paste0(round(Sum$conf.int[,3:4],2),collapse = "-")
Pvalue<-round(Sum$coefficients[,5],4)
HR<-round(Sum$coefficients[,2],2)
Unicox<-data.frame("Characteristics"=x,
"Hazard Ratio"=HR,
"CI95"=CI,
"P value"=Pvalue)
return(Unicox)
}
varNames<- as.list(all_list)
dat <- Train_id
UniVar<-lapply(varNames, UniCox)
# extract p values manually
UniVar_res <- ldply(UniVar, function(x){return(x$P.value <= 0.05 / length(UniVar))}) # result of univariate analysis
selected_predictors <- all_list[UniVar_res[, 1]]
selected_predictors
# [1] "Afp"   "Age"   "Alb"   "Plt"   "Inr"   "NF_CT" "score"
# multivariate
mod <- coxph(Surv(Times, Status) ~ Afp + Age + score,
data = Train_id)
# predict (Train)
tr_risk <- predict(mod, Train_id, type="risk")
Train_id$risk <- tr_risk
#选择最优阈值
res.cut <- surv_cutpoint(Train_id, time = "Time", event = "Status",variables = c("risk"))
cutoff <- res.cut$risk$estimate
Train_id$Group <- ifelse(Train_id$risk >= cutoff,"High","Low")
sum.surv <- summary(mod)
c_index_se <- sum.surv$concordance
c_index <- c_index_se[1]
c_index.ci_low <- c_index - c_index_se[2]
c_index.ci_upp <- c_index + c_index_se[2]
ggsurvplot(mod, # 创建的拟合对象
data = Train_id,  # 指定变量数据来源
conf.int = TRUE, # 显示置信区间
pval = TRUE, # 添加P值
fun = "event",
pval.size = 5,
title = paste0("Derivation Cohort(cutpoint: ",round(cutoff,3),", ","C-index: ",round(c_index,3),")"),
#surv.median.line = "hv",  # 添加中位生存时间线
risk.table = TRUE, # 添加风险表
xlab = "Follow up time(Month)", # 指定x轴标签
ylab = "Cumulative risk of hepatocellular carcinoma",
legend = c(0.15,0.8), # 指定图例位置
legend.title = "aMAP-plus Score", # 设置图例标题，这里设置不显示标题，用空格替代
legend.labs = c("High-risk group", "Low-risk group"), # 指定图例分组标签
break.x.by = 3,
xlim = c(0,36),
#ylim = c(0,0.4)
)  # 设置x轴刻度间距
# whatever, on test set...
te_risk <- predict(mod, Test_id, type="risk")
Test_id$risk <- te_risk
Test_id$Group <- ifelse(Test_id$risk >= cutoff,"High","Low")
idx <- !is.na(te_risk)
c_index_te <- concordance.index(x = te_risk[idx], surv.time = Test_id$Times[idx],
surv.event = Test_id$Status[idx])$c.index
# with baseline data,
c_index
c_index_te
max(Train$Time[Train$Status == 1])
max(Test$Time[Test$Status == 1])
