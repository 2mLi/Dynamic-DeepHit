{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7802fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16428\\145838855.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_x_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_x_dim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_x_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_mask1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_mask2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_mask3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_data_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_feat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cont_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mte_x_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_x_dim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_x_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_mask1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_mask2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_mask3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_data_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_feat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cont_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_x_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_x_dim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_x_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_mask1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_mask2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_mask3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_data_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_feat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cont_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\import_data.py\u001b[0m in \u001b[0;36mimport_dataset\u001b[1;34m(path, bin_list_in, cont_list_in, log_list)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0mpat_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mf_construct_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_org\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[0mf_construct_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_org_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\import_data.py\u001b[0m in \u001b[0;36mf_construct_dataset\u001b[1;34m(df, feat_list)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# pat_info[i,5] = tmp['Patient'][0] # Patient ID as strings. necessary for internal/external validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2810\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2812\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2814\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   3407\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3408\u001b[0m         \"\"\"\n\u001b[1;32m-> 3409\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3410\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m         new_data = self._data.take(\n\u001b[1;32m-> 3395\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3396\u001b[0m         )\n\u001b[0;32m   3397\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m         return self.reindex_indexer(\n\u001b[1;32m-> 1394\u001b[1;33m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m         )\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m             new_blocks = [\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m             blknos = algos.take_1d(\n\u001b[1;32m-> 1315\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m             )\n\u001b[0;32m   1317\u001b[0m             blklocs = algos.take_1d(\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1660\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     )\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar', '1', '12', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = tr_label[:, 0]\n",
    "time = tr_time[:, 0]\n",
    "# true label: \n",
    "label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "    PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "'''\n",
    "\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "AUC_name = str(np.round(AUC, decimals = 4))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "    json.dump(tv_tr_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_train = Lspec\n",
    "Lsens_train = Lsens\n",
    "AUC_name_train = AUC_name\n",
    "AUC_UB_train = AUC_UB\n",
    "AUC_LB_train = AUC_LB\n",
    "'''\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "plt.plot(Lspec, Lsens)\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for test: \n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from 0 to 1\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_te)/sum(label_te)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "    PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "'''\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "'''\n",
    "# here, an alternative using the stat_util.py\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_te_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "    json.dump(tv_te_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_test = Lspec\n",
    "Lsens_test = Lsens\n",
    "AUC_name_test = AUC_name\n",
    "AUC_UB_test = AUC_UB\n",
    "AUC_LB_test = AUC_LB\n",
    "\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_general.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"Training tvAUC: \"+ AUC_name_train + \" (\" + AUC_LB_train + \", \" + AUC_UB_train + \")\")\n",
    "plt.text(x = 0.4, y = 0.04, s = \"Testing tvAUC: \"+ AUC_name_test + \" (\" + AUC_LB_test + \", \" + AUC_UB_test + \")\")\n",
    "\n",
    "plt.plot(Lspec_train, Lsens_train, label = 'Train')\n",
    "plt.plot(Lspec_test, Lsens_test, label = 'Test')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "# add a point with PPV about 0.33\n",
    "plt.scatter(Lspec_test[9693], Lsens_test[9693], c = 'red')\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532ba52e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2520\\3474407489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# we use PPV = 0.3 as a cutting point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# then calculate 12-month HCC rate in high-risk and low-risk groups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcut_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLPPV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mLPPV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcutpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcut_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# okay let us consider this: \n",
    "# we use PPV = 0.3 as a cutting point\n",
    "# then calculate 12-month HCC rate in high-risk and low-risk groups\n",
    "cut_idx = [i for i in range(len(LPPV)) if LPPV[i] >= 0.3][0]\n",
    "cutpoint = r[cut_idx]\n",
    "\n",
    "# high and low-risk group...\n",
    "te_highrisk_label = te_label[risk > cutpoint, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c289e3ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'te_highrisk_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2520\\144309574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PPV: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_highrisk_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_highrisk_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# PPV: 30% patients become HCC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'High-risk pop size: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_highrisk_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'High-risk HCC size: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.302\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'te_highrisk_label' is not defined"
     ]
    }
   ],
   "source": [
    "print('PPV: ' + str(float(sum(te_highrisk_label))/float(len(te_highrisk_label)))) # PPV: 30% patients become HCC\n",
    "print('High-risk pop size: ' + str(int(len(te_highrisk_label))))\n",
    "print('High-risk HCC size: ' + str(int(0.302 * 43)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb48d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff: 0.03978679348900914\n",
      "High risk size: 490\n",
      "High risk HCC: 25.0\n",
      "PPV: 0.05102040816326531\n",
      "Low risk size: 1530\n",
      "Low risk HCC: 9.0\n",
      "NPV: 0.9941176470588236\n"
     ]
    }
   ],
   "source": [
    "# Youden selection of best threshold\n",
    "from operator import add\n",
    "Lsens_tr = tv_tr_log[\"sens\"]\n",
    "Lspec_tr = tv_tr_log[\"spec\"]\n",
    "steps_tr = tv_tr_log['steps']\n",
    "youden = list(map(add, Lsens_tr, [-i for i in Lspec_tr]))\n",
    "max_idx = [i for i in range(len(youden)) if youden[i] >= max(youden)]\n",
    "cutoff = steps_tr[max_idx[0]]\n",
    "\n",
    "# cutoff = 0.045\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "print('Cutoff: ' + str(cutoff))\n",
    "print('High risk size: ' + str(len(highrisk_label)))\n",
    "print('High risk HCC: ' + str(sum(highrisk_label)))\n",
    "print('PPV: ' + str(sum(highrisk_label) / len(highrisk_label)))\n",
    "print('Low risk size: ' + str(len(lowrisk_label)))\n",
    "print('Low risk HCC: ' + str(sum(lowrisk_label)))\n",
    "print('NPV: ' + str(1 - sum(lowrisk_label) / len(lowrisk_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b86e147a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0634850338101387"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93feabf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High risk size: 3\n",
      "High risk HCC: 2.0\n",
      "PPV: 0.6666666666666666\n",
      "Low risk size: 2017\n",
      "Low risk HCC: 35.0\n",
      "NPV: 0.9826474962816063\n"
     ]
    }
   ],
   "source": [
    "cutoff = 0.06\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "print('High risk size: ' + str(len(highrisk_label)))\n",
    "print('High risk HCC: ' + str(sum(highrisk_label)))\n",
    "print('PPV: ' + str(sum(highrisk_label) / len(highrisk_label)))\n",
    "print('Low risk size: ' + str(len(lowrisk_label)))\n",
    "print('Low risk HCC: ' + str(sum(lowrisk_label)))\n",
    "print('NPV: ' + str(1 - sum(lowrisk_label) / len(lowrisk_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b9ff2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import ndtri\n",
    "\n",
    "\n",
    "def _proportion_confidence_interval(r, n, z):\n",
    "    A = 2*r + z**2\n",
    "    B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "    C = 2*(n + z**2)\n",
    "    return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "    z = -ndtri((1.0-alpha)/2)\n",
    "    sensitivity_point_estimate = TP/(TP + FN)\n",
    "    sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "    specificity_point_estimate = TN/(TN + FP)\n",
    "    specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "    \n",
    "    PPV_point_estimate = TP/(TP + FP)\n",
    "    PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "    NPV_point_estimate = TN / (FN + TN)\n",
    "    NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "    return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a06040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025777856034599245\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Youden selection of best threshold\n",
    "from operator import add\n",
    "Lsens_tr = tv_tr_log[\"sens\"]\n",
    "Lspec_tr = tv_tr_log[\"spec\"]\n",
    "steps_tr = tv_tr_log['steps']\n",
    "youden = list(map(add, Lsens_tr, [-i for i in Lspec_tr]))\n",
    "max_idx = [i for i in range(len(youden)) if youden[i] >= max(youden)]\n",
    "cutoff = steps_tr[max_idx[0]]\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "TP = sum(highrisk_label)\n",
    "FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "FN = sum(lowrisk_label)\n",
    "\n",
    "# sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "\n",
    "\n",
    "res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f04499a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b38c7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.859 (0.81, 0.904)\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.837 (0.752, 0.911)\n",
      "Cutoff: 0.06229167737998068\n",
      "sensitivity: [0.44117647] [[0.28883482], [0.60546101]]\n",
      "specificity: [0.97280967] [[0.96469288], [0.9791009]]\n",
      "PPV: [0.2173913] [[0.13640766], [0.32818296]]\n",
      "NPV: [0.9902614] [[0.98483939], [0.99375659]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = ['mod', 'PreCar', '1', '12', '10000']\n",
    "cutoff_adjustment = +0\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = tr_label[:, 0]\n",
    "time = tr_time[:, 0]\n",
    "# true label: \n",
    "label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "    PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "'''\n",
    "\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "AUC_name = str(np.round(AUC, decimals = 4))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "    json.dump(tv_tr_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_train = Lspec\n",
    "Lsens_train = Lsens\n",
    "AUC_name_train = AUC_name\n",
    "AUC_UB_train = AUC_UB\n",
    "AUC_LB_train = AUC_LB\n",
    "'''\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "plt.plot(Lspec, Lsens)\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for test: \n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from 0 to 1\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_te)/sum(label_te)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "    PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "'''\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "'''\n",
    "# here, an alternative using the stat_util.py\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_te_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "    json.dump(tv_te_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_test = Lspec\n",
    "Lsens_test = Lsens\n",
    "AUC_name_test = AUC_name\n",
    "AUC_UB_test = AUC_UB\n",
    "AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "from scipy.special import ndtri\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "# okay, now use pred_time and eval_time to make something\n",
    "# for this, we need a new step\n",
    "idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "tr_data_sub = tr_data[list(idx), :, :]\n",
    "tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "tr_time_sub = tr_time[idx, :]\n",
    "tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "label = tr_label_sub[:, 0]\n",
    "time = tr_time_sub[:, 0]\n",
    "true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "tr_label_sub = true_tr_label\n",
    "\n",
    "# now, risk\n",
    "risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "# okay given this risk, use log-rank...\n",
    "\n",
    "risk_max = max(risk_sub)\n",
    "risk_min = min(risk_sub)\n",
    "\n",
    "# let us say steps = 100\n",
    "steps = 100\n",
    "step = (risk_max - risk_min)/steps\n",
    "\n",
    "r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "# this should be a working example\n",
    "\n",
    "pvalL = []\n",
    "\n",
    "this_eval_time = eval_time\n",
    "this_pred_time = pred_time\n",
    "\n",
    "for step in r:\n",
    "\n",
    "\n",
    "\n",
    "    # divide pops based on the step\n",
    "    grp1_idx = [i > step for i in risk_sub]\n",
    "    grp0_idx = [i <= step for i in risk_sub]\n",
    "\n",
    "    grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "    grp1_time = tr_time_sub[grp1_idx]\n",
    "    grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "    # new label that is time-dynamic\n",
    "    grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "    grp1_label_new = np.zeros(len(grp1_label))\n",
    "    grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "    grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "    grp0_time = tr_time_sub[grp0_idx]\n",
    "    grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "    grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "    grp0_label_new = np.zeros(len(grp0_label))\n",
    "    grp0_label_new[grp0_label_idx] = 1\n",
    "\n",
    "\n",
    "    # now KM\n",
    "    lrt = logrank_test(grp0_time, grp1_time, grp0_label_new, grp1_label_new)\n",
    "    # print p value, just to check\n",
    "    # print('p value: ' + str(lrt.p_value))\n",
    "    # log p value\n",
    "    pvalL.append(lrt.p_value)\n",
    "\n",
    "min_p = min(pvalL)\n",
    "min_p_idx = [i for i in range(len(r)) if pvalL[i] == min_p][0]\n",
    "min_p_steps = r[min_p_idx]\n",
    "\n",
    "# then use it to calculate sens, spec, PPV and NPV in test set\n",
    "\n",
    "\n",
    "def _proportion_confidence_interval(r, n, z):\n",
    "    A = 2*r + z**2\n",
    "    B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "    C = 2*(n + z**2)\n",
    "    return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "    z = -ndtri((1.0-alpha)/2)\n",
    "    sensitivity_point_estimate = TP/(TP + FN)\n",
    "    sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "    specificity_point_estimate = TN/(TN + FP)\n",
    "    specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "    \n",
    "    PPV_point_estimate = TP/(TP + FP)\n",
    "    PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "    NPV_point_estimate = TN / (FN + TN)\n",
    "    NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "    return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# Youden selection of best threshold\n",
    "from operator import add\n",
    "cutoff = min_p_steps + cutoff_adjustment * step\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "# comment this to use the true te_data\n",
    "#te_data = tr_data\n",
    "#te_data_mi = tr_data_mi\n",
    "#te_label = tr_label\n",
    "#te_time = tr_time\n",
    "\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label\n",
    "time = te_time\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "TP = sum(highrisk_label)\n",
    "FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "FN = sum(lowrisk_label)\n",
    "\n",
    "# sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "# unpack res\n",
    "(sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572b843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.]\n",
      "[54.]\n",
      "[1932.]\n",
      "[19.]\n",
      "[2020.]\n",
      "[22.32265446]\n",
      "[1.34874584]\n"
     ]
    }
   ],
   "source": [
    "print(TP)\n",
    "print(FP)\n",
    "print(TN)\n",
    "print(FN)\n",
    "print(str(TP + FP + TN + FN))\n",
    "PPV = TP/(TP + FP)\n",
    "NPV = 1 - FN/(FN + TN)\n",
    "print(PPV/(1 - NPV))\n",
    "print(np.log10(PPV/(1-NPV)))\n",
    "# print(np.log10(2.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ae223c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.864 (0.788, 0.929)\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.746 (0.597, 0.842)\n",
      "Cutoff: 0.039468901546206324\n",
      "sensitivity: [0.] [[0.], [0.2775328]]\n",
      "specificity: [0.99751244] [[0.99418983], [0.99893701]]\n",
      "PPV: [0.] [[0.], [0.43448246]]\n",
      "NPV: [0.99503722] [[0.99088845], [0.99730207]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.735 (0.679, 0.792)\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.652 (0.554, 0.744)\n",
      "Cutoff: 0.13574070332571864\n",
      "sensitivity: [0.05882353] [[0.01628266], [0.19093607]]\n",
      "specificity: [0.99244713] [[0.98757538], [0.99541751]]\n",
      "PPV: [0.11764706] [[0.03287977], [0.34336351]]\n",
      "NPV: [0.98402396] [[0.9775341], [0.98866081]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.735 (0.688, 0.784)\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.664 (0.576, 0.747)\n",
      "Cutoff: 0.23148004956543444\n",
      "sensitivity: [0.10810811] [[0.0428519], [0.24708532]]\n",
      "specificity: [0.98537569] [[0.97907604], [0.98979845]]\n",
      "PPV: [0.12121212] [[0.04816161], [0.27325505]]\n",
      "NPV: [0.98339205] [[0.97676863], [0.98815]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.729 (0.681, 0.776)\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.647 (0.556, 0.733)\n",
      "Cutoff: 0.141956588588655\n",
      "sensitivity: [0.57894737] [[0.42192345], [0.72147499]]\n",
      "specificity: [0.64429869] [[0.62296237], [0.66507674]]\n",
      "PPV: [0.03026135] [[0.02006774], [0.04539305]]\n",
      "NPV: [0.98762568] [[0.97999355], [0.99236895]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.73 (0.681, 0.777)\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.637 (0.545, 0.724)\n",
      "Cutoff: 0.062268829829990865\n",
      "sensitivity: [1.] [[0.91033315], [1.]]\n",
      "specificity: [0.01060071] [[0.00694395], [0.01615183]]\n",
      "PPV: [0.01950975] [[0.01430442], [0.02655825]]\n",
      "NPV: [1.] [[0.84536098], [1.]]\n"
     ]
    }
   ],
   "source": [
    "# for loop our interested range\n",
    "eval_times = [1, 7, 13, 19, 25]\n",
    "for eval_time in eval_times: \n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['mod', 'PreCar', eval_time, '12', '10000']\n",
    "    cutoff_adjustment = +0\n",
    "\n",
    "    _EPSILON = 1e-08\n",
    "\n",
    "    #### <<< Warning suppression>>> ###\n",
    "    # import warnings\n",
    "    # warnings.filterwarnings('deprecated')\n",
    "    #### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import random\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import time as timepackage\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import import_data as impt\n",
    "\n",
    "    from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "    from utils_eval             import c_index, brier_score\n",
    "    from utils_log              import save_logging, load_logging\n",
    "    from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "    def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "        \"\"\"\n",
    "            predictions based on the prediction time.\n",
    "            create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "        \"\"\"\n",
    "        new_data    = np.zeros(np.shape(data))\n",
    "        new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "        meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "        for i in range(np.shape(data)[0]):\n",
    "            last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "            new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "            new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "        return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "    def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "\n",
    "        pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "        _, num_Event, num_Category = np.shape(pred)\n",
    "\n",
    "        risk_all = {}\n",
    "        for k in range(num_Event):\n",
    "            risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            ### PREDICTION\n",
    "            pred_horizon = int(p_time)\n",
    "            pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):\n",
    "                eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "                # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "                risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "                risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "\n",
    "                for k in range(num_Event):\n",
    "                    risk_all[k][:, p, t] = risk[:, k]\n",
    "\n",
    "        return risk_all\n",
    "\n",
    "    ## cmd args: \n",
    "    # now only one argument is needed\n",
    "    # this will be something like \"PreCar\"\n",
    "    # and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### the following codes read model training results plus needed data from Model_Training.py\n",
    "    # and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "    '''\n",
    "    saver.restore(sess, sys.argv[1])\n",
    "    with open(sys.argv[2]) as p: \n",
    "        params = json.load(p)\n",
    "    '''\n",
    "\n",
    "    # argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "    # argv[2], if left empty, will choose the most recent log\n",
    "    # if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "    data_mode_name = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # to do so, for now lets just use max argument\n",
    "        # firstly, take out all log.json documents\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        # logs is a list of all available logs; find the most recent one...\n",
    "        target_dir = data_mode_name + '/' + max(logs)\n",
    "        print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "    else: \n",
    "        # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        matched = [i for i in logs if sys.argv[2] in i]\n",
    "        if len(matched) >= 2: \n",
    "            print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "            matched = max(matched)\n",
    "        target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "    # read log\n",
    "    with open(target_dir + '/' + '_log.json') as p: \n",
    "        params = json.load(p)\n",
    "    mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "    # print(type(params))\n",
    "    new_parser = params['new_parser']\n",
    "    dataset_info = params['dataset_info']\n",
    "    evaluation_info = params['evaluation_info']\n",
    "    model_configs = params['model_configs']\n",
    "    eval_configs = params['eval_configs']\n",
    "    time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "    dirs = dataset_info\n",
    "    test_dir = []\n",
    "    data_mode = data_mode_name\n",
    "    for key in list(dirs.keys()): \n",
    "        if key == data_mode: \n",
    "            train_dir = dirs[key]\n",
    "        else: \n",
    "            test_dir.append(dirs[key])\n",
    "\n",
    "    (tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "    eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "    _, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "    max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "    #####\n",
    "\n",
    "    # A little treat: print name (in dict) of dataset\n",
    "    def get_key(val):\n",
    "        for key, value in dataset_info.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "\n",
    "        return \"There is no such Key\"\n",
    "\n",
    "    train_name = get_key(train_dir)\n",
    "    test1_name = get_key(test_dir[0])\n",
    "    test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "    #####\n",
    "\n",
    "    input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                    'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                    'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                    'num_Event'     : num_Event,\n",
    "                                    'num_Category'  : num_Category,\n",
    "                                    'max_length'    : max_length }\n",
    "\n",
    "    network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                    'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                    'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                    'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                    'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                    'RNN_type'          : new_parser['RNN_type'],\n",
    "                                    'FC_active_fn'      : tf.nn.relu,\n",
    "                                    'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                    'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                    'reg_W'             : new_parser['reg_W'],\n",
    "                                    'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                     }\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, mod_dir)\n",
    "\n",
    "    # By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "    # Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "    # here, we superseded eval_time and pred_time: \n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "        eval_time = float(sys.argv[2])\n",
    "        pred_time = float(sys.argv[3])\n",
    "        steps = int(sys.argv[4])\n",
    "    else: \n",
    "        eval_time = float(sys.argv[3])\n",
    "        pred_time = float(sys.argv[4])\n",
    "        steps = int(sys.argv[5])\n",
    "\n",
    "    # for train...\n",
    "    risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = tr_label[:, 0]\n",
    "    time = tr_time[:, 0]\n",
    "    # true label: \n",
    "    label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "        PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    AUC_name = str(np.round(AUC, decimals = 4))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "        json.dump(tv_tr_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_train = Lspec\n",
    "    Lsens_train = Lsens\n",
    "    AUC_name_train = AUC_name\n",
    "    AUC_UB_train = AUC_UB\n",
    "    AUC_LB_train = AUC_LB\n",
    "    '''\n",
    "    Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(6)\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "    plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    plt.plot(Lspec, Lsens)\n",
    "    # plt.show()\n",
    "    plt.savefig(Fig_name)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # for test: \n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label[:, 0]\n",
    "    time = te_time[:, 0]\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from 0 to 1\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_te)/sum(label_te)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "        PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    '''\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    '''\n",
    "    # here, an alternative using the stat_util.py\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_te_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "        json.dump(tv_te_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_test = Lspec\n",
    "    Lsens_test = Lsens\n",
    "    AUC_name_test = AUC_name\n",
    "    AUC_UB_test = AUC_UB\n",
    "    AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "    from scipy.special import ndtri\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "    # okay, now use pred_time and eval_time to make something\n",
    "    # for this, we need a new step\n",
    "    idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "    tr_data_sub = tr_data[list(idx), :, :]\n",
    "    tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "    tr_time_sub = tr_time[idx, :]\n",
    "    tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "    label = tr_label_sub[:, 0]\n",
    "    time = tr_time_sub[:, 0]\n",
    "    true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    tr_label_sub = true_tr_label\n",
    "\n",
    "    # now, risk\n",
    "    risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "    risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "    # okay given this risk, use log-rank...\n",
    "\n",
    "    risk_max = max(risk_sub)\n",
    "    risk_min = min(risk_sub)\n",
    "\n",
    "    # let us say steps = 100\n",
    "    steps = 100\n",
    "    step = (risk_max - risk_min)/steps\n",
    "\n",
    "    r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "    # this should be a working example\n",
    "\n",
    "    pvalL = []\n",
    "\n",
    "    this_eval_time = eval_time\n",
    "    this_pred_time = pred_time\n",
    "\n",
    "    for step in r:\n",
    "\n",
    "\n",
    "\n",
    "        # divide pops based on the step\n",
    "        grp1_idx = [i > step for i in risk_sub]\n",
    "        grp0_idx = [i <= step for i in risk_sub]\n",
    "\n",
    "        grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "        grp1_time = tr_time_sub[grp1_idx]\n",
    "        grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "        # new label that is time-dynamic\n",
    "        grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "        grp1_label_new = np.zeros(len(grp1_label))\n",
    "        grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "        grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "        grp0_time = tr_time_sub[grp0_idx]\n",
    "        grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "        grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "        grp0_label_new = np.zeros(len(grp0_label))\n",
    "        grp0_label_new[grp0_label_idx] = 1\n",
    "\n",
    "\n",
    "        # now KM\n",
    "        lrt = logrank_test(grp0_time, grp1_time, grp0_label_new, grp1_label_new)\n",
    "        # print p value, just to check\n",
    "        # print('p value: ' + str(lrt.p_value))\n",
    "        # log p value\n",
    "        pvalL.append(lrt.p_value)\n",
    "\n",
    "    min_p = min(pvalL)\n",
    "    min_p_idx = [i for i in range(len(r)) if pvalL[i] == min_p][0]\n",
    "    min_p_steps = r[min_p_idx]\n",
    "\n",
    "    # then use it to calculate sens, spec, PPV and NPV in test set\n",
    "\n",
    "\n",
    "    def _proportion_confidence_interval(r, n, z):\n",
    "        A = 2*r + z**2\n",
    "        B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "        C = 2*(n + z**2)\n",
    "        return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "    def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "        z = -ndtri((1.0-alpha)/2)\n",
    "        sensitivity_point_estimate = TP/(TP + FN)\n",
    "        sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "        specificity_point_estimate = TN/(TN + FP)\n",
    "        specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "\n",
    "        PPV_point_estimate = TP/(TP + FP)\n",
    "        PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "        NPV_point_estimate = TN / (FN + TN)\n",
    "        NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "        return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "    from math import sqrt\n",
    "\n",
    "    # Youden selection of best threshold\n",
    "    from operator import add\n",
    "    cutoff = min_p_steps + cutoff_adjustment * step\n",
    "\n",
    "    # use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "    # comment this to use the true te_data\n",
    "    #te_data = tr_data\n",
    "    #te_data_mi = tr_data_mi\n",
    "    #te_label = tr_label\n",
    "    #te_time = tr_time\n",
    "\n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label\n",
    "    time = te_time\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "    highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "    lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "    TP = sum(highrisk_label)\n",
    "    FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "    TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "    FN = sum(lowrisk_label)\n",
    "\n",
    "    # sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "    res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "    print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "    # unpack res\n",
    "    (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "    print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "    print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "    print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "    print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cf0271",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.859 (0.81, 0.904)\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.837 (0.752, 0.911)\n",
      "In train set... \n",
      "Cutoff: 0.06753163365637883\n",
      "sensitivity: [0.07142857] [[0.03089422], [0.15655412]]\n",
      "specificity: [0.99903754] [[0.99649738], [0.99973602]]\n",
      "PPV: [0.71428571] [[0.35893445], [0.91778108]]\n",
      "NPV: [0.96964035] [[0.96148953], [0.9761089]]\n",
      "Enrichment ratio: [23.52747253]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 7.0 with horizon 12.0: 0.868 (0.827, 0.906)\n",
      "Time-varying AUC at landmark 7.0 with horizon 12.0: 0.827 (0.747, 0.899)\n",
      "In train set... \n",
      "Cutoff: 0.20040974135398865\n",
      "sensitivity: [0.20430108] [[0.13487642], [0.297185]]\n",
      "specificity: [0.99513382] [[0.99106534], [0.99735463]]\n",
      "PPV: [0.65517241] [[0.47345104], [0.80059281]]\n",
      "NPV: [0.96507787] [[0.9563816], [0.97209094]]\n",
      "Enrichment ratio: [18.76095061]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 13.0 with horizon 12.0: 0.864 (0.825, 0.902)\n",
      "Time-varying AUC at landmark 13.0 with horizon 12.0: 0.808 (0.719, 0.888)\n",
      "In train set... \n",
      "Cutoff: 0.295194588957727\n",
      "sensitivity: [0.28865979] [[0.20790256], [0.38551864]]\n",
      "specificity: [0.99268649] [[0.98796797], [0.9955629]]\n",
      "PPV: [0.65116279] [[0.50171782], [0.7758141]]\n",
      "NPV: [0.9672209] [[0.95872276], [0.97401687]]\n",
      "Enrichment ratio: [19.86518369]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9140\\2866371978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mPPV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mNPV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[0mLsens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mLspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for loop our interested range\n",
    "eval_times = [1, 7, 13, 19, 25]\n",
    "adj_range = [0.41,0.44,0.44,0.44,0.19]\n",
    "for eval_time, adj in zip(eval_times, adj_range): \n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['mod', 'PreCar', eval_time, '12', '10000']\n",
    "    cutoff_adjustment = adj\n",
    "\n",
    "    _EPSILON = 1e-08\n",
    "\n",
    "    #### <<< Warning suppression>>> ###\n",
    "    # import warnings\n",
    "    # warnings.filterwarnings('deprecated')\n",
    "    #### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import random\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import time as timepackage\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import import_data as impt\n",
    "\n",
    "    from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "    from utils_eval             import c_index, brier_score\n",
    "    from utils_log              import save_logging, load_logging\n",
    "    from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "    def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "        \"\"\"\n",
    "            predictions based on the prediction time.\n",
    "            create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "        \"\"\"\n",
    "        new_data    = np.zeros(np.shape(data))\n",
    "        new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "        meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "        for i in range(np.shape(data)[0]):\n",
    "            last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "            new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "            new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "        return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "    def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "\n",
    "        pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "        _, num_Event, num_Category = np.shape(pred)\n",
    "\n",
    "        risk_all = {}\n",
    "        for k in range(num_Event):\n",
    "            risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            ### PREDICTION\n",
    "            pred_horizon = int(p_time)\n",
    "            pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):\n",
    "                eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "                # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "                risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "                risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "\n",
    "                for k in range(num_Event):\n",
    "                    risk_all[k][:, p, t] = risk[:, k]\n",
    "\n",
    "        return risk_all\n",
    "\n",
    "    ## cmd args: \n",
    "    # now only one argument is needed\n",
    "    # this will be something like \"PreCar\"\n",
    "    # and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### the following codes read model training results plus needed data from Model_Training.py\n",
    "    # and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "    '''\n",
    "    saver.restore(sess, sys.argv[1])\n",
    "    with open(sys.argv[2]) as p: \n",
    "        params = json.load(p)\n",
    "    '''\n",
    "\n",
    "    # argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "    # argv[2], if left empty, will choose the most recent log\n",
    "    # if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "    data_mode_name = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # to do so, for now lets just use max argument\n",
    "        # firstly, take out all log.json documents\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        # logs is a list of all available logs; find the most recent one...\n",
    "        target_dir = data_mode_name + '/' + max(logs)\n",
    "        print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "    else: \n",
    "        # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        matched = [i for i in logs if sys.argv[2] in i]\n",
    "        if len(matched) >= 2: \n",
    "            print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "            matched = max(matched)\n",
    "        target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "    # read log\n",
    "    with open(target_dir + '/' + '_log.json') as p: \n",
    "        params = json.load(p)\n",
    "    mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "    # print(type(params))\n",
    "    new_parser = params['new_parser']\n",
    "    dataset_info = params['dataset_info']\n",
    "    evaluation_info = params['evaluation_info']\n",
    "    model_configs = params['model_configs']\n",
    "    eval_configs = params['eval_configs']\n",
    "    time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "    dirs = dataset_info\n",
    "    test_dir = []\n",
    "    data_mode = data_mode_name\n",
    "    for key in list(dirs.keys()): \n",
    "        if key == data_mode: \n",
    "            train_dir = dirs[key]\n",
    "        else: \n",
    "            test_dir.append(dirs[key])\n",
    "\n",
    "    (tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "    eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "    _, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "    max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "    #####\n",
    "\n",
    "    # A little treat: print name (in dict) of dataset\n",
    "    def get_key(val):\n",
    "        for key, value in dataset_info.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "\n",
    "        return \"There is no such Key\"\n",
    "\n",
    "    train_name = get_key(train_dir)\n",
    "    test1_name = get_key(test_dir[0])\n",
    "    test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "    #####\n",
    "\n",
    "    input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                    'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                    'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                    'num_Event'     : num_Event,\n",
    "                                    'num_Category'  : num_Category,\n",
    "                                    'max_length'    : max_length }\n",
    "\n",
    "    network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                    'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                    'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                    'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                    'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                    'RNN_type'          : new_parser['RNN_type'],\n",
    "                                    'FC_active_fn'      : tf.nn.relu,\n",
    "                                    'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                    'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                    'reg_W'             : new_parser['reg_W'],\n",
    "                                    'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                     }\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, mod_dir)\n",
    "\n",
    "    # By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "    # Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "    # here, we superseded eval_time and pred_time: \n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "        eval_time = float(sys.argv[2])\n",
    "        pred_time = float(sys.argv[3])\n",
    "        steps = int(sys.argv[4])\n",
    "    else: \n",
    "        eval_time = float(sys.argv[3])\n",
    "        pred_time = float(sys.argv[4])\n",
    "        steps = int(sys.argv[5])\n",
    "\n",
    "    # for train...\n",
    "    risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = tr_label[:, 0]\n",
    "    time = tr_time[:, 0]\n",
    "    # true label: \n",
    "    label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "        PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    AUC_name = str(np.round(AUC, decimals = 4))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "        json.dump(tv_tr_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_train = Lspec\n",
    "    Lsens_train = Lsens\n",
    "    AUC_name_train = AUC_name\n",
    "    AUC_UB_train = AUC_UB\n",
    "    AUC_LB_train = AUC_LB\n",
    "    '''\n",
    "    Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(6)\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "    plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    plt.plot(Lspec, Lsens)\n",
    "    # plt.show()\n",
    "    plt.savefig(Fig_name)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # for test: \n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label[:, 0]\n",
    "    time = te_time[:, 0]\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from 0 to 1\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_te)/sum(label_te)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "        PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    '''\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    '''\n",
    "    # here, an alternative using the stat_util.py\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_te_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "        json.dump(tv_te_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_test = Lspec\n",
    "    Lsens_test = Lsens\n",
    "    AUC_name_test = AUC_name\n",
    "    AUC_UB_test = AUC_UB\n",
    "    AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "    from scipy.special import ndtri\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "    # okay, now use pred_time and eval_time to make something\n",
    "    # for this, we need a new step\n",
    "    idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "    tr_data_sub = tr_data[list(idx), :, :]\n",
    "    tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "    tr_time_sub = tr_time[idx, :]\n",
    "    tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "    label = tr_label_sub[:, 0]\n",
    "    time = tr_time_sub[:, 0]\n",
    "    true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    tr_label_sub = true_tr_label\n",
    "\n",
    "    # now, risk\n",
    "    risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "    risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "    # okay given this risk, use log-rank...\n",
    "\n",
    "    risk_max = max(risk_sub)\n",
    "    risk_min = min(risk_sub)\n",
    "\n",
    "    # let us say steps = 100\n",
    "    steps = 100\n",
    "    step = (risk_max - risk_min)/steps\n",
    "\n",
    "    r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "    # this should be a working example\n",
    "\n",
    "    youdenL = []\n",
    "\n",
    "    this_eval_time = eval_time\n",
    "    this_pred_time = pred_time\n",
    "    from math import sqrt\n",
    "    from operator import add\n",
    "    def _proportion_confidence_interval(r, n, z):\n",
    "        A = 2*r + z**2\n",
    "        B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "        C = 2*(n + z**2)\n",
    "        return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "    def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "        z = -ndtri((1.0-alpha)/2)\n",
    "        sensitivity_point_estimate = TP/(TP + FN)\n",
    "        sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "        specificity_point_estimate = TN/(TN + FP)\n",
    "        specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "\n",
    "        PPV_point_estimate = TP/(TP + FP)\n",
    "        PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "        NPV_point_estimate = TN / (FN + TN)\n",
    "        NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "        return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "    \n",
    "    for step in r: \n",
    "        # divide pops based on the step\n",
    "        grp1_idx = [i > step for i in risk_sub]\n",
    "        grp0_idx = [i <= step for i in risk_sub]\n",
    "        \n",
    "        grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "        grp1_time = tr_time_sub[grp1_idx]\n",
    "        grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "        # new label that is time-dynamic\n",
    "        grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "        grp1_label_new = np.zeros(len(grp1_label))\n",
    "        grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "        grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "        grp0_time = tr_time_sub[grp0_idx]\n",
    "        grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "        grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "        grp0_label_new = np.zeros(len(grp0_label))\n",
    "        grp0_label_new[grp0_label_idx] = 1\n",
    "        \n",
    "        # calculate sens and spec, then append to youdenL\n",
    "        risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])[0]\n",
    "        highrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] > step]\n",
    "        lowrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] <= step]\n",
    "\n",
    "        TP = sum(highrisk_label)\n",
    "        FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "        TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "        FN = sum(lowrisk_label)\n",
    "        res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "        (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "        \n",
    "        youdenL.append(sens + spec - 1)\n",
    "    \n",
    "\n",
    "    min_youden = max(youdenL)\n",
    "    min_idx = [i for i in range(len(r)) if youdenL[i] == min_youden][0]\n",
    "    cutoff_proto = r[min_idx]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Youden selection of best threshold\n",
    "    print('In train set... ')\n",
    "    cutoff = cutoff_proto + cutoff_adjustment * step\n",
    "\n",
    "    # use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "    # comment this to use the true te_data\n",
    "    te_data = tr_data\n",
    "    te_data_mi = tr_data_mi\n",
    "    te_label = tr_label\n",
    "    te_time = tr_time\n",
    "\n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label\n",
    "    time = te_time\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "    highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "    lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "    TP = sum(highrisk_label)\n",
    "    FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "    TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "    FN = sum(lowrisk_label)\n",
    "\n",
    "    # sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "    res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "    print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "    # unpack res\n",
    "    (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "    print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "    print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "    print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "    print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')\n",
    "    \n",
    "     # before printing enrichment ratio, modify NPV if it equals zero\n",
    "    if 1-NPV == 0: \n",
    "        NPV = NPV - 0.0001\n",
    "    print('Enrichment ratio: ' + str(PPV/(1-NPV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0859dfbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\utils_network.py:24: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\utils_network.py:29: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\class_DeepLongitudinal.py:20: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.864 (0.788, 0.929)\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.746 (0.597, 0.842)\n",
      "In test set...\n",
      "Cutoff: 0.009462962578982114\n",
      "sensitivity: [0.9] [[0.59584997], [0.98212379]]\n",
      "specificity: [0.60199005] [[0.58041612], [0.62317488]]\n",
      "PPV: [0.01112485] [[0.00586368], [0.02100682]]\n",
      "NPV: [0.99917424] [[0.99533737], [0.99985422]]\n",
      "Enrichment ratio: [13.47218789]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.735 (0.679, 0.792)\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.652 (0.554, 0.744)\n",
      "In test set...\n",
      "Cutoff: 0.07168296158313751\n",
      "sensitivity: [0.35294118] [[0.21487921], [0.52086037]]\n",
      "specificity: [0.81268882] [[0.7949317], [0.82923863]]\n",
      "PPV: [0.03125] [[0.01796504], [0.05382063]]\n",
      "NPV: [0.98655257] [[0.97972268], [0.99110287]]\n",
      "Enrichment ratio: [2.32386364]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.735 (0.688, 0.784)\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.664 (0.576, 0.747)\n",
      "In test set...\n",
      "Cutoff: 0.09939419385045767\n",
      "sensitivity: [0.75675676] [[0.59882708], [0.86638647]]\n",
      "specificity: [0.52950076] [[0.50749644], [0.551391]]\n",
      "PPV: [0.02913632] [[0.02023425], [0.04178782]]\n",
      "NPV: [0.99150142] [[0.98392743], [0.9955225]]\n",
      "Enrichment ratio: [3.42837322]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.729 (0.681, 0.776)\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.647 (0.556, 0.733)\n",
      "In test set...\n",
      "Cutoff: 0.12713213317096234\n",
      "sensitivity: [0.73684211] [[0.57991154], [0.85028379]]\n",
      "specificity: [0.49798184] [[0.47599488], [0.5199766]]\n",
      "PPV: [0.02737048] [[0.01900362], [0.03927359]]\n",
      "NPV: [0.98996991] [[0.98163574], [0.99454285]]\n",
      "Enrichment ratio: [2.72883675]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.73 (0.681, 0.777)\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.637 (0.545, 0.724)\n",
      "In test set...\n",
      "Cutoff: 0.16168523099273444\n",
      "sensitivity: [0.64102564] [[0.48418149], [0.77257915]]\n",
      "specificity: [0.54921757] [[0.52723235], [0.57101227]]\n",
      "PPV: [0.02723312] [[0.01851324], [0.03989318]]\n",
      "NPV: [0.98729583] [[0.97878864], [0.99241749]]\n",
      "Enrichment ratio: [2.14363523]\n"
     ]
    }
   ],
   "source": [
    "# for loop our interested range\n",
    "eval_times = [1, 7, 13, 19, 25]\n",
    "adj_range = [0, 0, 0, 0, 0]\n",
    "for eval_time, adj in zip(eval_times, adj_range): \n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['mod', 'PreCar', eval_time, '6', '10000']\n",
    "    cutoff_adjustment = adj\n",
    "\n",
    "    _EPSILON = 1e-08\n",
    "\n",
    "    #### <<< Warning suppression>>> ###\n",
    "    # import warnings\n",
    "    # warnings.filterwarnings('deprecated')\n",
    "    #### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import random\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import time as timepackage\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import import_data as impt\n",
    "\n",
    "    from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "    from utils_eval             import c_index, brier_score\n",
    "    from utils_log              import save_logging, load_logging\n",
    "    from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "    def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "        \"\"\"\n",
    "            predictions based on the prediction time.\n",
    "            create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "        \"\"\"\n",
    "        new_data    = np.zeros(np.shape(data))\n",
    "        new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "        meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "        for i in range(np.shape(data)[0]):\n",
    "            last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "            new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "            new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "        return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "    def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "\n",
    "        pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "        _, num_Event, num_Category = np.shape(pred)\n",
    "\n",
    "        risk_all = {}\n",
    "        for k in range(num_Event):\n",
    "            risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            ### PREDICTION\n",
    "            pred_horizon = int(p_time)\n",
    "            pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):\n",
    "                eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "                # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "                risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "                risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "\n",
    "                for k in range(num_Event):\n",
    "                    risk_all[k][:, p, t] = risk[:, k]\n",
    "\n",
    "        return risk_all\n",
    "\n",
    "    ## cmd args: \n",
    "    # now only one argument is needed\n",
    "    # this will be something like \"PreCar\"\n",
    "    # and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### the following codes read model training results plus needed data from Model_Training.py\n",
    "    # and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "    '''\n",
    "    saver.restore(sess, sys.argv[1])\n",
    "    with open(sys.argv[2]) as p: \n",
    "        params = json.load(p)\n",
    "    '''\n",
    "\n",
    "    # argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "    # argv[2], if left empty, will choose the most recent log\n",
    "    # if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "    data_mode_name = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # to do so, for now lets just use max argument\n",
    "        # firstly, take out all log.json documents\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        # logs is a list of all available logs; find the most recent one...\n",
    "        target_dir = data_mode_name + '/' + max(logs)\n",
    "        print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "    else: \n",
    "        # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        matched = [i for i in logs if sys.argv[2] in i]\n",
    "        if len(matched) >= 2: \n",
    "            print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "            matched = max(matched)\n",
    "        target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "    # read log\n",
    "    with open(target_dir + '/' + '_log.json') as p: \n",
    "        params = json.load(p)\n",
    "    mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "    # print(type(params))\n",
    "    new_parser = params['new_parser']\n",
    "    dataset_info = params['dataset_info']\n",
    "    evaluation_info = params['evaluation_info']\n",
    "    model_configs = params['model_configs']\n",
    "    eval_configs = params['eval_configs']\n",
    "    time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "    dirs = dataset_info\n",
    "    test_dir = []\n",
    "    data_mode = data_mode_name\n",
    "    for key in list(dirs.keys()): \n",
    "        if key == data_mode: \n",
    "            train_dir = dirs[key]\n",
    "        else: \n",
    "            test_dir.append(dirs[key])\n",
    "\n",
    "    (tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "    eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "    _, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "    max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "    #####\n",
    "\n",
    "    # A little treat: print name (in dict) of dataset\n",
    "    def get_key(val):\n",
    "        for key, value in dataset_info.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "\n",
    "        return \"There is no such Key\"\n",
    "\n",
    "    train_name = get_key(train_dir)\n",
    "    test1_name = get_key(test_dir[0])\n",
    "    test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "    #####\n",
    "\n",
    "    input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                    'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                    'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                    'num_Event'     : num_Event,\n",
    "                                    'num_Category'  : num_Category,\n",
    "                                    'max_length'    : max_length }\n",
    "\n",
    "    network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                    'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                    'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                    'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                    'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                    'RNN_type'          : new_parser['RNN_type'],\n",
    "                                    'FC_active_fn'      : tf.nn.relu,\n",
    "                                    'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                    'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                    'reg_W'             : new_parser['reg_W'],\n",
    "                                    'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                     }\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, mod_dir)\n",
    "\n",
    "    # By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "    # Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "    # here, we superseded eval_time and pred_time: \n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "        eval_time = float(sys.argv[2])\n",
    "        pred_time = float(sys.argv[3])\n",
    "        steps = int(sys.argv[4])\n",
    "    else: \n",
    "        eval_time = float(sys.argv[3])\n",
    "        pred_time = float(sys.argv[4])\n",
    "        steps = int(sys.argv[5])\n",
    "\n",
    "    # for train...\n",
    "    risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = tr_label[:, 0]\n",
    "    time = tr_time[:, 0]\n",
    "    # true label: \n",
    "    label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "        PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    AUC_name = str(np.round(AUC, decimals = 4))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "        json.dump(tv_tr_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_train = Lspec\n",
    "    Lsens_train = Lsens\n",
    "    AUC_name_train = AUC_name\n",
    "    AUC_UB_train = AUC_UB\n",
    "    AUC_LB_train = AUC_LB\n",
    "    '''\n",
    "    Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(6)\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "    plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    plt.plot(Lspec, Lsens)\n",
    "    # plt.show()\n",
    "    plt.savefig(Fig_name)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # for test: \n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label[:, 0]\n",
    "    time = te_time[:, 0]\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from 0 to 1\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_te)/sum(label_te)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "        PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    '''\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    '''\n",
    "    # here, an alternative using the stat_util.py\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_te_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "        json.dump(tv_te_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_test = Lspec\n",
    "    Lsens_test = Lsens\n",
    "    AUC_name_test = AUC_name\n",
    "    AUC_UB_test = AUC_UB\n",
    "    AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "    from scipy.special import ndtri\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "    # okay, now use pred_time and eval_time to make something\n",
    "    # for this, we need a new step\n",
    "    idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "    tr_data_sub = tr_data[list(idx), :, :]\n",
    "    tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "    tr_time_sub = tr_time[idx, :]\n",
    "    tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "    label = tr_label_sub[:, 0]\n",
    "    time = tr_time_sub[:, 0]\n",
    "    true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    tr_label_sub = true_tr_label\n",
    "\n",
    "    # now, risk\n",
    "    risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "    risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "    # okay given this risk, use log-rank...\n",
    "\n",
    "    risk_max = max(risk_sub)\n",
    "    risk_min = min(risk_sub)\n",
    "\n",
    "    # let us say steps = 100\n",
    "    steps = 100\n",
    "    step = (risk_max - risk_min)/steps\n",
    "\n",
    "    r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "    # this should be a working example\n",
    "\n",
    "    youdenL = []\n",
    "\n",
    "    this_eval_time = eval_time\n",
    "    this_pred_time = pred_time\n",
    "    from math import sqrt\n",
    "    from operator import add\n",
    "    def _proportion_confidence_interval(r, n, z):\n",
    "        A = 2*r + z**2\n",
    "        B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "        C = 2*(n + z**2)\n",
    "        return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "    def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "        z = -ndtri((1.0-alpha)/2)\n",
    "        sensitivity_point_estimate = TP/(TP + FN)\n",
    "        sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "        specificity_point_estimate = TN/(TN + FP)\n",
    "        specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "\n",
    "        PPV_point_estimate = TP/(TP + FP)\n",
    "        PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "        NPV_point_estimate = TN / (FN + TN)\n",
    "        NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "        return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "    \n",
    "    for step in r: \n",
    "        # divide pops based on the step\n",
    "        grp1_idx = [i > step for i in risk_sub]\n",
    "        grp0_idx = [i <= step for i in risk_sub]\n",
    "        \n",
    "        grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "        grp1_time = tr_time_sub[grp1_idx]\n",
    "        grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "        # new label that is time-dynamic\n",
    "        grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "        grp1_label_new = np.zeros(len(grp1_label))\n",
    "        grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "        grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "        grp0_time = tr_time_sub[grp0_idx]\n",
    "        grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "        grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "        grp0_label_new = np.zeros(len(grp0_label))\n",
    "        grp0_label_new[grp0_label_idx] = 1\n",
    "        \n",
    "        # calculate sens and spec, then append to youdenL\n",
    "        risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])[0]\n",
    "        highrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] > step]\n",
    "        lowrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] <= step]\n",
    "\n",
    "        TP = sum(highrisk_label)\n",
    "        FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "        TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "        FN = sum(lowrisk_label)\n",
    "        res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "        (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "        \n",
    "        youdenL.append(sens + spec - 1)\n",
    "    \n",
    "\n",
    "    min_youden = max(youdenL)\n",
    "    min_idx = [i for i in range(len(r)) if youdenL[i] == min_youden][0]\n",
    "    cutoff_proto = r[min_idx]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Youden selection of best threshold\n",
    "    \n",
    "    cutoff = cutoff_proto + cutoff_adjustment * step\n",
    "    print('In test set...')\n",
    "    # use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "    # comment this to use the true te_data\n",
    "    #te_data = tr_data\n",
    "    #te_data_mi = tr_data_mi\n",
    "    #te_label = tr_label\n",
    "    #te_time = tr_time\n",
    "\n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label\n",
    "    time = te_time\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "    highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "    lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "    TP = sum(highrisk_label)\n",
    "    FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "    TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "    FN = sum(lowrisk_label)\n",
    "\n",
    "    # sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "    res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "    print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "    # unpack res\n",
    "    (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "    print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "    print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "    print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "    print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')\n",
    "    \n",
    "    # before printing enrichment ratio, modify NPV if it equals zero\n",
    "    if 1-NPV == 0: \n",
    "        NPV = NPV - 0.0001\n",
    "    print('Enrichment ratio: ' + str(PPV/(1-NPV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3fe4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n"
     ]
    }
   ],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar', '1', '6', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "\n",
    "eval_path = target_dir + '/eval'\n",
    "\n",
    "tr_risk = list(risk[0][:, 0, 0])\n",
    "tr_export = {\"Risk\": tr_risk, \n",
    "       \"ID\": tr_id, \n",
    "            \"Times\": tr_time[:, 0], \n",
    "            \"Status\": tr_label[:, 0]}\n",
    "\n",
    "tr_df = pd.DataFrame(tr_export)\n",
    "\n",
    "tr_df.to_csv(eval_path + '/' + 'exported_risk_tr.csv', index = False)\n",
    "\n",
    "# test\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "\n",
    "eval_path = target_dir + '/eval'\n",
    "\n",
    "te_risk = list(risk[0][:, 0, 0])\n",
    "te_export = {\"Risk\": te_risk, \n",
    "       \"ID\": te_id, \n",
    "            \"Times\": te_time[:, 0], \n",
    "            \"Status\": te_label[:, 0]}\n",
    "\n",
    "te_df = pd.DataFrame(te_export)\n",
    "\n",
    "te_df.to_csv(eval_path + '/' + 'exported_risk_te.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d3249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# risk[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "296b7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 18.0: 0.891 (0.854, 0.927)\n"
     ]
    }
   ],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar', '1', '18', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = tr_label[:, 0]\n",
    "time = tr_time[:, 0]\n",
    "# true label: \n",
    "label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "    PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "'''\n",
    "\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "AUC_name = str(np.round(AUC, decimals = 4))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "    json.dump(tv_tr_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_train = Lspec\n",
    "Lsens_train = Lsens\n",
    "AUC_name_train = AUC_name\n",
    "AUC_UB_train = AUC_UB\n",
    "AUC_LB_train = AUC_LB\n",
    "'''\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "plt.plot(Lspec, Lsens)\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)\n",
    "'''\n",
    "\n",
    "pred_time = [12, 24, 36]\n",
    "eval_time = 0\n",
    "\n",
    "# for test: \n",
    "risk_tr = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, pred_time, [eval_time])\n",
    "risk_te = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, [eval_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51a39e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2148, 3, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_tr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9e87f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-year: \n",
      "High-risk mean incidence: 3.406%\n",
      "Low-risk mean incidence: 1.854%\n",
      "Two-year: \n",
      "High-risk mean incidence: 2.085%\n",
      "Low-risk mean incidence: 0.111%\n",
      "Three-year: \n",
      "High-risk mean incidence: 23.93%\n",
      "Low-risk mean incidence: 18.59%\n"
     ]
    }
   ],
   "source": [
    "# 12-month\n",
    "cutoff_12mth = 0.032424807325005536\n",
    "risk_tr_12mth = list(risk_tr[0][:, 0, 0])\n",
    "risk_te_12mth = list(risk_te[0][:, 0, 0])\n",
    "highrisk_12mth_tr = np.mean([i for i in risk_tr_12mth if i > cutoff_12mth])\n",
    "lowrisk_12mth_tr = np.mean([i for i in risk_tr_12mth if i <= cutoff_12mth])\n",
    "print('One-year: ')\n",
    "print('High-risk mean incidence: ' + str(highrisk_12mth_tr * 100)[0:5] + '%')\n",
    "print('Low-risk mean incidence: ' + str(lowrisk_12mth_tr * 100)[0:5] + '%')\n",
    "\n",
    "\n",
    "# 24-month\n",
    "cutoff_24mth = 0.01406039503752254\n",
    "risk_tr_24mth = list(risk_tr[0][:, 1, 0])\n",
    "risk_te_24mth = list(risk_te[0][:, 1, 0])\n",
    "highrisk_24mth_tr = np.mean([i for i in risk_tr_24mth if i > cutoff_24mth])\n",
    "lowrisk_24mth_tr = np.mean([i for i in risk_tr_24mth if i <= cutoff_24mth])\n",
    "print('Two-year: ')\n",
    "print('High-risk mean incidence: ' + str(highrisk_24mth_tr * 100)[0:5] + '%')\n",
    "print('Low-risk mean incidence: ' + str(lowrisk_24mth_tr * 100)[0:5] + '%')\n",
    "\n",
    "# 36-month\n",
    "cutoff_36mth = 0.19262462258338928\n",
    "risk_tr_36mth = list(risk_tr[0][:, 2, 0])\n",
    "risk_te_36mth = list(risk_te[0][:, 2, 0])\n",
    "highrisk_36mth_tr = np.mean([i for i in risk_tr_36mth if i > cutoff_36mth])\n",
    "lowrisk_36mth_tr = np.mean([i for i in risk_tr_36mth if i <= cutoff_36mth])\n",
    "print('Three-year: ')\n",
    "print('High-risk mean incidence: ' + str(highrisk_36mth_tr * 100)[0:5] + '%')\n",
    "print('Low-risk mean incidence: ' + str(lowrisk_36mth_tr * 100)[0:5] + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fd075f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in risk_tr if i <= cutoff_12mth]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "738373a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = str(lowrisk_12mth_tr * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87f2c403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.854'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe5144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-04-25_01-23-17-994216_my_aMAP_model_with_CNVs_FS_aMAP/model\n",
      "Patient Status: LC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# okay, now combine everything together...\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from numpy import newaxis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "sys.argv = ['mod', 'PreCar', '6', '0.01', '1', '1']\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 7:  \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "if tr_data.shape[1] > te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - te_data.shape[1]\n",
    "    for i in range(k): \n",
    "        te_data = np.append(te_data, np.zeros(shape = (te_data.shape[0], 1, te_data.shape[2]), dtype = float), axis = 1) \n",
    "        te_data_mi = np.append(te_data_mi, np.zeros(shape = (te_data_mi.shape[0], 1, te_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "if tr_data.shape[1] > tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - tea_data.shape[1]\n",
    "    for i in range(k): \n",
    "        tea_data = np.append(tea_data, np.zeros(shape = (tea_data.shape[0], 1, tea_data.shape[2]), dtype = float), axis = 1) \n",
    "        tea_data_mi = np.append(tea_data_mi, np.zeros(shape = (tea_data_mi.shape[0], 1, tea_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "# on the other hand what may happen if... \n",
    "if tr_data.shape[1] < te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    te_data = te_data[:, range(tr_data.shape[1]), :]\n",
    "    te_data_mi = te_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "if tr_data.shape[1] < tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    tea_data = tea_data[:, range(tr_data.shape[1]), :]\n",
    "    tea_data_mi = tea_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) < 7: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    # eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[2])\n",
    "    step = float(sys.argv[3])\n",
    "    pat1 = int(sys.argv[4])# {Left or Right}\n",
    "    grp = int(sys.argv[5])\n",
    "else: \n",
    "    # eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    step = float(sys.argv[4])\n",
    "    pat1 = int(sys.argv[5])\n",
    "    grp = int(sys.argv[6])\n",
    "# for this patient... (in test set)\n",
    "# determine which set this is\n",
    "if grp == 1:  \n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "elif grp == 2: \n",
    "    te_id = list(tea_id)\n",
    "    te_data = tea_data\n",
    "    te_data_mi = tea_data_mi\n",
    "    idf = test2_name\n",
    "elif grp == 0: \n",
    "    te_id = list(tr_id)\n",
    "    te_data = tr_data\n",
    "    te_data_mi = tr_data_mi\n",
    "    idf = train_name\n",
    "else: \n",
    "    print(\"The user has not correctly specified which dataset the patient comes from. Assuming from test set 1. \")\n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "\n",
    "# find pat_idx\n",
    "if pat1 in te_id: \n",
    "    pat1_idx = te_id.index(pat1)\n",
    "else: \n",
    "    print(\"The specified patient id was not found in the specified test set. Assuming the use of first patient in test set. \")\n",
    "    pat_idx = 0\n",
    "    \n",
    "\n",
    "\n",
    "pat1_data = te_data[pat1_idx, :, :]\n",
    "pat1_data = pat1_data[newaxis, :, :]\n",
    "pat1_data_mi = te_data_mi[pat1_idx, :, :]\n",
    "pat1_data_mi = pat1_data_mi[newaxis, :, :]\n",
    "\n",
    "\n",
    "# work out the true eval time\n",
    "# the first element is always zero...\n",
    "true_eval_time1 = [0]\n",
    "pat_time_series1 = pat1_data[0, :, 0]\n",
    "pat_time_series1 = [i for i in pat_time_series1 if not i == 0]\n",
    "\n",
    "for i in range(len(pat_time_series1)): \n",
    "    true_eval_time1.append(pat_time_series1[i]) # append time\n",
    "    \n",
    "l1 = len(pat_time_series1)\n",
    "for i in [int(j) for j in list(np.linspace(1, l1, l1))]: \n",
    "    true_eval_time1[i] = true_eval_time1[i] + true_eval_time1[i - 1]\n",
    "\n",
    "# for pred_time, let us still use the external argument\n",
    "# pred_time = float(sys.argv[3])\n",
    "steps = round(pred_time/step)\n",
    "true_pred_time = [step * i for i in range(steps)]\n",
    "true_pred_time.append(pred_time)\n",
    "\n",
    "# finally, risks\n",
    "risk1 = f_get_risk_predictions(sess, model, pat1_data, pat1_data_mi, true_eval_time1, true_pred_time)\n",
    "risk1 = risk1[0]\n",
    "# print(str(true_eval_time1))\n",
    "\n",
    "# plotting\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first, the longitudinal data\n",
    "# first, extract continuous biomarkers\n",
    "cont_list = model_configs['cont_list']\n",
    "\n",
    "# extract x dim info\n",
    "\n",
    "x_dim_cont = input_dims['x_dim_cont']\n",
    "cont_range = range(1, 1 + x_dim_cont)\n",
    "long_data_to_plot1 = pat1_data[0, :, cont_range]\n",
    "\n",
    "\n",
    "# does this patient become HCC? \n",
    "if te_label[pat1_idx, ] == 1: \n",
    "    print('Patient Status: HCC')\n",
    "else: \n",
    "    print('Patient Status: LC')\n",
    "\n",
    "\n",
    "xMAX = max([max(true_eval_time1)])\n",
    "\n",
    "# here, a for-loop\n",
    "fig, ax = plt.subplots(x_dim_cont, 1, figsize=(8,6), sharex = True, sharey = True)\n",
    "for i in range(x_dim_cont): \n",
    "    x1_plot = true_eval_time1\n",
    "    # print(str(long_data_to_plot1.shape))\n",
    "    data_to_plot1_sub = list(long_data_to_plot1[i, range(len(x1_plot))])\n",
    "    # print(str(data_to_plot1_sub))\n",
    "    \n",
    "    # print(str(x1_plot))\n",
    "    # print(str(data_to_plot1_sub))\n",
    "\n",
    "    x1_plot = [i for i in x1_plot]\n",
    "    data_to_plot1_sub = [i for i in data_to_plot1_sub]\n",
    "    ax[i, ].plot(x1_plot, data_to_plot1_sub, 'm.-.', color='blue')\n",
    "    ax[i, ].set_xlim((0, xMAX + 2))\n",
    "fig.text(0.5, 0, 'Time', ha = 'center')\n",
    "\n",
    "# plt.ylabel('Predicted risk')\n",
    "x_plot_sub = []\n",
    "y_plot_sub = []\n",
    "for t in range(len(true_eval_time1) - 1): # here minus 1 since we don't want the last follow-up\n",
    "    x1_plot = [true_eval_time1[t] + i for i in true_pred_time]\n",
    "    y1_plot = list(risk1[0, t, :])\n",
    "    # then subset x_plot's part smaller than true_eval_time[1]\n",
    "    x_plot_sub_temp = [x1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    y_plot_sub_temp = [y1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    # add them to x_plot_sub and y_plot_sub\n",
    "\n",
    "    x_plot_sub = [x_plot_sub, x_plot_sub_temp]\n",
    "    x_plot_sub = [item for sublist in x_plot_sub for item in sublist]\n",
    "    y_plot_sub = [y_plot_sub, y_plot_sub_temp]\n",
    "    y_plot_sub = [item for sublist in y_plot_sub for item in sublist]\n",
    "# print(x_plot_sub)\n",
    "# print(y_plot_sub)\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, xMAX + 2))\n",
    "plt.ylim((0, max(y_plot_sub) * 1.1))\n",
    "plt.xlabel('Time')\n",
    "plt.plot(x_plot_sub, y_plot_sub, 'b')\n",
    "    # add a vertical line\n",
    "for t in range(len(true_eval_time1) - 1): \n",
    "    plt.vlines(true_eval_time1[t + 1], 0, max(y_plot_sub) * 1.1, 'k', '--')\n",
    "    # save\n",
    "\n",
    "fig_dir = target_dir + '/eval/patTraj/'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "fig_name = 'tv_risk_' +  idf + '_Patient_' + str(pat1) + '_horizon_' + str(pred_time) + '_.jpg'\n",
    "plt.savefig(target_dir + '/eval/patTraj/' + fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25f01231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Patient Status: LC\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 0 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11764\\4063742256.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mx1_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx1_plot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mdata_to_plot1_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_to_plot1_sub\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_to_plot1_sub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'm.-.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxMAX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;31m# ax[i, ].set_ylim((0, yMAX * 1.1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 11 is out of bounds for axis 0 with size 11"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x2160 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# okay, now combine everything together...\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from numpy import newaxis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "sys.argv = ['mod', 'PreCar', '191288', '12', '0.01', '1', '1']\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 7:  \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "if tr_data.shape[1] > te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - te_data.shape[1]\n",
    "    for i in range(k): \n",
    "        te_data = np.append(te_data, np.zeros(shape = (te_data.shape[0], 1, te_data.shape[2]), dtype = float), axis = 1) \n",
    "        te_data_mi = np.append(te_data_mi, np.zeros(shape = (te_data_mi.shape[0], 1, te_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "if tr_data.shape[1] > tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - tea_data.shape[1]\n",
    "    for i in range(k): \n",
    "        tea_data = np.append(tea_data, np.zeros(shape = (tea_data.shape[0], 1, tea_data.shape[2]), dtype = float), axis = 1) \n",
    "        tea_data_mi = np.append(tea_data_mi, np.zeros(shape = (tea_data_mi.shape[0], 1, tea_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "# on the other hand what may happen if... \n",
    "if tr_data.shape[1] < te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    te_data = te_data[:, range(tr_data.shape[1]), :]\n",
    "    te_data_mi = te_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "if tr_data.shape[1] < tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    tea_data = tea_data[:, range(tr_data.shape[1]), :]\n",
    "    tea_data_mi = tea_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) < 7: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    # eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[2])\n",
    "    step = float(sys.argv[3])\n",
    "    pat1 = int(sys.argv[4])# {Left or Right}\n",
    "    grp = int(sys.argv[5])\n",
    "else: \n",
    "    # eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    step = float(sys.argv[4])\n",
    "    pat1 = int(sys.argv[5])\n",
    "    grp = int(sys.argv[6])\n",
    "# for this patient... (in test set)\n",
    "# determine which set this is\n",
    "if grp == 1:  \n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "elif grp == 2: \n",
    "    te_id = list(tea_id)\n",
    "    te_data = tea_data\n",
    "    te_data_mi = tea_data_mi\n",
    "    idf = test2_name\n",
    "elif grp == 0: \n",
    "    te_id = list(tr_id)\n",
    "    te_data = tr_data\n",
    "    te_data_mi = tr_data_mi\n",
    "    idf = train_name\n",
    "else: \n",
    "    print(\"The user has not correctly specified which dataset the patient comes from. Assuming from test set 1. \")\n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "\n",
    "# find pat_idx\n",
    "if pat1 in te_id: \n",
    "    pat1_idx = te_id.index(pat1)\n",
    "else: \n",
    "    print(\"The specified patient id was not found in the specified test set. Assuming the use of first patient in test set. \")\n",
    "    pat_idx = 0\n",
    "    \n",
    "\n",
    "\n",
    "pat1_data = te_data[pat1_idx, :, :]\n",
    "pat1_data = pat1_data[newaxis, :, :]\n",
    "pat1_data_mi = te_data_mi[pat1_idx, :, :]\n",
    "pat1_data_mi = pat1_data_mi[newaxis, :, :]\n",
    "\n",
    "\n",
    "# work out the true eval time\n",
    "# the first element is always zero...\n",
    "true_eval_time1 = [0]\n",
    "pat_time_series1 = pat1_data[0, :, 0]\n",
    "pat_time_series1 = [i for i in pat_time_series1 if not i == 0]\n",
    "\n",
    "for i in range(len(pat_time_series1)): \n",
    "    true_eval_time1.append(pat_time_series1[i]) # append time\n",
    "    \n",
    "l1 = len(pat_time_series1)\n",
    "for i in [int(j) for j in list(np.linspace(1, l1, l1))]: \n",
    "    true_eval_time1[i] = true_eval_time1[i] + true_eval_time1[i - 1]\n",
    "\n",
    "# for pred_time, let us still use the external argument\n",
    "# pred_time = float(sys.argv[3])\n",
    "steps = round(pred_time/step)\n",
    "true_pred_time = [step * i for i in range(steps)]\n",
    "true_pred_time.append(pred_time)\n",
    "\n",
    "# finally, risks\n",
    "risk1 = f_get_risk_predictions(sess, model, pat1_data, pat1_data_mi, true_eval_time1, true_pred_time)\n",
    "risk1 = risk1[0]\n",
    "# print(str(true_eval_time1))\n",
    "\n",
    "# plotting\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first, the longitudinal data\n",
    "# first, extract continuous biomarkers\n",
    "cont_list = model_configs['cont_list']\n",
    "\n",
    "# extract x dim info\n",
    "\n",
    "x_dim_cont = input_dims['x_dim_cont']\n",
    "cont_range = range(1, 1 + x_dim_cont)\n",
    "long_data_to_plot1 = pat1_data[0, :, cont_range]\n",
    "\n",
    "\n",
    "# does this patient become HCC? \n",
    "if te_label[pat1_idx, ] == 1: \n",
    "    print('Patient Status: HCC')\n",
    "else: \n",
    "    print('Patient Status: LC')\n",
    "\n",
    "\n",
    "xMAX = max([max(true_eval_time1)])\n",
    "\n",
    "# here, a for-loop\n",
    "log_transform = model_configs['log_transform']\n",
    "cont_list = model_configs['cont_list']\n",
    "reverse_log = 'OFF'\n",
    "fig, ax = plt.subplots(x_dim_cont - 1, 1, figsize=(8, 2.5 * len(cont_list)), sharex = True, sharey = False)\n",
    "for i in range(x_dim_cont): \n",
    "    if not cont_list[i] == 'Age': \n",
    "        # determine yMAX\n",
    "        # for the ith continuous variable, the values were stored in... \n",
    "        # all_vals = tr_data[:, :, i + 1]\n",
    "        # yMAX = np.max(all_vals)\n",
    "        # if reverse_log == 'ON': \n",
    "            # yMAX = np.power(10, yMAX)\n",
    "\n",
    "        x1_plot = true_eval_time1\n",
    "        # print(str(long_data_to_plot1.shape))\n",
    "        data_to_plot1_sub = list(long_data_to_plot1[i, range(len(x1_plot))])\n",
    "        # here, we say we reverse log-transformation if needed\n",
    "        if cont_list[i] in log_transform and reverse_log == 'ON': \n",
    "            data_to_plot1_sub = [np.power(10, j) for j in data_to_plot1_sub]\n",
    "\n",
    "        x1_plot = [i for i in x1_plot]\n",
    "        data_to_plot1_sub = [i for i in data_to_plot1_sub]\n",
    "        ax[i, ].plot(x1_plot, data_to_plot1_sub, 'm.-.', color='blue')\n",
    "        ax[i, ].set_xlim((0, xMAX + 2))\n",
    "        # ax[i, ].set_ylim((0, yMAX * 1.1))\n",
    "fig.text(0.5, 0, 'Time', ha = 'center')\n",
    "\n",
    "# plt.ylabel('Predicted risk')\n",
    "\n",
    "for t in range(len(true_eval_time1) - 1): # here minus 1 since we don't want the last follow-up\n",
    "    x1_plot = [true_eval_time1[t] + i for i in true_pred_time]\n",
    "    y1_plot = list(risk1[0, t, :])\n",
    "    # then subset x_plot's part smaller than true_eval_time[1]\n",
    "    x_plot_sub_temp = [x1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    y_plot_sub_temp = [y1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    # add them to x_plot_sub and y_plot_sub\n",
    "\n",
    "    x_plot_sub = [x_plot_sub, x_plot_sub_temp]\n",
    "    x_plot_sub = [item for sublist in x_plot_sub for item in sublist]\n",
    "    y_plot_sub = [y_plot_sub, y_plot_sub_temp]\n",
    "    y_plot_sub = [item for sublist in y_plot_sub for item in sublist]\n",
    "# print(x_plot_sub)\n",
    "# print(y_plot_sub)\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, xMAX + 2))\n",
    "plt.ylim((0, max(y_plot_sub) * 1.1))\n",
    "plt.xlabel('Time')\n",
    "for t in range(len(true_eval_time1) - 1): # here minus 1 since we don't want the last follow-up\n",
    "    x1_plot = [true_eval_time1[t] + i for i in true_pred_time]\n",
    "    y1_plot = list(risk1[0, t, :])\n",
    "    # then subset x_plot's part smaller than true_eval_time[1]\n",
    "    x_plot_sub_temp = [x1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    y_plot_sub_temp = [y1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    # add them to x_plot_sub and y_plot_sub\n",
    "    plt.vlines(true_eval_time1[t + 1], 0, max(y_plot_sub) * 1.1, 'k', '--')\n",
    "\n",
    "    plt.plot(x_plot_sub_temp, y_plot_sub_temp, 'b')\n",
    "    # add a vertical line\n",
    "plt.show()\n",
    "\n",
    "fig_name = 'tv_risk_' +  idf + '_Patient_' + str(pat1) + '_horizon_' + str(pred_time) + '_.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "652fb391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.30949540e-01  1.13290009e+00  3.50365452e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 6.80000000e+01  6.80000000e+01  6.80000000e+01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.32221950e+00  1.46239815e+00  1.55630262e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.67486123e+00  1.65030762e+00  1.66745305e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.60206010e+00  1.71600343e+00  1.64345278e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.30749625e+00  1.24551291e+00  1.36735611e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 7.55506109e-02  4.53268913e-02  5.30822868e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.35317000e-03  6.05278600e-02  9.75802900e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.20167480e-01  2.51637530e-01  7.84483960e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.73151100e-01  1.38266820e-01  2.21331780e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.20469801e+00 -1.14146166e+00 -6.16426399e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.20469801e+00 -1.14146166e+00  4.34292310e-06  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "+++++++++++++++++++++++++++++++++++++\n",
      "[[8.53001000e+00 1.35800100e+01 3.18900001e+03 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [6.80000000e+01 6.80000000e+01 6.80000000e+01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.10000100e+01 2.90000100e+01 3.60000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [4.73000100e+01 4.47000100e+01 4.65000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [4.00000100e+01 5.20000100e+01 4.40000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [2.03000100e+01 1.76000100e+01 2.33000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [1.19001000e+00 1.11001000e+00 1.13001000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [1.35317000e-03 6.05278600e-02 9.75802900e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.20167480e-01 2.51637530e-01 7.84483960e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.73151100e-01 1.38266820e-01 2.21331780e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.24168700e-02 7.22001900e-02 2.41865320e-01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [6.24168700e-02 7.22001900e-02 1.00001000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "log_transform = model_configs['log_transform']\n",
    "cont_list = model_configs['cont_list']\n",
    "\n",
    "print(long_data_to_plot1)\n",
    "for i in range(x_dim_cont): \n",
    "    if cont_list[i] in log_transform: \n",
    "        temp = [np.power(10, j) for j in long_data_to_plot1[i, :]]\n",
    "        # here, temp[j] == 1 means the original data was zero, so remove then\n",
    "        \n",
    "        long_data_to_plot1[i, :] = temp\n",
    "    else: \n",
    "        temp = [j for j in long_data_to_plot1[i, :]]\n",
    "        long_data_to_plot1[i, :] = temp\n",
    "print('+++++++++++++++++++++++++++++++++++++')\n",
    "print(long_data_to_plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebf91f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "========================================================\n",
      "========================================================\n",
      "========================================================\n",
      "=\n",
      "Used variables: Gender, CNV_score, Afp, Age, Alt, Alb, Plt, Tb, Inr, NF_CT, Fragment_CT, motif_CT, Comb_CT, score\n",
      "Log-transformed variables:  Afp, Alt, Alb, Plt, Tb, Inr, Comb_CT, score\n",
      "=\n",
      "========================================================\n",
      "========================================================\n",
      "Train set internal validation\n",
      "Data: PreCar\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 1.0  eval_time 2.0  eval_time 3.0  \\\n",
      "pred_time 12: event_1       0.871458       0.871477       0.870846   \n",
      "\n",
      "                       eval_time 4.0  eval_time 5.0  eval_time 6.0  \\\n",
      "pred_time 12: event_1       0.870859       0.870374       0.870867   \n",
      "\n",
      "                       eval_time 7.0  eval_time 8.0  eval_time 9.0  \\\n",
      "pred_time 12: event_1       0.870075       0.870128       0.869607   \n",
      "\n",
      "                       eval_time 10.0  ...  eval_time 13.0  eval_time 14.0  \\\n",
      "pred_time 12: event_1        0.869476  ...        0.869302         0.86931   \n",
      "\n",
      "                       eval_time 15.0  eval_time 16.0  eval_time 17.0  \\\n",
      "pred_time 12: event_1        0.869286        0.869294        0.869212   \n",
      "\n",
      "                       eval_time 18.0  eval_time 19.0  eval_time 20.0  \\\n",
      "pred_time 12: event_1        0.868944        0.868952        0.868651   \n",
      "\n",
      "                       eval_time 21.0  eval_time 22.0  \n",
      "pred_time 12: event_1         0.86896        0.869448  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 1.0  eval_time 2.0  eval_time 3.0  \\\n",
      "pred_time 12: event_1       0.028564       0.032151       0.033831   \n",
      "\n",
      "                       eval_time 4.0  eval_time 5.0  eval_time 6.0  \\\n",
      "pred_time 12: event_1       0.034493       0.035082       0.036516   \n",
      "\n",
      "                       eval_time 7.0  eval_time 8.0  eval_time 9.0  \\\n",
      "pred_time 12: event_1       0.037044        0.03753       0.037926   \n",
      "\n",
      "                       eval_time 10.0  ...  eval_time 13.0  eval_time 14.0  \\\n",
      "pred_time 12: event_1        0.037908  ...        0.039313        0.039473   \n",
      "\n",
      "                       eval_time 15.0  eval_time 16.0  eval_time 17.0  \\\n",
      "pred_time 12: event_1        0.039471        0.039455        0.039586   \n",
      "\n",
      "                       eval_time 18.0  eval_time 19.0  eval_time 20.0  \\\n",
      "pred_time 12: event_1        0.040319         0.04262        0.049711   \n",
      "\n",
      "                       eval_time 21.0  eval_time 22.0  \n",
      "pred_time 12: event_1        0.068888        0.093411  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "========================================================\n",
      "========================================================\n",
      "========================================================\n",
      "========================================================\n",
      "=\n",
      "Used variables: Gender, CNV_score, Afp, Age, Alt, Alb, Plt, Tb, Inr, NF_CT, Fragment_CT, motif_CT, Comb_CT, score\n",
      "Log-transformed variables:  Afp, Alt, Alb, Plt, Tb, Inr, Comb_CT, score\n",
      "=\n",
      "========================================================\n",
      "========================================================\n",
      "Train set internal validation\n",
      "Data: PreCar\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 1.0  eval_time 2.0  eval_time 3.0  \\\n",
      "pred_time 12: event_1        0.85784       0.857336       0.853844   \n",
      "\n",
      "                       eval_time 4.0  eval_time 5.0  eval_time 6.0  \\\n",
      "pred_time 12: event_1       0.853639       0.852228       0.853333   \n",
      "\n",
      "                       eval_time 7.0  eval_time 8.0  eval_time 9.0  \\\n",
      "pred_time 12: event_1        0.85335       0.853299       0.853265   \n",
      "\n",
      "                       eval_time 10.0  ...  eval_time 13.0  eval_time 14.0  \\\n",
      "pred_time 12: event_1        0.853265  ...           0.852        0.851915   \n",
      "\n",
      "                       eval_time 15.0  eval_time 16.0  eval_time 17.0  \\\n",
      "pred_time 12: event_1        0.851957        0.851957        0.851753   \n",
      "\n",
      "                       eval_time 18.0  eval_time 19.0  eval_time 20.0  \\\n",
      "pred_time 12: event_1        0.851329        0.851431        0.850769   \n",
      "\n",
      "                       eval_time 21.0  eval_time 22.0  \n",
      "pred_time 12: event_1        0.851278        0.852262  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 1.0  eval_time 2.0  eval_time 3.0  \\\n",
      "pred_time 12: event_1       0.011443        0.01424       0.015703   \n",
      "\n",
      "                       eval_time 4.0  eval_time 5.0  eval_time 6.0  \\\n",
      "pred_time 12: event_1       0.016683       0.017998       0.020627   \n",
      "\n",
      "                       eval_time 7.0  eval_time 8.0  eval_time 9.0  \\\n",
      "pred_time 12: event_1       0.020874       0.022306       0.023823   \n",
      "\n",
      "                       eval_time 10.0  ...  eval_time 13.0  eval_time 14.0  \\\n",
      "pred_time 12: event_1        0.023995  ...        0.027456         0.02821   \n",
      "\n",
      "                       eval_time 15.0  eval_time 16.0  eval_time 17.0  \\\n",
      "pred_time 12: event_1        0.028732        0.029222        0.030062   \n",
      "\n",
      "                       eval_time 18.0  eval_time 19.0  eval_time 20.0  \\\n",
      "pred_time 12: event_1        0.031994        0.036146        0.046807   \n",
      "\n",
      "                       eval_time 21.0  eval_time 22.0  \n",
      "pred_time 12: event_1        0.070912         0.10004  \n",
      "\n",
      "[1 rows x 22 columns]\n",
      "========================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time-varying c-index\n",
    "# here, we vary the evaluation time (horizon)\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar','191288', '1', '12', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# create eval_time array\n",
    "eval_time = np.linspace(1, 22, 7)\n",
    "pred_time = [12]\n",
    "\n",
    "risk_all = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, pred_time, eval_time)\n",
    "\n",
    "for p, p_time in enumerate(pred_time):\n",
    "    pred_horizon = int(p_time)\n",
    "    result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "    for t, t_time in enumerate(eval_time):                \n",
    "        eval_horizon = int(t_time) + pred_horizon\n",
    "        for k in range(num_Event):\n",
    "            result1[k, t] = c_index(risk_all[k][:, p, t], tr_time, (tr_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "            result2[k, t] = brier_score(risk_all[k][:, p, t], tr_time, (tr_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "    \n",
    "    if p == 0:\n",
    "        final1, final2 = result1, result2\n",
    "    else:\n",
    "        final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "        \n",
    "        \n",
    "row_header = []\n",
    "for p_time in pred_time:\n",
    "    for t in range(num_Event):\n",
    "        row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "            \n",
    "col_header = []\n",
    "for t_time in eval_time:\n",
    "    col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "# c-index result\n",
    "df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "# brier-score result\n",
    "df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "feat_list = model_configs['bin_list'] + model_configs['cont_list']\n",
    "\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('=')\n",
    "print('Used variables: ' + \", \".join(feat_list))\n",
    "if len(model_configs['log_transform']) >= 1: \n",
    "    logged_var = [i for i in model_configs['log_transform'] if i in model_configs['cont_list']]\n",
    "    print('Log-transformed variables: ', \", \".join(logged_var))\n",
    "print('=')\n",
    "print('========================================================')\n",
    "\n",
    "### PRINT RESULTS\n",
    "print('========================================================')\n",
    "print('Train set internal validation')\n",
    "print('Data: ' + train_name)\n",
    "print('========================================================')\n",
    "print('--------------------------------------------------------')\n",
    "print('- C-INDEX: ')\n",
    "print(df1)\n",
    "print('--------------------------------------------------------')\n",
    "print('- BRIER-SCORE: ')\n",
    "print(df2)\n",
    "print('========================================================')\n",
    "\n",
    "df1_train = df1\n",
    "df2_train = df2\n",
    "\n",
    "risk_all = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, eval_time)\n",
    "\n",
    "for p, p_time in enumerate(pred_time):\n",
    "    pred_horizon = int(p_time)\n",
    "    result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "    for t, t_time in enumerate(eval_time):                \n",
    "        eval_horizon = int(t_time) + pred_horizon\n",
    "        for k in range(num_Event):\n",
    "            result1[k, t] = c_index(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "            result2[k, t] = brier_score(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "    \n",
    "    if p == 0:\n",
    "        final1, final2 = result1, result2\n",
    "    else:\n",
    "        final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "        \n",
    "        \n",
    "row_header = []\n",
    "for p_time in pred_time:\n",
    "    for t in range(num_Event):\n",
    "        row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "            \n",
    "col_header = []\n",
    "for t_time in eval_time:\n",
    "    col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "# c-index result\n",
    "df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "# brier-score result\n",
    "df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "feat_list = model_configs['bin_list'] + model_configs['cont_list']\n",
    "\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('=')\n",
    "print('Used variables: ' + \", \".join(feat_list))\n",
    "if len(model_configs['log_transform']) >= 1: \n",
    "    logged_var = [i for i in model_configs['log_transform'] if i in model_configs['cont_list']]\n",
    "    print('Log-transformed variables: ', \", \".join(logged_var))\n",
    "print('=')\n",
    "print('========================================================')\n",
    "\n",
    "### PRINT RESULTS\n",
    "print('========================================================')\n",
    "print('Train set internal validation')\n",
    "print('Data: ' + train_name)\n",
    "print('========================================================')\n",
    "print('--------------------------------------------------------')\n",
    "print('- C-INDEX: ')\n",
    "print(df1)\n",
    "print('--------------------------------------------------------')\n",
    "print('- BRIER-SCORE: ')\n",
    "print(df2)\n",
    "print('========================================================')\n",
    "\n",
    "df1_test = df1\n",
    "df2_test = df2\n",
    "\n",
    "# plot c index change with time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "# plt.ylim((0.75, 0.95))\n",
    "plt.plot(eval_time, np.array(df1_train)[0, :], 'r-.p', color = 'blue', label = 'T rain')\n",
    "plt.plot(eval_time, np.array(df1_test)[0, :], 'r-.p', color = 'red', label = 'T est')\n",
    "plt.legend()\n",
    "plt.xlabel('Time horizon (month)')\n",
    "plt.ylabel('c-index')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.plot(eval_time, np.array(df2_train)[0, :], 'r-.p', color = 'blue', label = 'T rain')\n",
    "plt.plot(eval_time, np.array(df2_test)[0, :], 'r-.p', color = 'red', label = 'T est')\n",
    "plt.legend(loc = 2)\n",
    "plt.xlabel('Time horizon (month)')\n",
    "plt.ylabel('Brier score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1caaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "\n",
    "\n",
    "from cmath import inf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "sys.argv = ['xx', './params/onlyBL.json']\n",
    "#time_tag = timepackage.strftime(\"%d_%b_%Y_%H%M%S%f_GMT\", sys_time)\n",
    "time_tag = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "# read in external parameters passed from the console\n",
    "with open(sys.argv[1]) as p: \n",
    "    params = json.load(p)\n",
    "new_parser = params[\"new_parser\"]\n",
    "dataset_info = params[\"dataset_info\"]\n",
    "evaluation_info = params[\"evaluation_info\"]\n",
    "model_configs = params[\"model_configs\"]\n",
    "eval_configs = params[\"eval_configs\"]\n",
    "\n",
    "params[\"new_parser\"][\"time_tag\"] = time_tag\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def recursion(dic): \n",
    "    for key, value in dic.items(): \n",
    "        if isinstance(value, np.floating): \n",
    "            dic[key] = float(value)\n",
    "        elif isinstance(value, dict): \n",
    "            recursion(value)\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "\n",
    "# ### 1. Import Dataset\n",
    "# #####      - Users must prepare dataset in csv format and modify \"import_data.py\" following our examplar \"PBC2\"\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data_mode                   = model_configs[\"data_mode\"]\n",
    "seed                        = model_configs[\"seed\"]\n",
    "\n",
    "##### IMPORT DATASET\n",
    "\"\"\"\n",
    "    num_Category            = max event/censoring time * 1.2\n",
    "    num_Event               = number of evetns i.e. len(np.unique(label))-1\n",
    "    max_length              = maximum number of measurements\n",
    "    x_dim                   = data dimension including delta (1 + num_features)\n",
    "    x_dim_cont              = dim of continuous features\n",
    "    x_dim_bin               = dim of binary features\n",
    "    mask1, mask2, mask3     = used for cause-specific network (FCNet structure)\n",
    "\"\"\"\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "    \n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs[\"bin_list\"], cont_list_in = model_configs[\"cont_list\"], log_list = model_configs[\"log_transform\"])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs[\"bin_list\"], cont_list_in = model_configs[\"cont_list\"], log_list = model_configs[\"log_transform\"])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs[\"bin_list\"], cont_list_in = model_configs[\"cont_list\"], log_list = model_configs[\"log_transform\"])\n",
    "\n",
    "pred_time = evaluation_info[\"pred_time\"] # prediction time (in months)\n",
    "eval_time = evaluation_info[\"eval_time\"] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "\n",
    "mode_path = \"{}\".format(data_mode)\n",
    "\n",
    "if not os.path.exists(mode_path):\n",
    "    os.makedirs(mode_path)\n",
    "\n",
    "file_path = mode_path + \"/\" + time_tag + \"_\" + new_parser[\"reference\"]\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "# ### 2. Set Hyper-Parameters\n",
    "# ##### - Play with your own hyper-parameters!\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "burn_in_mode                = model_configs[\"burnin_mode\"]\n",
    "boost_mode                  = model_configs[\"boost_mode\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# INPUT DIMENSIONS\n",
    "input_dims                  = { \"x_dim\"         : tr_x_dim,\n",
    "                                \"x_dim_cont\"    : tr_x_dim_cont,\n",
    "                                \"x_dim_bin\"     : tr_x_dim_bin,\n",
    "                                \"num_Event\"     : num_Event,\n",
    "                                \"num_Category\"  : num_Category,\n",
    "                                \"max_length\"    : max_length }\n",
    "\n",
    "# NETWORK HYPER-PARMETERS\n",
    "network_settings            = { \"h_dim_RNN\"         : new_parser[\"h_dim_RNN\"],\n",
    "                                \"h_dim_FC\"          : new_parser[\"h_dim_FC\"],\n",
    "                                \"num_layers_RNN\"    : new_parser[\"num_layers_RNN\"],\n",
    "                                \"num_layers_ATT\"    : new_parser[\"num_layers_ATT\"],\n",
    "                                \"num_layers_CS\"     : new_parser[\"num_layers_CS\"],\n",
    "                                \"RNN_type\"          : new_parser[\"RNN_type\"],\n",
    "                                \"FC_active_fn\"      : tf.nn.relu,\n",
    "                                \"RNN_active_fn\"     : tf.nn.tanh,\n",
    "                                \"initial_W\"         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                \"reg_W\"             : new_parser[\"reg_W\"],\n",
    "                                \"reg_W_out\"         : float(new_parser[\"reg_W_out\"])\n",
    "                                 }\n",
    "\n",
    "\n",
    "mb_size           = new_parser[\"mb_size\"]\n",
    "iteration         = new_parser[\"iteration\"]\n",
    "iteration_burn_in = new_parser[\"iteration_burn_in\"]\n",
    "\n",
    "keep_prob         = new_parser[\"keep_prob\"]\n",
    "lr_train          = new_parser[\"lr_train\"]\n",
    "\n",
    "alpha             = new_parser[\"alpha\"]\n",
    "beta              = new_parser[\"beta\"]\n",
    "gamma             = new_parser[\"gamma\"]\n",
    "\n",
    "# SAVE HYPERPARAMETERS\n",
    "log_name = file_path + \"/\" + \"_log.json\"\n",
    "log_file = params\n",
    "\n",
    "recursion(log_file)\n",
    "\n",
    "with open(log_name, \"w\") as f:\n",
    "    json.dump(log_file, f)\n",
    "\n",
    "\n",
    "# ### 3. Split Dataset into Train/Valid/Test Sets\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "(tr_data,va_data, tr_data_mi, va_data_mi, tr_time,va_time, tr_label,va_label, \n",
    " tr_mask1,va_mask1, tr_mask2,va_mask2, tr_mask3,va_mask3) = train_test_split(tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3, test_size=model_configs[\"val_ratio\"], random_state = seed) \n",
    "\n",
    "if boost_mode == \"ON\":\n",
    "    tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3 = f_get_boosted_trainset(tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2dc9e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10.0, 100.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(list(range(10)), list(range(10)))\n",
    "plt.xlim((-10, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a30db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a22a9d348>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758c4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
