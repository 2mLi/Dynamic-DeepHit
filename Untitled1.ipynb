{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7802fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16428\\145838855.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_x_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_x_dim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_x_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_mask1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_mask2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_mask3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_data_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtr_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtr_feat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cont_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mte_x_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_x_dim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_x_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_mask1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_mask2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_mask3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_data_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mte_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_feat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cont_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_x_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_x_dim_cont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_x_dim_bin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_mask1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_mask2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_mask3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_data_mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtea_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtea_feat_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bin_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcont_list_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cont_list'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'log_transform'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\import_data.py\u001b[0m in \u001b[0;36mimport_dataset\u001b[1;34m(path, bin_list_in, cont_list_in, log_list)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     \u001b[0mpat_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m     \u001b[1;33m=\u001b[0m \u001b[0mf_construct_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_org\u001b[0m        \u001b[1;33m=\u001b[0m \u001b[0mf_construct_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_org_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\import_data.py\u001b[0m in \u001b[0;36mf_construct_dataset\u001b[1;34m(df, feat_list)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# pat_info[i,5] = tmp['Patient'][0] # Patient ID as strings. necessary for internal/external validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpat_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2810\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2812\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2814\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[1;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[0;32m   3407\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3408\u001b[0m         \"\"\"\n\u001b[1;32m-> 3409\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3410\u001b[0m         \u001b[1;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3394\u001b[0m         new_data = self._data.take(\n\u001b[1;32m-> 3395\u001b[1;33m             \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3396\u001b[0m         )\n\u001b[0;32m   3397\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m         return self.reindex_indexer(\n\u001b[1;32m-> 1394\u001b[1;33m             \u001b[0mnew_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m         )\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[0;32m   1255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1257\u001b[1;33m             \u001b[0mnew_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_tuple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1258\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m             new_blocks = [\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[1;34m(self, slice_or_indexer, fill_tuple)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m             blknos = algos.take_1d(\n\u001b[1;32m-> 1315\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m             )\n\u001b[0;32m   1317\u001b[0m             blklocs = algos.take_1d(\n",
      "\u001b[1;32mF:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1660\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1661\u001b[0m     )\n\u001b[1;32m-> 1662\u001b[1;33m     \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar', '1', '12', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = tr_label[:, 0]\n",
    "time = tr_time[:, 0]\n",
    "# true label: \n",
    "label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "    PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "'''\n",
    "\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "AUC_name = str(np.round(AUC, decimals = 4))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "    json.dump(tv_tr_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_train = Lspec\n",
    "Lsens_train = Lsens\n",
    "AUC_name_train = AUC_name\n",
    "AUC_UB_train = AUC_UB\n",
    "AUC_LB_train = AUC_LB\n",
    "'''\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "plt.plot(Lspec, Lsens)\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for test: \n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from 0 to 1\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_te)/sum(label_te)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "    PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "'''\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "'''\n",
    "# here, an alternative using the stat_util.py\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_te_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "    json.dump(tv_te_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_test = Lspec\n",
    "Lsens_test = Lsens\n",
    "AUC_name_test = AUC_name\n",
    "AUC_UB_test = AUC_UB\n",
    "AUC_LB_test = AUC_LB\n",
    "\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_general.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"Training tvAUC: \"+ AUC_name_train + \" (\" + AUC_LB_train + \", \" + AUC_UB_train + \")\")\n",
    "plt.text(x = 0.4, y = 0.04, s = \"Testing tvAUC: \"+ AUC_name_test + \" (\" + AUC_LB_test + \", \" + AUC_UB_test + \")\")\n",
    "\n",
    "plt.plot(Lspec_train, Lsens_train, label = 'Train')\n",
    "plt.plot(Lspec_test, Lsens_test, label = 'Test')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "# add a point with PPV about 0.33\n",
    "plt.scatter(Lspec_test[9693], Lsens_test[9693], c = 'red')\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532ba52e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2520\\3474407489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# we use PPV = 0.3 as a cutting point\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# then calculate 12-month HCC rate in high-risk and low-risk groups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcut_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLPPV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mLPPV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcutpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcut_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# okay let us consider this: \n",
    "# we use PPV = 0.3 as a cutting point\n",
    "# then calculate 12-month HCC rate in high-risk and low-risk groups\n",
    "cut_idx = [i for i in range(len(LPPV)) if LPPV[i] >= 0.3][0]\n",
    "cutpoint = r[cut_idx]\n",
    "\n",
    "# high and low-risk group...\n",
    "te_highrisk_label = te_label[risk > cutpoint, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c289e3ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'te_highrisk_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2520\\144309574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PPV: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_highrisk_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_highrisk_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# PPV: 30% patients become HCC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'High-risk pop size: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mte_highrisk_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'High-risk HCC size: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.302\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m43\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'te_highrisk_label' is not defined"
     ]
    }
   ],
   "source": [
    "print('PPV: ' + str(float(sum(te_highrisk_label))/float(len(te_highrisk_label)))) # PPV: 30% patients become HCC\n",
    "print('High-risk pop size: ' + str(int(len(te_highrisk_label))))\n",
    "print('High-risk HCC size: ' + str(int(0.302 * 43)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb48d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff: 0.03978679348900914\n",
      "High risk size: 490\n",
      "High risk HCC: 25.0\n",
      "PPV: 0.05102040816326531\n",
      "Low risk size: 1530\n",
      "Low risk HCC: 9.0\n",
      "NPV: 0.9941176470588236\n"
     ]
    }
   ],
   "source": [
    "# Youden selection of best threshold\n",
    "from operator import add\n",
    "Lsens_tr = tv_tr_log[\"sens\"]\n",
    "Lspec_tr = tv_tr_log[\"spec\"]\n",
    "steps_tr = tv_tr_log['steps']\n",
    "youden = list(map(add, Lsens_tr, [-i for i in Lspec_tr]))\n",
    "max_idx = [i for i in range(len(youden)) if youden[i] >= max(youden)]\n",
    "cutoff = steps_tr[max_idx[0]]\n",
    "\n",
    "# cutoff = 0.045\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "print('Cutoff: ' + str(cutoff))\n",
    "print('High risk size: ' + str(len(highrisk_label)))\n",
    "print('High risk HCC: ' + str(sum(highrisk_label)))\n",
    "print('PPV: ' + str(sum(highrisk_label) / len(highrisk_label)))\n",
    "print('Low risk size: ' + str(len(lowrisk_label)))\n",
    "print('Low risk HCC: ' + str(sum(lowrisk_label)))\n",
    "print('NPV: ' + str(1 - sum(lowrisk_label) / len(lowrisk_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b86e147a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0634850338101387"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "93feabf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High risk size: 3\n",
      "High risk HCC: 2.0\n",
      "PPV: 0.6666666666666666\n",
      "Low risk size: 2017\n",
      "Low risk HCC: 35.0\n",
      "NPV: 0.9826474962816063\n"
     ]
    }
   ],
   "source": [
    "cutoff = 0.06\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "print('High risk size: ' + str(len(highrisk_label)))\n",
    "print('High risk HCC: ' + str(sum(highrisk_label)))\n",
    "print('PPV: ' + str(sum(highrisk_label) / len(highrisk_label)))\n",
    "print('Low risk size: ' + str(len(lowrisk_label)))\n",
    "print('Low risk HCC: ' + str(sum(lowrisk_label)))\n",
    "print('NPV: ' + str(1 - sum(lowrisk_label) / len(lowrisk_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b9ff2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import ndtri\n",
    "\n",
    "\n",
    "def _proportion_confidence_interval(r, n, z):\n",
    "    A = 2*r + z**2\n",
    "    B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "    C = 2*(n + z**2)\n",
    "    return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "    z = -ndtri((1.0-alpha)/2)\n",
    "    sensitivity_point_estimate = TP/(TP + FN)\n",
    "    sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "    specificity_point_estimate = TN/(TN + FP)\n",
    "    specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "    \n",
    "    PPV_point_estimate = TP/(TP + FP)\n",
    "    PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "    NPV_point_estimate = TN / (FN + TN)\n",
    "    NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "    return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a06040d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025777856034599245\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "# Youden selection of best threshold\n",
    "from operator import add\n",
    "Lsens_tr = tv_tr_log[\"sens\"]\n",
    "Lspec_tr = tv_tr_log[\"spec\"]\n",
    "steps_tr = tv_tr_log['steps']\n",
    "youden = list(map(add, Lsens_tr, [-i for i in Lspec_tr]))\n",
    "max_idx = [i for i in range(len(youden)) if youden[i] >= max(youden)]\n",
    "cutoff = steps_tr[max_idx[0]]\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "TP = sum(highrisk_label)\n",
    "FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "FN = sum(lowrisk_label)\n",
    "\n",
    "# sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "\n",
    "\n",
    "res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "print(cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4f04499a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b38c7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.859 (0.81, 0.904)\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.837 (0.752, 0.911)\n",
      "Cutoff: 0.06229167737998068\n",
      "sensitivity: [0.44117647] [[0.28883482], [0.60546101]]\n",
      "specificity: [0.97280967] [[0.96469288], [0.9791009]]\n",
      "PPV: [0.2173913] [[0.13640766], [0.32818296]]\n",
      "NPV: [0.9902614] [[0.98483939], [0.99375659]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.argv = ['mod', 'PreCar', '1', '12', '10000']\n",
    "cutoff_adjustment = +0\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = tr_label[:, 0]\n",
    "time = tr_time[:, 0]\n",
    "# true label: \n",
    "label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "    PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "'''\n",
    "\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "AUC_name = str(np.round(AUC, decimals = 4))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "    json.dump(tv_tr_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_train = Lspec\n",
    "Lsens_train = Lsens\n",
    "AUC_name_train = AUC_name\n",
    "AUC_UB_train = AUC_UB\n",
    "AUC_LB_train = AUC_LB\n",
    "'''\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "plt.plot(Lspec, Lsens)\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for test: \n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label[:, 0]\n",
    "time = te_time[:, 0]\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from 0 to 1\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_te)/sum(label_te)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "    PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "'''\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "'''\n",
    "# here, an alternative using the stat_util.py\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_te_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "    json.dump(tv_te_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_test = Lspec\n",
    "Lsens_test = Lsens\n",
    "AUC_name_test = AUC_name\n",
    "AUC_UB_test = AUC_UB\n",
    "AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "from scipy.special import ndtri\n",
    "from lifelines import KaplanMeierFitter\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "# okay, now use pred_time and eval_time to make something\n",
    "# for this, we need a new step\n",
    "idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "tr_data_sub = tr_data[list(idx), :, :]\n",
    "tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "tr_time_sub = tr_time[idx, :]\n",
    "tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "label = tr_label_sub[:, 0]\n",
    "time = tr_time_sub[:, 0]\n",
    "true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "tr_label_sub = true_tr_label\n",
    "\n",
    "# now, risk\n",
    "risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "# okay given this risk, use log-rank...\n",
    "\n",
    "risk_max = max(risk_sub)\n",
    "risk_min = min(risk_sub)\n",
    "\n",
    "# let us say steps = 100\n",
    "steps = 100\n",
    "step = (risk_max - risk_min)/steps\n",
    "\n",
    "r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "# this should be a working example\n",
    "\n",
    "pvalL = []\n",
    "\n",
    "this_eval_time = eval_time\n",
    "this_pred_time = pred_time\n",
    "\n",
    "for step in r:\n",
    "\n",
    "\n",
    "\n",
    "    # divide pops based on the step\n",
    "    grp1_idx = [i > step for i in risk_sub]\n",
    "    grp0_idx = [i <= step for i in risk_sub]\n",
    "\n",
    "    grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "    grp1_time = tr_time_sub[grp1_idx]\n",
    "    grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "    # new label that is time-dynamic\n",
    "    grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "    grp1_label_new = np.zeros(len(grp1_label))\n",
    "    grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "    grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "    grp0_time = tr_time_sub[grp0_idx]\n",
    "    grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "    grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "    grp0_label_new = np.zeros(len(grp0_label))\n",
    "    grp0_label_new[grp0_label_idx] = 1\n",
    "\n",
    "\n",
    "    # now KM\n",
    "    lrt = logrank_test(grp0_time, grp1_time, grp0_label_new, grp1_label_new)\n",
    "    # print p value, just to check\n",
    "    # print('p value: ' + str(lrt.p_value))\n",
    "    # log p value\n",
    "    pvalL.append(lrt.p_value)\n",
    "\n",
    "min_p = min(pvalL)\n",
    "min_p_idx = [i for i in range(len(r)) if pvalL[i] == min_p][0]\n",
    "min_p_steps = r[min_p_idx]\n",
    "\n",
    "# then use it to calculate sens, spec, PPV and NPV in test set\n",
    "\n",
    "\n",
    "def _proportion_confidence_interval(r, n, z):\n",
    "    A = 2*r + z**2\n",
    "    B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "    C = 2*(n + z**2)\n",
    "    return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "    z = -ndtri((1.0-alpha)/2)\n",
    "    sensitivity_point_estimate = TP/(TP + FN)\n",
    "    sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "    specificity_point_estimate = TN/(TN + FP)\n",
    "    specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "    \n",
    "    PPV_point_estimate = TP/(TP + FP)\n",
    "    PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "    NPV_point_estimate = TN / (FN + TN)\n",
    "    NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "    return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "# Youden selection of best threshold\n",
    "from operator import add\n",
    "cutoff = min_p_steps + cutoff_adjustment * step\n",
    "\n",
    "# use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "# comment this to use the true te_data\n",
    "#te_data = tr_data\n",
    "#te_data_mi = tr_data_mi\n",
    "#te_label = tr_label\n",
    "#te_time = tr_time\n",
    "\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "# we need: label, time\n",
    "label = te_label\n",
    "time = te_time\n",
    "# true label: \n",
    "label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "TP = sum(highrisk_label)\n",
    "FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "FN = sum(lowrisk_label)\n",
    "\n",
    "# sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "# unpack res\n",
    "(sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572b843a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.]\n",
      "[54.]\n",
      "[1932.]\n",
      "[19.]\n",
      "[2020.]\n",
      "[22.32265446]\n",
      "[1.34874584]\n"
     ]
    }
   ],
   "source": [
    "print(TP)\n",
    "print(FP)\n",
    "print(TN)\n",
    "print(FN)\n",
    "print(str(TP + FP + TN + FN))\n",
    "PPV = TP/(TP + FP)\n",
    "NPV = 1 - FN/(FN + TN)\n",
    "print(PPV/(1 - NPV))\n",
    "print(np.log10(PPV/(1-NPV)))\n",
    "# print(np.log10(2.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7ae223c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.864 (0.788, 0.929)\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.746 (0.597, 0.842)\n",
      "Cutoff: 0.039468901546206324\n",
      "sensitivity: [0.] [[0.], [0.2775328]]\n",
      "specificity: [0.99751244] [[0.99418983], [0.99893701]]\n",
      "PPV: [0.] [[0.], [0.43448246]]\n",
      "NPV: [0.99503722] [[0.99088845], [0.99730207]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.735 (0.679, 0.792)\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.652 (0.554, 0.744)\n",
      "Cutoff: 0.13574070332571864\n",
      "sensitivity: [0.05882353] [[0.01628266], [0.19093607]]\n",
      "specificity: [0.99244713] [[0.98757538], [0.99541751]]\n",
      "PPV: [0.11764706] [[0.03287977], [0.34336351]]\n",
      "NPV: [0.98402396] [[0.9775341], [0.98866081]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.735 (0.688, 0.784)\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.664 (0.576, 0.747)\n",
      "Cutoff: 0.23148004956543444\n",
      "sensitivity: [0.10810811] [[0.0428519], [0.24708532]]\n",
      "specificity: [0.98537569] [[0.97907604], [0.98979845]]\n",
      "PPV: [0.12121212] [[0.04816161], [0.27325505]]\n",
      "NPV: [0.98339205] [[0.97676863], [0.98815]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.729 (0.681, 0.776)\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.647 (0.556, 0.733)\n",
      "Cutoff: 0.141956588588655\n",
      "sensitivity: [0.57894737] [[0.42192345], [0.72147499]]\n",
      "specificity: [0.64429869] [[0.62296237], [0.66507674]]\n",
      "PPV: [0.03026135] [[0.02006774], [0.04539305]]\n",
      "NPV: [0.98762568] [[0.97999355], [0.99236895]]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.73 (0.681, 0.777)\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.637 (0.545, 0.724)\n",
      "Cutoff: 0.062268829829990865\n",
      "sensitivity: [1.] [[0.91033315], [1.]]\n",
      "specificity: [0.01060071] [[0.00694395], [0.01615183]]\n",
      "PPV: [0.01950975] [[0.01430442], [0.02655825]]\n",
      "NPV: [1.] [[0.84536098], [1.]]\n"
     ]
    }
   ],
   "source": [
    "# for loop our interested range\n",
    "eval_times = [1, 7, 13, 19, 25]\n",
    "for eval_time in eval_times: \n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['mod', 'PreCar', eval_time, '12', '10000']\n",
    "    cutoff_adjustment = +0\n",
    "\n",
    "    _EPSILON = 1e-08\n",
    "\n",
    "    #### <<< Warning suppression>>> ###\n",
    "    # import warnings\n",
    "    # warnings.filterwarnings('deprecated')\n",
    "    #### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import random\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import time as timepackage\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import import_data as impt\n",
    "\n",
    "    from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "    from utils_eval             import c_index, brier_score\n",
    "    from utils_log              import save_logging, load_logging\n",
    "    from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "    def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "        \"\"\"\n",
    "            predictions based on the prediction time.\n",
    "            create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "        \"\"\"\n",
    "        new_data    = np.zeros(np.shape(data))\n",
    "        new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "        meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "        for i in range(np.shape(data)[0]):\n",
    "            last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "            new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "            new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "        return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "    def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "\n",
    "        pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "        _, num_Event, num_Category = np.shape(pred)\n",
    "\n",
    "        risk_all = {}\n",
    "        for k in range(num_Event):\n",
    "            risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            ### PREDICTION\n",
    "            pred_horizon = int(p_time)\n",
    "            pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):\n",
    "                eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "                # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "                risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "                risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "\n",
    "                for k in range(num_Event):\n",
    "                    risk_all[k][:, p, t] = risk[:, k]\n",
    "\n",
    "        return risk_all\n",
    "\n",
    "    ## cmd args: \n",
    "    # now only one argument is needed\n",
    "    # this will be something like \"PreCar\"\n",
    "    # and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### the following codes read model training results plus needed data from Model_Training.py\n",
    "    # and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "    '''\n",
    "    saver.restore(sess, sys.argv[1])\n",
    "    with open(sys.argv[2]) as p: \n",
    "        params = json.load(p)\n",
    "    '''\n",
    "\n",
    "    # argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "    # argv[2], if left empty, will choose the most recent log\n",
    "    # if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "    data_mode_name = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # to do so, for now lets just use max argument\n",
    "        # firstly, take out all log.json documents\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        # logs is a list of all available logs; find the most recent one...\n",
    "        target_dir = data_mode_name + '/' + max(logs)\n",
    "        print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "    else: \n",
    "        # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        matched = [i for i in logs if sys.argv[2] in i]\n",
    "        if len(matched) >= 2: \n",
    "            print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "            matched = max(matched)\n",
    "        target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "    # read log\n",
    "    with open(target_dir + '/' + '_log.json') as p: \n",
    "        params = json.load(p)\n",
    "    mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "    # print(type(params))\n",
    "    new_parser = params['new_parser']\n",
    "    dataset_info = params['dataset_info']\n",
    "    evaluation_info = params['evaluation_info']\n",
    "    model_configs = params['model_configs']\n",
    "    eval_configs = params['eval_configs']\n",
    "    time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "    dirs = dataset_info\n",
    "    test_dir = []\n",
    "    data_mode = data_mode_name\n",
    "    for key in list(dirs.keys()): \n",
    "        if key == data_mode: \n",
    "            train_dir = dirs[key]\n",
    "        else: \n",
    "            test_dir.append(dirs[key])\n",
    "\n",
    "    (tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "    eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "    _, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "    max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "    #####\n",
    "\n",
    "    # A little treat: print name (in dict) of dataset\n",
    "    def get_key(val):\n",
    "        for key, value in dataset_info.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "\n",
    "        return \"There is no such Key\"\n",
    "\n",
    "    train_name = get_key(train_dir)\n",
    "    test1_name = get_key(test_dir[0])\n",
    "    test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "    #####\n",
    "\n",
    "    input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                    'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                    'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                    'num_Event'     : num_Event,\n",
    "                                    'num_Category'  : num_Category,\n",
    "                                    'max_length'    : max_length }\n",
    "\n",
    "    network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                    'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                    'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                    'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                    'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                    'RNN_type'          : new_parser['RNN_type'],\n",
    "                                    'FC_active_fn'      : tf.nn.relu,\n",
    "                                    'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                    'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                    'reg_W'             : new_parser['reg_W'],\n",
    "                                    'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                     }\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, mod_dir)\n",
    "\n",
    "    # By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "    # Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "    # here, we superseded eval_time and pred_time: \n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "        eval_time = float(sys.argv[2])\n",
    "        pred_time = float(sys.argv[3])\n",
    "        steps = int(sys.argv[4])\n",
    "    else: \n",
    "        eval_time = float(sys.argv[3])\n",
    "        pred_time = float(sys.argv[4])\n",
    "        steps = int(sys.argv[5])\n",
    "\n",
    "    # for train...\n",
    "    risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = tr_label[:, 0]\n",
    "    time = tr_time[:, 0]\n",
    "    # true label: \n",
    "    label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "        PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    AUC_name = str(np.round(AUC, decimals = 4))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "        json.dump(tv_tr_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_train = Lspec\n",
    "    Lsens_train = Lsens\n",
    "    AUC_name_train = AUC_name\n",
    "    AUC_UB_train = AUC_UB\n",
    "    AUC_LB_train = AUC_LB\n",
    "    '''\n",
    "    Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(6)\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "    plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    plt.plot(Lspec, Lsens)\n",
    "    # plt.show()\n",
    "    plt.savefig(Fig_name)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # for test: \n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label[:, 0]\n",
    "    time = te_time[:, 0]\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from 0 to 1\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_te)/sum(label_te)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "        PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    '''\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    '''\n",
    "    # here, an alternative using the stat_util.py\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_te_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "        json.dump(tv_te_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_test = Lspec\n",
    "    Lsens_test = Lsens\n",
    "    AUC_name_test = AUC_name\n",
    "    AUC_UB_test = AUC_UB\n",
    "    AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "    from scipy.special import ndtri\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "    # okay, now use pred_time and eval_time to make something\n",
    "    # for this, we need a new step\n",
    "    idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "    tr_data_sub = tr_data[list(idx), :, :]\n",
    "    tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "    tr_time_sub = tr_time[idx, :]\n",
    "    tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "    label = tr_label_sub[:, 0]\n",
    "    time = tr_time_sub[:, 0]\n",
    "    true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    tr_label_sub = true_tr_label\n",
    "\n",
    "    # now, risk\n",
    "    risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "    risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "    # okay given this risk, use log-rank...\n",
    "\n",
    "    risk_max = max(risk_sub)\n",
    "    risk_min = min(risk_sub)\n",
    "\n",
    "    # let us say steps = 100\n",
    "    steps = 100\n",
    "    step = (risk_max - risk_min)/steps\n",
    "\n",
    "    r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "    # this should be a working example\n",
    "\n",
    "    pvalL = []\n",
    "\n",
    "    this_eval_time = eval_time\n",
    "    this_pred_time = pred_time\n",
    "\n",
    "    for step in r:\n",
    "\n",
    "\n",
    "\n",
    "        # divide pops based on the step\n",
    "        grp1_idx = [i > step for i in risk_sub]\n",
    "        grp0_idx = [i <= step for i in risk_sub]\n",
    "\n",
    "        grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "        grp1_time = tr_time_sub[grp1_idx]\n",
    "        grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "        # new label that is time-dynamic\n",
    "        grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "        grp1_label_new = np.zeros(len(grp1_label))\n",
    "        grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "        grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "        grp0_time = tr_time_sub[grp0_idx]\n",
    "        grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "        grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "        grp0_label_new = np.zeros(len(grp0_label))\n",
    "        grp0_label_new[grp0_label_idx] = 1\n",
    "\n",
    "\n",
    "        # now KM\n",
    "        lrt = logrank_test(grp0_time, grp1_time, grp0_label_new, grp1_label_new)\n",
    "        # print p value, just to check\n",
    "        # print('p value: ' + str(lrt.p_value))\n",
    "        # log p value\n",
    "        pvalL.append(lrt.p_value)\n",
    "\n",
    "    min_p = min(pvalL)\n",
    "    min_p_idx = [i for i in range(len(r)) if pvalL[i] == min_p][0]\n",
    "    min_p_steps = r[min_p_idx]\n",
    "\n",
    "    # then use it to calculate sens, spec, PPV and NPV in test set\n",
    "\n",
    "\n",
    "    def _proportion_confidence_interval(r, n, z):\n",
    "        A = 2*r + z**2\n",
    "        B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "        C = 2*(n + z**2)\n",
    "        return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "    def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "        z = -ndtri((1.0-alpha)/2)\n",
    "        sensitivity_point_estimate = TP/(TP + FN)\n",
    "        sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "        specificity_point_estimate = TN/(TN + FP)\n",
    "        specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "\n",
    "        PPV_point_estimate = TP/(TP + FP)\n",
    "        PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "        NPV_point_estimate = TN / (FN + TN)\n",
    "        NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "        return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "    from math import sqrt\n",
    "\n",
    "    # Youden selection of best threshold\n",
    "    from operator import add\n",
    "    cutoff = min_p_steps + cutoff_adjustment * step\n",
    "\n",
    "    # use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "    # comment this to use the true te_data\n",
    "    #te_data = tr_data\n",
    "    #te_data_mi = tr_data_mi\n",
    "    #te_label = tr_label\n",
    "    #te_time = tr_time\n",
    "\n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label\n",
    "    time = te_time\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "    highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "    lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "    TP = sum(highrisk_label)\n",
    "    FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "    TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "    FN = sum(lowrisk_label)\n",
    "\n",
    "    # sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "    res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "    print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "    # unpack res\n",
    "    (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "    print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "    print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "    print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "    print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9cf0271",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.859 (0.81, 0.904)\n",
      "Time-varying AUC at landmark 1.0 with horizon 12.0: 0.837 (0.752, 0.911)\n",
      "In train set... \n",
      "Cutoff: 0.06753163365637883\n",
      "sensitivity: [0.07142857] [[0.03089422], [0.15655412]]\n",
      "specificity: [0.99903754] [[0.99649738], [0.99973602]]\n",
      "PPV: [0.71428571] [[0.35893445], [0.91778108]]\n",
      "NPV: [0.96964035] [[0.96148953], [0.9761089]]\n",
      "Enrichment ratio: [23.52747253]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 7.0 with horizon 12.0: 0.868 (0.827, 0.906)\n",
      "Time-varying AUC at landmark 7.0 with horizon 12.0: 0.827 (0.747, 0.899)\n",
      "In train set... \n",
      "Cutoff: 0.20040974135398865\n",
      "sensitivity: [0.20430108] [[0.13487642], [0.297185]]\n",
      "specificity: [0.99513382] [[0.99106534], [0.99735463]]\n",
      "PPV: [0.65517241] [[0.47345104], [0.80059281]]\n",
      "NPV: [0.96507787] [[0.9563816], [0.97209094]]\n",
      "Enrichment ratio: [18.76095061]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 13.0 with horizon 12.0: 0.864 (0.825, 0.902)\n",
      "Time-varying AUC at landmark 13.0 with horizon 12.0: 0.808 (0.719, 0.888)\n",
      "In train set... \n",
      "Cutoff: 0.295194588957727\n",
      "sensitivity: [0.28865979] [[0.20790256], [0.38551864]]\n",
      "specificity: [0.99268649] [[0.98796797], [0.9955629]]\n",
      "PPV: [0.65116279] [[0.50171782], [0.7758141]]\n",
      "NPV: [0.9672209] [[0.95872276], [0.97401687]]\n",
      "Enrichment ratio: [19.86518369]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9140\\2866371978.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m         \u001b[0mPPV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_pred\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 254\u001b[1;33m         \u001b[0mNPV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlabel_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    255\u001b[0m         \u001b[0mLsens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         \u001b[0mLspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for loop our interested range\n",
    "eval_times = [1, 7, 13, 19, 25]\n",
    "adj_range = [0.41,0.44,0.44,0.44,0.19]\n",
    "for eval_time, adj in zip(eval_times, adj_range): \n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['mod', 'PreCar', eval_time, '12', '10000']\n",
    "    cutoff_adjustment = adj\n",
    "\n",
    "    _EPSILON = 1e-08\n",
    "\n",
    "    #### <<< Warning suppression>>> ###\n",
    "    # import warnings\n",
    "    # warnings.filterwarnings('deprecated')\n",
    "    #### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import random\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import time as timepackage\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import import_data as impt\n",
    "\n",
    "    from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "    from utils_eval             import c_index, brier_score\n",
    "    from utils_log              import save_logging, load_logging\n",
    "    from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "    def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "        \"\"\"\n",
    "            predictions based on the prediction time.\n",
    "            create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "        \"\"\"\n",
    "        new_data    = np.zeros(np.shape(data))\n",
    "        new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "        meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "        for i in range(np.shape(data)[0]):\n",
    "            last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "            new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "            new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "        return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "    def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "\n",
    "        pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "        _, num_Event, num_Category = np.shape(pred)\n",
    "\n",
    "        risk_all = {}\n",
    "        for k in range(num_Event):\n",
    "            risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            ### PREDICTION\n",
    "            pred_horizon = int(p_time)\n",
    "            pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):\n",
    "                eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "                # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "                risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "                risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "\n",
    "                for k in range(num_Event):\n",
    "                    risk_all[k][:, p, t] = risk[:, k]\n",
    "\n",
    "        return risk_all\n",
    "\n",
    "    ## cmd args: \n",
    "    # now only one argument is needed\n",
    "    # this will be something like \"PreCar\"\n",
    "    # and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### the following codes read model training results plus needed data from Model_Training.py\n",
    "    # and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "    '''\n",
    "    saver.restore(sess, sys.argv[1])\n",
    "    with open(sys.argv[2]) as p: \n",
    "        params = json.load(p)\n",
    "    '''\n",
    "\n",
    "    # argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "    # argv[2], if left empty, will choose the most recent log\n",
    "    # if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "    data_mode_name = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # to do so, for now lets just use max argument\n",
    "        # firstly, take out all log.json documents\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        # logs is a list of all available logs; find the most recent one...\n",
    "        target_dir = data_mode_name + '/' + max(logs)\n",
    "        print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "    else: \n",
    "        # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        matched = [i for i in logs if sys.argv[2] in i]\n",
    "        if len(matched) >= 2: \n",
    "            print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "            matched = max(matched)\n",
    "        target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "    # read log\n",
    "    with open(target_dir + '/' + '_log.json') as p: \n",
    "        params = json.load(p)\n",
    "    mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "    # print(type(params))\n",
    "    new_parser = params['new_parser']\n",
    "    dataset_info = params['dataset_info']\n",
    "    evaluation_info = params['evaluation_info']\n",
    "    model_configs = params['model_configs']\n",
    "    eval_configs = params['eval_configs']\n",
    "    time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "    dirs = dataset_info\n",
    "    test_dir = []\n",
    "    data_mode = data_mode_name\n",
    "    for key in list(dirs.keys()): \n",
    "        if key == data_mode: \n",
    "            train_dir = dirs[key]\n",
    "        else: \n",
    "            test_dir.append(dirs[key])\n",
    "\n",
    "    (tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "    eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "    _, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "    max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "    #####\n",
    "\n",
    "    # A little treat: print name (in dict) of dataset\n",
    "    def get_key(val):\n",
    "        for key, value in dataset_info.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "\n",
    "        return \"There is no such Key\"\n",
    "\n",
    "    train_name = get_key(train_dir)\n",
    "    test1_name = get_key(test_dir[0])\n",
    "    test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "    #####\n",
    "\n",
    "    input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                    'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                    'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                    'num_Event'     : num_Event,\n",
    "                                    'num_Category'  : num_Category,\n",
    "                                    'max_length'    : max_length }\n",
    "\n",
    "    network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                    'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                    'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                    'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                    'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                    'RNN_type'          : new_parser['RNN_type'],\n",
    "                                    'FC_active_fn'      : tf.nn.relu,\n",
    "                                    'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                    'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                    'reg_W'             : new_parser['reg_W'],\n",
    "                                    'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                     }\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, mod_dir)\n",
    "\n",
    "    # By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "    # Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "    # here, we superseded eval_time and pred_time: \n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "        eval_time = float(sys.argv[2])\n",
    "        pred_time = float(sys.argv[3])\n",
    "        steps = int(sys.argv[4])\n",
    "    else: \n",
    "        eval_time = float(sys.argv[3])\n",
    "        pred_time = float(sys.argv[4])\n",
    "        steps = int(sys.argv[5])\n",
    "\n",
    "    # for train...\n",
    "    risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = tr_label[:, 0]\n",
    "    time = tr_time[:, 0]\n",
    "    # true label: \n",
    "    label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "        PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    AUC_name = str(np.round(AUC, decimals = 4))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "        json.dump(tv_tr_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_train = Lspec\n",
    "    Lsens_train = Lsens\n",
    "    AUC_name_train = AUC_name\n",
    "    AUC_UB_train = AUC_UB\n",
    "    AUC_LB_train = AUC_LB\n",
    "    '''\n",
    "    Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(6)\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "    plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    plt.plot(Lspec, Lsens)\n",
    "    # plt.show()\n",
    "    plt.savefig(Fig_name)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # for test: \n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label[:, 0]\n",
    "    time = te_time[:, 0]\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from 0 to 1\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_te)/sum(label_te)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "        PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    '''\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    '''\n",
    "    # here, an alternative using the stat_util.py\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_te_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "        json.dump(tv_te_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_test = Lspec\n",
    "    Lsens_test = Lsens\n",
    "    AUC_name_test = AUC_name\n",
    "    AUC_UB_test = AUC_UB\n",
    "    AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "    from scipy.special import ndtri\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "    # okay, now use pred_time and eval_time to make something\n",
    "    # for this, we need a new step\n",
    "    idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "    tr_data_sub = tr_data[list(idx), :, :]\n",
    "    tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "    tr_time_sub = tr_time[idx, :]\n",
    "    tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "    label = tr_label_sub[:, 0]\n",
    "    time = tr_time_sub[:, 0]\n",
    "    true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    tr_label_sub = true_tr_label\n",
    "\n",
    "    # now, risk\n",
    "    risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "    risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "    # okay given this risk, use log-rank...\n",
    "\n",
    "    risk_max = max(risk_sub)\n",
    "    risk_min = min(risk_sub)\n",
    "\n",
    "    # let us say steps = 100\n",
    "    steps = 100\n",
    "    step = (risk_max - risk_min)/steps\n",
    "\n",
    "    r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "    # this should be a working example\n",
    "\n",
    "    youdenL = []\n",
    "\n",
    "    this_eval_time = eval_time\n",
    "    this_pred_time = pred_time\n",
    "    from math import sqrt\n",
    "    from operator import add\n",
    "    def _proportion_confidence_interval(r, n, z):\n",
    "        A = 2*r + z**2\n",
    "        B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "        C = 2*(n + z**2)\n",
    "        return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "    def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "        z = -ndtri((1.0-alpha)/2)\n",
    "        sensitivity_point_estimate = TP/(TP + FN)\n",
    "        sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "        specificity_point_estimate = TN/(TN + FP)\n",
    "        specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "\n",
    "        PPV_point_estimate = TP/(TP + FP)\n",
    "        PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "        NPV_point_estimate = TN / (FN + TN)\n",
    "        NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "        return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "    \n",
    "    for step in r: \n",
    "        # divide pops based on the step\n",
    "        grp1_idx = [i > step for i in risk_sub]\n",
    "        grp0_idx = [i <= step for i in risk_sub]\n",
    "        \n",
    "        grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "        grp1_time = tr_time_sub[grp1_idx]\n",
    "        grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "        # new label that is time-dynamic\n",
    "        grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "        grp1_label_new = np.zeros(len(grp1_label))\n",
    "        grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "        grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "        grp0_time = tr_time_sub[grp0_idx]\n",
    "        grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "        grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "        grp0_label_new = np.zeros(len(grp0_label))\n",
    "        grp0_label_new[grp0_label_idx] = 1\n",
    "        \n",
    "        # calculate sens and spec, then append to youdenL\n",
    "        risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])[0]\n",
    "        highrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] > step]\n",
    "        lowrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] <= step]\n",
    "\n",
    "        TP = sum(highrisk_label)\n",
    "        FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "        TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "        FN = sum(lowrisk_label)\n",
    "        res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "        (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "        \n",
    "        youdenL.append(sens + spec - 1)\n",
    "    \n",
    "\n",
    "    min_youden = max(youdenL)\n",
    "    min_idx = [i for i in range(len(r)) if youdenL[i] == min_youden][0]\n",
    "    cutoff_proto = r[min_idx]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Youden selection of best threshold\n",
    "    print('In train set... ')\n",
    "    cutoff = cutoff_proto + cutoff_adjustment * step\n",
    "\n",
    "    # use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "    # comment this to use the true te_data\n",
    "    te_data = tr_data\n",
    "    te_data_mi = tr_data_mi\n",
    "    te_label = tr_label\n",
    "    te_time = tr_time\n",
    "\n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label\n",
    "    time = te_time\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "    highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "    lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "    TP = sum(highrisk_label)\n",
    "    FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "    TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "    FN = sum(lowrisk_label)\n",
    "\n",
    "    # sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "    res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "    print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "    # unpack res\n",
    "    (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "    print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "    print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "    print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "    print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')\n",
    "    \n",
    "     # before printing enrichment ratio, modify NPV if it equals zero\n",
    "    if 1-NPV == 0: \n",
    "        NPV = NPV - 0.0001\n",
    "    print('Enrichment ratio: ' + str(PPV/(1-NPV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0859dfbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\utils_network.py:24: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\utils_network.py:29: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\class_DeepLongitudinal.py:20: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.864 (0.788, 0.929)\n",
      "Time-varying AUC at landmark 1.0 with horizon 6.0: 0.746 (0.597, 0.842)\n",
      "In test set...\n",
      "Cutoff: 0.009462962578982114\n",
      "sensitivity: [0.9] [[0.59584997], [0.98212379]]\n",
      "specificity: [0.60199005] [[0.58041612], [0.62317488]]\n",
      "PPV: [0.01112485] [[0.00586368], [0.02100682]]\n",
      "NPV: [0.99917424] [[0.99533737], [0.99985422]]\n",
      "Enrichment ratio: [13.47218789]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.735 (0.679, 0.792)\n",
      "Time-varying AUC at landmark 7.0 with horizon 6.0: 0.652 (0.554, 0.744)\n",
      "In test set...\n",
      "Cutoff: 0.07168296158313751\n",
      "sensitivity: [0.35294118] [[0.21487921], [0.52086037]]\n",
      "specificity: [0.81268882] [[0.7949317], [0.82923863]]\n",
      "PPV: [0.03125] [[0.01796504], [0.05382063]]\n",
      "NPV: [0.98655257] [[0.97972268], [0.99110287]]\n",
      "Enrichment ratio: [2.32386364]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.735 (0.688, 0.784)\n",
      "Time-varying AUC at landmark 13.0 with horizon 6.0: 0.664 (0.576, 0.747)\n",
      "In test set...\n",
      "Cutoff: 0.09939419385045767\n",
      "sensitivity: [0.75675676] [[0.59882708], [0.86638647]]\n",
      "specificity: [0.52950076] [[0.50749644], [0.551391]]\n",
      "PPV: [0.02913632] [[0.02023425], [0.04178782]]\n",
      "NPV: [0.99150142] [[0.98392743], [0.9955225]]\n",
      "Enrichment ratio: [3.42837322]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.729 (0.681, 0.776)\n",
      "Time-varying AUC at landmark 19.0 with horizon 6.0: 0.647 (0.556, 0.733)\n",
      "In test set...\n",
      "Cutoff: 0.12713213317096234\n",
      "sensitivity: [0.73684211] [[0.57991154], [0.85028379]]\n",
      "specificity: [0.49798184] [[0.47599488], [0.5199766]]\n",
      "PPV: [0.02737048] [[0.01900362], [0.03927359]]\n",
      "NPV: [0.98996991] [[0.98163574], [0.99454285]]\n",
      "Enrichment ratio: [2.72883675]\n",
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.73 (0.681, 0.777)\n",
      "Time-varying AUC at landmark 25.0 with horizon 6.0: 0.637 (0.545, 0.724)\n",
      "In test set...\n",
      "Cutoff: 0.16168523099273444\n",
      "sensitivity: [0.64102564] [[0.48418149], [0.77257915]]\n",
      "specificity: [0.54921757] [[0.52723235], [0.57101227]]\n",
      "PPV: [0.02723312] [[0.01851324], [0.03989318]]\n",
      "NPV: [0.98729583] [[0.97878864], [0.99241749]]\n",
      "Enrichment ratio: [2.14363523]\n"
     ]
    }
   ],
   "source": [
    "# for loop our interested range\n",
    "eval_times = [1, 7, 13, 19, 25]\n",
    "adj_range = [0, 0, 0, 0, 0]\n",
    "for eval_time, adj in zip(eval_times, adj_range): \n",
    "    import sys\n",
    "\n",
    "    sys.argv = ['mod', 'PreCar', eval_time, '6', '10000']\n",
    "    cutoff_adjustment = adj\n",
    "\n",
    "    _EPSILON = 1e-08\n",
    "\n",
    "    #### <<< Warning suppression>>> ###\n",
    "    # import warnings\n",
    "    # warnings.filterwarnings('deprecated')\n",
    "    #### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import tensorflow as tf\n",
    "    import random\n",
    "    import os\n",
    "    import sys\n",
    "    import json\n",
    "    import time as timepackage\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    import import_data as impt\n",
    "\n",
    "    from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "    from utils_eval             import c_index, brier_score\n",
    "    from utils_log              import save_logging, load_logging\n",
    "    from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "    def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "        \"\"\"\n",
    "            predictions based on the prediction time.\n",
    "            create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "        \"\"\"\n",
    "        new_data    = np.zeros(np.shape(data))\n",
    "        new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "        meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "        for i in range(np.shape(data)[0]):\n",
    "            last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "            new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "            new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "        return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "    def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "\n",
    "        pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "        _, num_Event, num_Category = np.shape(pred)\n",
    "\n",
    "        risk_all = {}\n",
    "        for k in range(num_Event):\n",
    "            risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "\n",
    "        for p, p_time in enumerate(pred_time):\n",
    "            ### PREDICTION\n",
    "            pred_horizon = int(p_time)\n",
    "            pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "            for t, t_time in enumerate(eval_time):\n",
    "                eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "                # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "                risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "                risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "\n",
    "                for k in range(num_Event):\n",
    "                    risk_all[k][:, p, t] = risk[:, k]\n",
    "\n",
    "        return risk_all\n",
    "\n",
    "    ## cmd args: \n",
    "    # now only one argument is needed\n",
    "    # this will be something like \"PreCar\"\n",
    "    # and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### the following codes read model training results plus needed data from Model_Training.py\n",
    "    # and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "    '''\n",
    "    saver.restore(sess, sys.argv[1])\n",
    "    with open(sys.argv[2]) as p: \n",
    "        params = json.load(p)\n",
    "    '''\n",
    "\n",
    "    # argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "    # argv[2], if left empty, will choose the most recent log\n",
    "    # if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "    data_mode_name = sys.argv[1]\n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # to do so, for now lets just use max argument\n",
    "        # firstly, take out all log.json documents\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        # logs is a list of all available logs; find the most recent one...\n",
    "        target_dir = data_mode_name + '/' + max(logs)\n",
    "        print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "    else: \n",
    "        # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "        logs = os.listdir(data_mode_name)\n",
    "        matched = [i for i in logs if sys.argv[2] in i]\n",
    "        if len(matched) >= 2: \n",
    "            print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "            matched = max(matched)\n",
    "        target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "    # read log\n",
    "    with open(target_dir + '/' + '_log.json') as p: \n",
    "        params = json.load(p)\n",
    "    mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "    # print(type(params))\n",
    "    new_parser = params['new_parser']\n",
    "    dataset_info = params['dataset_info']\n",
    "    evaluation_info = params['evaluation_info']\n",
    "    model_configs = params['model_configs']\n",
    "    eval_configs = params['eval_configs']\n",
    "    time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "    dirs = dataset_info\n",
    "    test_dir = []\n",
    "    data_mode = data_mode_name\n",
    "    for key in list(dirs.keys()): \n",
    "        if key == data_mode: \n",
    "            train_dir = dirs[key]\n",
    "        else: \n",
    "            test_dir.append(dirs[key])\n",
    "\n",
    "    (tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    (tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "    pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "    eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "    _, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "    max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "    #####\n",
    "\n",
    "    # A little treat: print name (in dict) of dataset\n",
    "    def get_key(val):\n",
    "        for key, value in dataset_info.items():\n",
    "             if val == value:\n",
    "                 return key\n",
    "\n",
    "        return \"There is no such Key\"\n",
    "\n",
    "    train_name = get_key(train_dir)\n",
    "    test1_name = get_key(test_dir[0])\n",
    "    test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "    #####\n",
    "\n",
    "    input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                    'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                    'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                    'num_Event'     : num_Event,\n",
    "                                    'num_Category'  : num_Category,\n",
    "                                    'max_length'    : max_length }\n",
    "\n",
    "    network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                    'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                    'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                    'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                    'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                    'RNN_type'          : new_parser['RNN_type'],\n",
    "                                    'FC_active_fn'      : tf.nn.relu,\n",
    "                                    'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                    'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                    'reg_W'             : new_parser['reg_W'],\n",
    "                                    'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                     }\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "\n",
    "    model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, mod_dir)\n",
    "\n",
    "    # By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "    # Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "    # here, we superseded eval_time and pred_time: \n",
    "\n",
    "    if len(sys.argv) < 6: \n",
    "        # this means no argv[2] is given; we use the most recent log\n",
    "        # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "        eval_time = float(sys.argv[2])\n",
    "        pred_time = float(sys.argv[3])\n",
    "        steps = int(sys.argv[4])\n",
    "    else: \n",
    "        eval_time = float(sys.argv[3])\n",
    "        pred_time = float(sys.argv[4])\n",
    "        steps = int(sys.argv[5])\n",
    "\n",
    "    # for train...\n",
    "    risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = tr_label[:, 0]\n",
    "    time = tr_time[:, 0]\n",
    "    # true label: \n",
    "    label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "        PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "    '''\n",
    "\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    AUC_name = str(np.round(AUC, decimals = 4))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "    '''\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "        json.dump(tv_tr_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_train = Lspec\n",
    "    Lsens_train = Lsens\n",
    "    AUC_name_train = AUC_name\n",
    "    AUC_UB_train = AUC_UB\n",
    "    AUC_LB_train = AUC_LB\n",
    "    '''\n",
    "    Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "    f = plt.figure()\n",
    "    f.set_figwidth(6)\n",
    "    f.set_figheight(6)\n",
    "    plt.xlabel('1 - Specificity')\n",
    "    plt.ylabel('Sensitivity')\n",
    "    plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "    plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    plt.plot(Lspec, Lsens)\n",
    "    # plt.show()\n",
    "    plt.savefig(Fig_name)\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "    # for test: \n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = risk[0][:, 0, 0]\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label[:, 0]\n",
    "    time = te_time[:, 0]\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    # we need a discretised scale from 0 to 1\n",
    "    min_risk = min(risk)\n",
    "    max_risk = max(risk)\n",
    "    step = (max_risk - min_risk)/steps #step width\n",
    "    r = [min_risk + step * i for i in range(steps)]\n",
    "    r = r[1:len(r)]\n",
    "\n",
    "\n",
    "    # at each scale, calculate sens and spec\n",
    "    Lsens = []\n",
    "    Lspec = []\n",
    "    LPPV = []\n",
    "    LNPV = []\n",
    "    for ri in r: \n",
    "        label_pred = risk >= ri # predicted label\n",
    "        sens = sum(label_pred * label_te)/sum(label_te)\n",
    "        spec = 1 - sum((1 - label_pred) * (1 - label_te))/sum(1 - label_te)\n",
    "        PPV = sum(label_pred * label_te)/sum(label_pred)\n",
    "        NPV = sum((1 - label_pred) * (1 - label_te))/sum(1 - label_pred)\n",
    "        Lsens.append(sens)\n",
    "        Lspec.append(spec)\n",
    "        LPPV.append(PPV)\n",
    "        LNPV.append(NPV)\n",
    "    # print(Lsens)\n",
    "    # print(Lspec)\n",
    "\n",
    "    # get AUC with trapezium rule\n",
    "    '''\n",
    "    rL = len(r) - 1\n",
    "    AUCL = []\n",
    "    for i in list(range(rL)): \n",
    "        AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "\n",
    "    AUC = - sum(AUCL)\n",
    "    '''\n",
    "    # here, an alternative using the stat_util.py\n",
    "\n",
    "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "    import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "    score, ci_lower, ci_upper, scores = stat_util.score_ci(label_te, risk, score_fun=roc_auc_score,seed=142857)\n",
    "\n",
    "\n",
    "    AUC_name = str(np.round(score, decimals = 3))\n",
    "    AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "    AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "    print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "    # store results\n",
    "    # firstly, deal with the fucking disgusting float32 stuff\n",
    "    Lspec_to_save = [float(i) for i in Lspec]\n",
    "    Lsens_to_save = [float(i) for i in Lsens]\n",
    "    AUC = score\n",
    "    AUC_to_save = float(AUC)\n",
    "    r_to_save = [float(i) for i in r]\n",
    "    tv_te_log = {\"spec\": Lspec_to_save, \n",
    "    \"sens\": Lsens_to_save, \n",
    "    \"AUC\": AUC_to_save, \n",
    "    \"steps\": r_to_save}\n",
    "\n",
    "    # eval_path = target_dir + '/eval'\n",
    "    tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "    if not os.path.exists(tvROC_dir):\n",
    "        os.makedirs(tvROC_dir)\n",
    "\n",
    "    landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "    with open(tvROC_dir + landmark_horizon_lab + '_log_test.json', \"w\") as f:\n",
    "        json.dump(tv_te_log, f)\n",
    "\n",
    "    # plot bit\n",
    "    Lspec_test = Lspec\n",
    "    Lsens_test = Lsens\n",
    "    AUC_name_test = AUC_name\n",
    "    AUC_UB_test = AUC_UB\n",
    "    AUC_LB_test = AUC_LB\n",
    "\n",
    "\n",
    "    from scipy.special import ndtri\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    import matplotlib.pyplot as plt\n",
    "    from lifelines.statistics import logrank_test\n",
    "\n",
    "\n",
    "    # okay, now use pred_time and eval_time to make something\n",
    "    # for this, we need a new step\n",
    "    idx = [i > eval_time for i in list(tr_time[:, 0])]\n",
    "    tr_data_sub = tr_data[list(idx), :, :]\n",
    "    tr_data_mi_sub = tr_data_mi[list(idx), :, :]\n",
    "    tr_time_sub = tr_time[idx, :]\n",
    "    tr_label_sub = tr_label[idx, :]\n",
    "\n",
    "    label = tr_label_sub[:, 0]\n",
    "    time = tr_time_sub[:, 0]\n",
    "    true_tr_label = label * (time <= pred_time + eval_time)\n",
    "\n",
    "    tr_label_sub = true_tr_label\n",
    "\n",
    "    # now, risk\n",
    "    risk_sub = f_get_risk_predictions(sess, model, tr_data_sub, tr_data_mi_sub, [pred_time], [eval_time])\n",
    "    risk_sub = list(risk_sub[0][:, 0, 0])\n",
    "\n",
    "    # okay given this risk, use log-rank...\n",
    "\n",
    "    risk_max = max(risk_sub)\n",
    "    risk_min = min(risk_sub)\n",
    "\n",
    "    # let us say steps = 100\n",
    "    steps = 100\n",
    "    step = (risk_max - risk_min)/steps\n",
    "\n",
    "    r = [risk_min + (i + 1) * step for i in range(steps - 1)]\n",
    "    # this should be a working example\n",
    "\n",
    "    youdenL = []\n",
    "\n",
    "    this_eval_time = eval_time\n",
    "    this_pred_time = pred_time\n",
    "    from math import sqrt\n",
    "    from operator import add\n",
    "    def _proportion_confidence_interval(r, n, z):\n",
    "        A = 2*r + z**2\n",
    "        B = z*sqrt(z**2 + 4*r*(1 - r/n))\n",
    "        C = 2*(n + z**2)\n",
    "        return ((A-B)/C, (A+B)/C)\n",
    "\n",
    "    def sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=0.95):\n",
    "        z = -ndtri((1.0-alpha)/2)\n",
    "        sensitivity_point_estimate = TP/(TP + FN)\n",
    "        sensitivity_confidence_interval = _proportion_confidence_interval(TP, TP + FN, z)\n",
    "        specificity_point_estimate = TN/(TN + FP)\n",
    "        specificity_confidence_interval = _proportion_confidence_interval(TN, TN + FP, z)\n",
    "\n",
    "        PPV_point_estimate = TP/(TP + FP)\n",
    "        PPV_CI = _proportion_confidence_interval(TP, TP+FP, z)\n",
    "        NPV_point_estimate = TN / (FN + TN)\n",
    "        NPV_CI = _proportion_confidence_interval(TN, FN + TN, z)\n",
    "        return sensitivity_point_estimate, specificity_point_estimate, PPV_point_estimate, NPV_point_estimate, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI\n",
    "\n",
    "    \n",
    "    for step in r: \n",
    "        # divide pops based on the step\n",
    "        grp1_idx = [i > step for i in risk_sub]\n",
    "        grp0_idx = [i <= step for i in risk_sub]\n",
    "        \n",
    "        grp1_data = tr_data_sub[grp1_idx, :, :]\n",
    "        grp1_time = tr_time_sub[grp1_idx]\n",
    "        grp1_label = tr_label_sub[grp1_idx]\n",
    "\n",
    "        # new label that is time-dynamic\n",
    "        grp1_label_idx = [i for i in range(len(grp1_label)) if grp1_label[i] == 1 and grp1_time[i] < this_eval_time + this_pred_time]\n",
    "        grp1_label_new = np.zeros(len(grp1_label))\n",
    "        grp1_label_new[grp1_label_idx] = 1\n",
    "\n",
    "        grp0_data = tr_data_sub[grp0_idx, :, :]\n",
    "        grp0_time = tr_time_sub[grp0_idx]\n",
    "        grp0_label = tr_label_sub[grp0_idx]\n",
    "\n",
    "        grp0_label_idx = [i for i in range(len(grp0_label)) if grp0_label[i] == 1 and grp0_time[i] < this_eval_time + this_pred_time]\n",
    "        grp0_label_new = np.zeros(len(grp0_label))\n",
    "        grp0_label_new[grp0_label_idx] = 1\n",
    "        \n",
    "        # calculate sens and spec, then append to youdenL\n",
    "        risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])[0]\n",
    "        highrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] > step]\n",
    "        lowrisk_label = [label_tr[i] for i in range(len(label_tr)) if risk[i] <= step]\n",
    "\n",
    "        TP = sum(highrisk_label)\n",
    "        FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "        TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "        FN = sum(lowrisk_label)\n",
    "        res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "        (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "        \n",
    "        youdenL.append(sens + spec - 1)\n",
    "    \n",
    "\n",
    "    min_youden = max(youdenL)\n",
    "    min_idx = [i for i in range(len(r)) if youdenL[i] == min_youden][0]\n",
    "    cutoff_proto = r[min_idx]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # Youden selection of best threshold\n",
    "    \n",
    "    cutoff = cutoff_proto + cutoff_adjustment * step\n",
    "    print('In test set...')\n",
    "    # use the cutoff to separate highrisk and lowrisk among test people\n",
    "\n",
    "    # comment this to use the true te_data\n",
    "    #te_data = tr_data\n",
    "    #te_data_mi = tr_data_mi\n",
    "    #te_label = tr_label\n",
    "    #te_time = tr_time\n",
    "\n",
    "    risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "    risk = list(risk[0][:, 0, 0])\n",
    "\n",
    "    # we need: label, time\n",
    "    label = te_label\n",
    "    time = te_time\n",
    "    # true label: \n",
    "    label_te = label * (time <= pred_time + eval_time)\n",
    "\n",
    "\n",
    "    highrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] > cutoff]\n",
    "    lowrisk_label = [label_te[i] for i in range(len(label_te)) if risk[i] <= cutoff]\n",
    "\n",
    "    TP = sum(highrisk_label)\n",
    "    FP = len(highrisk_label) - sum(highrisk_label)\n",
    "\n",
    "    TN = len(lowrisk_label) - sum(lowrisk_label)\n",
    "    FN = sum(lowrisk_label)\n",
    "\n",
    "    # sensitivity_point_estimate, specificity_point_estimate, PPV, NPV, sensitivity_confidence_interval, specificity_confidence_interval, PPV_CI, NPV_CI = sensitivity_and_specificity_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "\n",
    "    res= sensitivity_and_specificity_and_PPV_NPV_with_confidence_intervals(TP, FP, FN, TN, alpha=.95)\n",
    "    print('Cutoff: ' + str(cutoff))\n",
    "\n",
    "    # unpack res\n",
    "    (sens, spec, PPV, NPV, (sens_LB, sens_UB), (spec_LB, spec_UB), (PPV_LB, PPV_UB), (NPV_LB, NPV_UB)) = res\n",
    "    print('sensitivity: ' + str(sens) + ' [' + str(sens_LB) + ', ' + str(sens_UB) + ']')\n",
    "    print('specificity: ' + str(spec) + ' [' + str(spec_LB) + ', ' + str(spec_UB) + ']')\n",
    "    print('PPV: ' + str(PPV) + ' [' + str(PPV_LB) + ', ' + str(PPV_UB) + ']')\n",
    "    print('NPV: ' + str(NPV) + ' [' + str(NPV_LB) + ', ' + str(NPV_UB) + ']')\n",
    "    \n",
    "    # before printing enrichment ratio, modify NPV if it equals zero\n",
    "    if 1-NPV == 0: \n",
    "        NPV = NPV - 0.0001\n",
    "    print('Enrichment ratio: ' + str(PPV/(1-NPV)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3fe4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n"
     ]
    }
   ],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar', '1', '6', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "\n",
    "eval_path = target_dir + '/eval'\n",
    "\n",
    "tr_risk = list(risk[0][:, 0, 0])\n",
    "tr_export = {\"Risk\": tr_risk, \n",
    "       \"ID\": tr_id, \n",
    "            \"Times\": tr_time[:, 0], \n",
    "            \"Status\": tr_label[:, 0]}\n",
    "\n",
    "tr_df = pd.DataFrame(tr_export)\n",
    "\n",
    "tr_df.to_csv(eval_path + '/' + 'exported_risk_tr.csv', index = False)\n",
    "\n",
    "# test\n",
    "risk = f_get_risk_predictions(sess, model, te_data, te_data_mi, [pred_time], [eval_time])\n",
    "\n",
    "eval_path = target_dir + '/eval'\n",
    "\n",
    "te_risk = list(risk[0][:, 0, 0])\n",
    "te_export = {\"Risk\": te_risk, \n",
    "       \"ID\": te_id, \n",
    "            \"Times\": te_time[:, 0], \n",
    "            \"Status\": te_label[:, 0]}\n",
    "\n",
    "te_df = pd.DataFrame(te_export)\n",
    "\n",
    "te_df.to_csv(eval_path + '/' + 'exported_risk_te.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89d3249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# risk[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "296b7b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Time-varying AUC at landmark 1.0 with horizon 18.0: 0.891 (0.854, 0.927)\n"
     ]
    }
   ],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar', '1', '18', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    steps = int(sys.argv[4])\n",
    "else: \n",
    "    eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[4])\n",
    "    steps = int(sys.argv[5])\n",
    "\n",
    "# for train...\n",
    "risk = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, [pred_time], [eval_time])\n",
    "risk = risk[0][:, 0, 0]\n",
    "\n",
    "# we need: label, time\n",
    "label = tr_label[:, 0]\n",
    "time = tr_time[:, 0]\n",
    "# true label: \n",
    "label_tr = label * (time <= pred_time + eval_time)\n",
    "\n",
    "# we need a discretised scale from min(risk) to max(risk) in Train set\n",
    "min_risk = min(risk)\n",
    "max_risk = max(risk)\n",
    "step = (max_risk - min_risk)/steps #step width\n",
    "r = [min_risk + step * i for i in range(steps)]\n",
    "r = r[1:len(r)]\n",
    "\n",
    "\n",
    "# at each scale, calculate sens and spec\n",
    "Lsens = []\n",
    "Lspec = []\n",
    "LPPV = []\n",
    "LNPV = []\n",
    "for ri in r: \n",
    "    label_pred = risk >= ri # predicted label\n",
    "    sens = sum(label_pred * label_tr)/sum(label_tr)\n",
    "    spec = 1 - sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_tr)\n",
    "    PPV = sum(label_pred * label_tr)/sum(label_pred)\n",
    "    NPV = sum((1 - label_pred) * (1 - label_tr))/sum(1 - label_pred)\n",
    "    Lsens.append(sens)\n",
    "    Lspec.append(spec)\n",
    "    LPPV.append(PPV)\n",
    "    LNPV.append(NPV)\n",
    "\n",
    "# print(Lsens)\n",
    "# print(Lspec)\n",
    "\n",
    "# get AUC with trapezium rule\n",
    "rL = len(r) - 1\n",
    "AUCL = []\n",
    "for i in list(range(rL)): \n",
    "    AUCL.append(1/2 * (Lsens[i] + Lsens[i + 1]) * (Lspec[i + 1] - Lspec[i]))\n",
    "'''\n",
    "\n",
    "\n",
    "AUC = - sum(AUCL)\n",
    "AUC_name = str(np.round(AUC, decimals = 4))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import stat_util    #Compute AUC with 95% confidence interval\n",
    "\n",
    "score, ci_lower, ci_upper, scores = stat_util.score_ci(label_tr, risk, score_fun=roc_auc_score,seed = 142857)\n",
    "\n",
    "\n",
    "AUC_name = str(np.round(score, decimals = 3))\n",
    "AUC_UB = str(np.round(ci_upper, decimals = 3))\n",
    "AUC_LB = str(np.round(ci_lower, decimals = 3))\n",
    "print(\"Time-varying AUC at landmark \" + str(eval_time) + \" with horizon \" + str(pred_time) + \": \" + AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "# store results\n",
    "# firstly, deal with the fucking disgusting float32 stuff\n",
    "Lspec_to_save = [float(i) for i in Lspec]\n",
    "Lsens_to_save = [float(i) for i in Lsens]\n",
    "AUC = score\n",
    "AUC_to_save = float(AUC)\n",
    "r_to_save = [float(i) for i in r]\n",
    "tv_tr_log = {\"spec\": Lspec_to_save, \n",
    "\"sens\": Lsens_to_save, \n",
    "\"AUC\": AUC_to_save, \n",
    "\"steps\": r_to_save}\n",
    "\n",
    "# eval_path = target_dir + '/eval'\n",
    "tvROC_dir = target_dir + '/eval/tvROC/'\n",
    "\n",
    "if not os.path.exists(tvROC_dir):\n",
    "    os.makedirs(tvROC_dir)\n",
    "\n",
    "landmark_horizon_lab = 'L' + str(eval_time) + 'H' + str(pred_time)\n",
    "with open(tvROC_dir + landmark_horizon_lab + '_log_train.json', \"w\") as f:\n",
    "    json.dump(tv_tr_log, f)\n",
    "\n",
    "# plot bit\n",
    "Lspec_train = Lspec\n",
    "Lsens_train = Lsens\n",
    "AUC_name_train = AUC_name\n",
    "AUC_UB_train = AUC_UB\n",
    "AUC_LB_train = AUC_LB\n",
    "'''\n",
    "Fig_name = tvROC_dir + landmark_horizon_lab + '_tvROC_train.png'\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "f = plt.figure()\n",
    "f.set_figwidth(6)\n",
    "f.set_figheight(6)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Landmark Time: ' + str(eval_time) + '; Horizon Time: '+ str(pred_time))\n",
    "plt.text(x = 0.4, y = 0.1, s = \"tvAUC: \"+ AUC_name + \" (\" + AUC_LB + \", \" + AUC_UB + \")\")\n",
    "\n",
    "plt.plot(Lspec, Lsens)\n",
    "# plt.show()\n",
    "plt.savefig(Fig_name)\n",
    "'''\n",
    "\n",
    "pred_time = [12, 24, 36]\n",
    "eval_time = 0\n",
    "\n",
    "# for test: \n",
    "risk_tr = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, pred_time, [eval_time])\n",
    "risk_te = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, [eval_time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51a39e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2148, 3, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "risk_tr[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9e87f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-year: \n",
      "High-risk mean incidence: 3.406%\n",
      "Low-risk mean incidence: 1.854%\n",
      "Two-year: \n",
      "High-risk mean incidence: 2.085%\n",
      "Low-risk mean incidence: 0.111%\n",
      "Three-year: \n",
      "High-risk mean incidence: 23.93%\n",
      "Low-risk mean incidence: 18.59%\n"
     ]
    }
   ],
   "source": [
    "# 12-month\n",
    "cutoff_12mth = 0.032424807325005536\n",
    "risk_tr_12mth = list(risk_tr[0][:, 0, 0])\n",
    "risk_te_12mth = list(risk_te[0][:, 0, 0])\n",
    "highrisk_12mth_tr = np.mean([i for i in risk_tr_12mth if i > cutoff_12mth])\n",
    "lowrisk_12mth_tr = np.mean([i for i in risk_tr_12mth if i <= cutoff_12mth])\n",
    "print('One-year: ')\n",
    "print('High-risk mean incidence: ' + str(highrisk_12mth_tr * 100)[0:5] + '%')\n",
    "print('Low-risk mean incidence: ' + str(lowrisk_12mth_tr * 100)[0:5] + '%')\n",
    "\n",
    "\n",
    "# 24-month\n",
    "cutoff_24mth = 0.01406039503752254\n",
    "risk_tr_24mth = list(risk_tr[0][:, 1, 0])\n",
    "risk_te_24mth = list(risk_te[0][:, 1, 0])\n",
    "highrisk_24mth_tr = np.mean([i for i in risk_tr_24mth if i > cutoff_24mth])\n",
    "lowrisk_24mth_tr = np.mean([i for i in risk_tr_24mth if i <= cutoff_24mth])\n",
    "print('Two-year: ')\n",
    "print('High-risk mean incidence: ' + str(highrisk_24mth_tr * 100)[0:5] + '%')\n",
    "print('Low-risk mean incidence: ' + str(lowrisk_24mth_tr * 100)[0:5] + '%')\n",
    "\n",
    "# 36-month\n",
    "cutoff_36mth = 0.19262462258338928\n",
    "risk_tr_36mth = list(risk_tr[0][:, 2, 0])\n",
    "risk_te_36mth = list(risk_te[0][:, 2, 0])\n",
    "highrisk_36mth_tr = np.mean([i for i in risk_tr_36mth if i > cutoff_36mth])\n",
    "lowrisk_36mth_tr = np.mean([i for i in risk_tr_36mth if i <= cutoff_36mth])\n",
    "print('Three-year: ')\n",
    "print('High-risk mean incidence: ' + str(highrisk_36mth_tr * 100)[0:5] + '%')\n",
    "print('Low-risk mean incidence: ' + str(lowrisk_36mth_tr * 100)[0:5] + '%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fd075f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in risk_tr if i <= cutoff_12mth]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "738373a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = str(lowrisk_12mth_tr * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87f2c403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.854'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe5144b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the most recent _log.json by default, since no specification is given. \n",
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-04-25_01-23-17-994216_my_aMAP_model_with_CNVs_FS_aMAP/model\n",
      "Patient Status: LC\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# okay, now combine everything together...\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from numpy import newaxis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "sys.argv = ['mod', 'PreCar', '6', '0.01', '1', '1']\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 7:  \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "if tr_data.shape[1] > te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - te_data.shape[1]\n",
    "    for i in range(k): \n",
    "        te_data = np.append(te_data, np.zeros(shape = (te_data.shape[0], 1, te_data.shape[2]), dtype = float), axis = 1) \n",
    "        te_data_mi = np.append(te_data_mi, np.zeros(shape = (te_data_mi.shape[0], 1, te_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "if tr_data.shape[1] > tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - tea_data.shape[1]\n",
    "    for i in range(k): \n",
    "        tea_data = np.append(tea_data, np.zeros(shape = (tea_data.shape[0], 1, tea_data.shape[2]), dtype = float), axis = 1) \n",
    "        tea_data_mi = np.append(tea_data_mi, np.zeros(shape = (tea_data_mi.shape[0], 1, tea_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "# on the other hand what may happen if... \n",
    "if tr_data.shape[1] < te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    te_data = te_data[:, range(tr_data.shape[1]), :]\n",
    "    te_data_mi = te_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "if tr_data.shape[1] < tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    tea_data = tea_data[:, range(tr_data.shape[1]), :]\n",
    "    tea_data_mi = tea_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) < 7: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    # eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[2])\n",
    "    step = float(sys.argv[3])\n",
    "    pat1 = int(sys.argv[4])# {Left or Right}\n",
    "    grp = int(sys.argv[5])\n",
    "else: \n",
    "    # eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    step = float(sys.argv[4])\n",
    "    pat1 = int(sys.argv[5])\n",
    "    grp = int(sys.argv[6])\n",
    "# for this patient... (in test set)\n",
    "# determine which set this is\n",
    "if grp == 1:  \n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "elif grp == 2: \n",
    "    te_id = list(tea_id)\n",
    "    te_data = tea_data\n",
    "    te_data_mi = tea_data_mi\n",
    "    idf = test2_name\n",
    "elif grp == 0: \n",
    "    te_id = list(tr_id)\n",
    "    te_data = tr_data\n",
    "    te_data_mi = tr_data_mi\n",
    "    idf = train_name\n",
    "else: \n",
    "    print(\"The user has not correctly specified which dataset the patient comes from. Assuming from test set 1. \")\n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "\n",
    "# find pat_idx\n",
    "if pat1 in te_id: \n",
    "    pat1_idx = te_id.index(pat1)\n",
    "else: \n",
    "    print(\"The specified patient id was not found in the specified test set. Assuming the use of first patient in test set. \")\n",
    "    pat_idx = 0\n",
    "    \n",
    "\n",
    "\n",
    "pat1_data = te_data[pat1_idx, :, :]\n",
    "pat1_data = pat1_data[newaxis, :, :]\n",
    "pat1_data_mi = te_data_mi[pat1_idx, :, :]\n",
    "pat1_data_mi = pat1_data_mi[newaxis, :, :]\n",
    "\n",
    "\n",
    "# work out the true eval time\n",
    "# the first element is always zero...\n",
    "true_eval_time1 = [0]\n",
    "pat_time_series1 = pat1_data[0, :, 0]\n",
    "pat_time_series1 = [i for i in pat_time_series1 if not i == 0]\n",
    "\n",
    "for i in range(len(pat_time_series1)): \n",
    "    true_eval_time1.append(pat_time_series1[i]) # append time\n",
    "    \n",
    "l1 = len(pat_time_series1)\n",
    "for i in [int(j) for j in list(np.linspace(1, l1, l1))]: \n",
    "    true_eval_time1[i] = true_eval_time1[i] + true_eval_time1[i - 1]\n",
    "\n",
    "# for pred_time, let us still use the external argument\n",
    "# pred_time = float(sys.argv[3])\n",
    "steps = round(pred_time/step)\n",
    "true_pred_time = [step * i for i in range(steps)]\n",
    "true_pred_time.append(pred_time)\n",
    "\n",
    "# finally, risks\n",
    "risk1 = f_get_risk_predictions(sess, model, pat1_data, pat1_data_mi, true_eval_time1, true_pred_time)\n",
    "risk1 = risk1[0]\n",
    "# print(str(true_eval_time1))\n",
    "\n",
    "# plotting\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first, the longitudinal data\n",
    "# first, extract continuous biomarkers\n",
    "cont_list = model_configs['cont_list']\n",
    "\n",
    "# extract x dim info\n",
    "\n",
    "x_dim_cont = input_dims['x_dim_cont']\n",
    "cont_range = range(1, 1 + x_dim_cont)\n",
    "long_data_to_plot1 = pat1_data[0, :, cont_range]\n",
    "\n",
    "\n",
    "# does this patient become HCC? \n",
    "if te_label[pat1_idx, ] == 1: \n",
    "    print('Patient Status: HCC')\n",
    "else: \n",
    "    print('Patient Status: LC')\n",
    "\n",
    "\n",
    "xMAX = max([max(true_eval_time1)])\n",
    "\n",
    "# here, a for-loop\n",
    "fig, ax = plt.subplots(x_dim_cont, 1, figsize=(8,6), sharex = True, sharey = True)\n",
    "for i in range(x_dim_cont): \n",
    "    x1_plot = true_eval_time1\n",
    "    # print(str(long_data_to_plot1.shape))\n",
    "    data_to_plot1_sub = list(long_data_to_plot1[i, range(len(x1_plot))])\n",
    "    # print(str(data_to_plot1_sub))\n",
    "    \n",
    "    # print(str(x1_plot))\n",
    "    # print(str(data_to_plot1_sub))\n",
    "\n",
    "    x1_plot = [i for i in x1_plot]\n",
    "    data_to_plot1_sub = [i for i in data_to_plot1_sub]\n",
    "    ax[i, ].plot(x1_plot, data_to_plot1_sub, 'm.-.', color='blue')\n",
    "    ax[i, ].set_xlim((0, xMAX + 2))\n",
    "fig.text(0.5, 0, 'Time', ha = 'center')\n",
    "\n",
    "# plt.ylabel('Predicted risk')\n",
    "x_plot_sub = []\n",
    "y_plot_sub = []\n",
    "for t in range(len(true_eval_time1) - 1): # here minus 1 since we don't want the last follow-up\n",
    "    x1_plot = [true_eval_time1[t] + i for i in true_pred_time]\n",
    "    y1_plot = list(risk1[0, t, :])\n",
    "    # then subset x_plot's part smaller than true_eval_time[1]\n",
    "    x_plot_sub_temp = [x1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    y_plot_sub_temp = [y1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    # add them to x_plot_sub and y_plot_sub\n",
    "\n",
    "    x_plot_sub = [x_plot_sub, x_plot_sub_temp]\n",
    "    x_plot_sub = [item for sublist in x_plot_sub for item in sublist]\n",
    "    y_plot_sub = [y_plot_sub, y_plot_sub_temp]\n",
    "    y_plot_sub = [item for sublist in y_plot_sub for item in sublist]\n",
    "# print(x_plot_sub)\n",
    "# print(y_plot_sub)\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, xMAX + 2))\n",
    "plt.ylim((0, max(y_plot_sub) * 1.1))\n",
    "plt.xlabel('Time')\n",
    "plt.plot(x_plot_sub, y_plot_sub, 'b')\n",
    "    # add a vertical line\n",
    "for t in range(len(true_eval_time1) - 1): \n",
    "    plt.vlines(true_eval_time1[t + 1], 0, max(y_plot_sub) * 1.1, 'k', '--')\n",
    "    # save\n",
    "\n",
    "fig_dir = target_dir + '/eval/patTraj/'\n",
    "\n",
    "if not os.path.exists(fig_dir):\n",
    "    os.makedirs(fig_dir)\n",
    "\n",
    "fig_name = 'tv_risk_' +  idf + '_Patient_' + str(pat1) + '_horizon_' + str(pred_time) + '_.jpg'\n",
    "plt.savefig(target_dir + '/eval/patTraj/' + fig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25f01231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "Patient Status: LC\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 11 is out of bounds for axis 0 with size 11",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11764\\4063742256.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mx1_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx1_plot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[0mdata_to_plot1_sub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_to_plot1_sub\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_to_plot1_sub\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'm.-.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxMAX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m         \u001b[1;31m# ax[i, ].set_ylim((0, yMAX * 1.1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 11 is out of bounds for axis 0 with size 11"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAZ+CAYAAACrZjY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5hV5bn+8e8jMAgoioCNIqgowYLiBkVFiYhBLOixl9hi0GM06i9GjTHxGGNJPZiIIehBYzQQCwI2xIYYBWWwo1JExQEi1UITZnh+fzwzmc0wNJ291+y178917Wtmrb1mz7Muyz1vWe9r7o6IiIikyxZJFyAiIiJ1TwEvIiKSQgp4ERGRFFLAi4iIpJACXkREJIUU8CIiIinUMOkC6lKrVq28Q4cOSZchIiKSN1OmTFno7q1rnk9VwHfo0IHS0tKkyxAREckbM/uktvPqohcREUkhBbyIiEgK5TzgzayfmU0zs5lmdm0t7w8ws7fN7E0zKzWzQzf1Z0VERLK98grceitMnJh0JcnL6Ri8mTUABgN9gTJgspmNcff3si57Dhjj7m5m+wIPAp038WdFRKTITZ8Oo0fD3/8OH3wAa9ZASQk89xz07Jl0dcnJdQu+BzDT3We5+ypgBDAg+wJ3X+rVO940A3xTf1ZERIrX3/4GXbrAnnvC1VfDwoVQXg4VFbBqFYwfn3SFycp1wLcBPs06Lqs8txYzO9HMPgCeAC7YzJ8dWNm1X7pgwYI6K1xEROqX6dPhoovgs8/iePVq2Hln+NOf4OOP4ZFHYMstoUGDaMH37p1ktcnL9WNyVsu5dfandfdHgUfN7DDgJuDIzfjZocBQgEwmo71vRURSYvFiePJJ2GMP6NEDVq6Ef/wDTjkFdtgBLrwwXlV22SW65cePj3Av5u55yH3AlwHtso7bAnPXd7G7TzCz3cys1eb+rIiIFL6PP47x9NGjYcKE6G6/7LII+H32iW74xo3X//M9eyrYq+Q64CcDncysIzAHOB04M/sCM9sd+LBykl03oARYBHy+sZ8VEZHC5g5vvgmjRkWov/VWnO/SJcbVBwyA7t3jnNmGw13WltOAd/dyM7sUeBpoAAxz96lmdnHl+0OAk4BzzGw1sAI4rXLSXa0/m8t6RUQk99wjrAH694exY+P4kEPgd7+LUO/UKdka08CqJ7AXvkwm41qqVkSk/rrnHvjlL2HGjJgQN2IErFgBxx4LrddZTV02hZlNcfdMzfOpWoteRETqj7lzYcyY6Hq/6SbIZKBjRzjySPjiiwj4009Pusr0UsCLiEidcIf33queJPfaa3F+t92g6inm3r31+Fq+KOBFROQbW7MGXn45An3UKPjwwzjfowfcfHOMp3fpUj3mLvmjgBcRkc2yfHkE+T77xPEpp8Qz6336wFVXwfHHxwI0kiwFvIiIbNSSJdCiRXx/7rnw6qvwySewxRbw+OOxGE3z5snWKGtTwIuISK1mzKgeT3/lFfjoI2jfHn7yE1i6tPpxt8w687elPlDAi4gIEOPppaXVi868V7l3Z9eucP31sb47wEEHJVejbDoFvIhIkfvsM7jhhnikbd682KzlsMNiY5fjj4cOHZKuUL4JBbyISBEaPjyeQz/xRNhqq9iJ7fDD4YQTYnW57bZLukL5thTwIiJFYPZseOONeGwN4PbbY9LciSdCs2bRcm+oREgV/eMUEUkh99i4per59DffjI1aFi2KQB81Crbfvvp6hXv66B+piEhKrF4NL71UPfP9k09ilvvBB8Nvfxut92bN4todd0y2Vsk9BbyISAo8+2wsOPP55zG23rcv/OIXsYnLDjskXZ0kQQEvIlKAvvgCzjwTzjgDzj4bOneOFvqAAXDUUdUtdSleCngRkQLwwQcxbm4G11wTq8YtXx7d8gBt28K99yZaotQzCngRkXqoogImTaoeT58+Pc737x8BbwYvvJBsjVK/KeBFROqJFStiLH30aHjsMZg/Hxo1gu9+F664Ao47LlrqIptCAS8ikqCFC6O7vaQEbr0Vbropjo85JsbT+/WDbbZJukopRAp4EZE8q6iI5WAnToRDD43Wev/+cN550KtXrChXte67yDe1RdIFiIiknXts4nL99bGH+g03xPlu3eLcnnvG8a67xuNtCnepC2rBi4jkwKpVMQlu9OjYxGXOnGi19+oFe+0V1zRuDDfemGydkl4KeBGROvTYY/DAA/DUU/Dll/E8+ve+F+PpxxwDLVsmXaEUCwW8iMi3MG8ePPEE/OAH8eja6NHRcj/11NiZrU+fWFlOJN9yPgZvZv3MbJqZzTSza2t5/ywze7vy9YqZdc1670ozm2pm75rZcDPTfyYikih3ePvt2LQFoqX+wx/Cu+/G8R/+EKF/113RYle4S1JyGvBm1gAYDBwNdAHOMLMuNS77CDjc3fcFbgKGVv5sG+DHQMbd9wYaAKfnsl4RkdqUl8P48XDllbDbbtC1K4wYEe+ddBK8/35MnoN4pG0LTV+WeiDXXfQ9gJnuPgvAzEYAA4D3qi5w91eyrp8EZC/j0BBoYmargabA3BzXKyICwLJl8PTT0eX++OOweHFMiuvbF667Do4/Pq7bZhs9py71U64Dvg3wadZxGXDgBq7/AfAUgLvPMbPfA7OBFcA4dx+Xq0JFRCC64E89NSbLff01bLdd7MhWtYnLVlslXaHIpsl1wFst57zWC82+SwT8oZXHLYjWfkfgc+AhMzvb3e+v8XMDgYEA7du3r7vKRaRoPPAAvPgiDB0aE+VatoT//u8I9UMPhYaajiwFKNf/2pYB7bKO21JLN7uZ7QvcDRzt7pVTVzgS+MjdF1ReMxI4GFgr4N19KJXj9plMptY/HkREqqxZE5u4jBkTi8xstRV88gm88QasXBmT4oYMSbpKkW8v11NBJgOdzKyjmZUQk+TGZF9gZu2BkcD33X161luzgYPMrKmZGdAHeD/H9YpICq1cGePoP/wh7LwzHHJIzHZ//fV4/9prYfJkzXiXdMlpC97dy83sUuBpYhb8MHefamYXV74/BPgl0BK4M3KccnfPuPurZvYw8DpQDrxBZUtdRGRjFi2K59NHj47JcsuWwdZbw9FHx/PpRx8N224b12rWu6SRuaenVzuTyXhpaWnSZYhIQqq62BcsiJZ6eXl8Pf74CPXevWMmvEiamNkUd8/UPK+pIyKSCsceG5PhRo2C1q2jC75nTzjgALXQpTgp4EWkoKxaFTPeR4+OyXKvvhqbuPTrF1+r/PjHydUoUh8o4EWk3vvyy1gSdvRoePJJ+OILaNIknkv//PN4rO3SS5OuUqR+UcCLSL20aBE8+GB0ub/wAqxeHV3vJ50Uz6cfeSQ0bZp0lSL1lwJeROoFd5g6NSbBdeoEs2bBJZfE95dfHqHes+fa3fAisn4KeBFJTHl57LzWrl0sC3vQQXD22bHQzAEHwHvvQefOsbqciGweBbyI5NWyZTBuXPUmLm3awFtvxeNtI0dW78q2xRbwne8kW6tIIVPAi0jOzZ8fm7eMHg3PPBPPq2+7beyXfsIJ0T1vFpPmRKRuKOBFJGfGjoVf/xpeeSVCvH17GDgwxtN79YJGjZKuUCS9FPAiUmc++wwGDYLvfx+6dIln1pctgxtuiFDv2lXj6SL5ooAXkW9s5Up4/vl4XK137zj3xz/GxLguXeC442KZWBHJPwW8iGyWJUtiE5dRo6ILftmyCPLevWGHHeL59a22imvVWhdJjgJeRDbqk09igtyoUTBhAlRUwE47xSNtAwbAEUdUX1sV7iKSLAW8iKyjalY7xBKwgwfH9126wNVXR6h3765NXETqMwW8iKzl6afh4otj5vtOO8H3vgcdOkSod+qUdHUisqn097dIEfvyy1jv/ayzYjMXgLZtY7b7l1/G8XHHwVVXKdxFCo1a8CJFZu5cGDMmxtSffz4eZWvVqnocfa+9YqxdRAqbAl6kCLz3XoT26NHw2mtxbrfd4LLLouv94IO1iYtI2ijgRVKoogKmT69ey/2ss+DNN6FHD7j55gj1Ll30GJtImingRVJi+fLYsGWLLWKm+1/+AgsXxiI0d90FO+8cLxEpDppkJ1LAFiyAYcOiRd6qVXX3+znnwL33Vne7ZzIKd5Fioxa8SIGZMSPG0kePjkfZ1qyJ/dR/8APYbru4pmvXeIlI8VLAixSA5ctjV7bRo2PCHESAX399bLe6334aTxeRteW8i97M+pnZNDObaWbX1vL+WWb2duXrFTPrmvXetmb2sJl9YGbvm1nPXNcrUl889xwMHx7fb7kl3H9/rPV+++3w0Ucxae7GG2H//RXuIrKunLbgzawBMBjoC5QBk81sjLu/l3XZR8Dh7r7EzI4GhgIHVr53OzDW3U82sxKgaS7rFUnSkiXw0kvVu68NHhyt9TPOiIlzM2ZA48bJ1igihSPXXfQ9gJnuPgvAzEYAA4D/BLy7v5J1/SSgbeW1zYHDgPMqr1sFrMpxvSJ5NXt29Xj6iy9CeTnMmgUdO8Idd1SPqYPCXUQ2T64Dvg3wadZxGdWt89r8AKhcMJNdgQXAPZXd9lOAy919WS4KFckHd3jrreqd2d58M8537hzLwQ4YALvsEuc0611Evo1cB3xtI4Ne64Vm3yUC/tDKUw2BbsBl7v6qmd0OXAv8osbPDQQGArRv376Oyhape++8E+u6f/JJjJkffDD89rcR6nvskXR1IpI2uZ5kVwa0yzpuC8yteZGZ7QvcDQxw90VZP1vm7q9WHj9MBP5a3H2ou2fcPdO6des6LV7k26ioiOfRb789jnfbDbp1g7vvhnnz4F//gp/+VOEuIrmR6xb8ZKCTmXUE5gCnA2dmX2Bm7YGRwPfdfXrVeXf/t5l9amZ7uvs0oA9ZY/ci9c28ebGJy5w58KtfxSIzn39evStb06YwcmSyNYpI8chpwLt7uZldCjwNNACGuftUM7u48v0hwC+BlsCdFs/6lLt7pvIjLgMeqJxBPws4P5f1imwOd/jgg+pNXF6t7Gv6znfgl7+Ehg0j8EVEkmDutQ6JF6RMJuOlpaVJlyEpVlEBEydWz3yfMSPOZzKx4MyAAbHdqp5LF5F8MbMpWQ3j/9BKdiIbsWJFtNabNoV77oEf/hAaNYLvfheuvDImzrVtm3SVIiJrU8CL1OLll2HChHh87eyzY6LchRdGmI8YAf36wTbbJF2liMj6KeBFgK+/jo1bnnkmJsLNnBnnS0rglFNi9jvEUrGnnZZcnSIim0oBL0XJHd5/H8aNi1AfPz42dGnYENq0iR3a3GHVqmjFd1vnAU0RkfpN+8FL0bnllhgz32uvGEOfORPOPz8mzS1aFBu8bLllPOZWUgK9eyddsYjI5lMLXlLviSfgppvg+edjolxJCRxyCPTtG68OHda+vmfP2Mlt/PgI957aw1BECpACXlLDHaZOjS73cePiWfSePWOTlsaN4bPPYhOXq67a+Gf17KlgF5HCpoCXgvbZZ/Dss9WhPm9enO/cGRYvju+PPDJeIiLFRAEvBWfFCrjhhgj1qt3YWraMED/qqOh2b9duw58hIpJ2CngpCH/9a8xyv/LKmAD30EPR3X7LLRHq++8PW2jKqIjIfyjgpd6ZNy+63d96C37/+zj37LPwxRcR8GaxRGxD/dsrIrJe+l+kJG75cnjppepx9HfeifOtWsHPfw4tWsADD8Ts9yoKdxGRDdP/JiURs2fDP/8Zgf7SS7GSXEkJHHoo3HZbjKPvt191t3t2uIuIyMYp4CUvli6FRx6BAw+MGe5Tp8LVV8diM5dcEuPovXpBs2ZJVyoikg4KeMmJZctis5Ytt4xd11atitXifv1ruO66OFdWFsvCiohI3VPAS51YsyYeWRs3Ll4vvxyh3q9fhPl228Xa7506xfVbbqlwFxHJJQW8fGNlZdUT4559FhYujPP77guXXVbd7V5lzz2TqVNEpBgp4GWTLV0Kr70GRxwRx5dfHlur7rADHH10BPqRR8KOOyZbp4iIaDc52YA1a6C0FL78Mo7/+lfo0yda7hBrvb/9djy3ft99cPbZCncRkfpCLXhZy+zZ1d3uzz0X26eOGAGnnRavrl2hdeu4tmvXZGsVEZH1U8AXua++ghdfrJ4cN21anN95Zzj22Opud4g91Nu2Ta5WERHZdAr4IlNREbustW4dXe+tW8ds9yZNYu/ziy6KUO/SJZaEFRGRwqSALwKLFsVuaxCz2ps3h7Fj4+tvfwv77AOHHBJ7pouISDoo4FPoyy/hhReqx9Lnz49H2Bo2jMfXsoP88suTq1NERHIn5wFvZv2A24EGwN3ufluN988Crqk8XAr8t7u/lfV+A6AUmOPux+a63kJUXh6z3ceNi1CfODG64ps1i273Sy+F1asj4M84I+lqRUQkH3Ia8JXhPBjoC5QBk81sjLu/l3XZR8Dh7r7EzI4GhgIHZr1/OfA+0DyXtRYa9xgjHzUqloD9/PM4zmTgmmtiHL1nT23SIiJSrHL9HHwPYKa7z3L3VcAIYED2Be7+irsvqTycBPxnnraZtQWOAe7OcZ31nnt8/egj2H332LgFYunXk0+OndkWLIiFaG6+GQ4/XOEuIlLMct1F3wb4NOu4jLVb5zX9AHgq63gQcDWw9fp+wMwGAgMB2rdv/40LrW/Ky+HVV6vH0Q8+GH7/e2jXDvbfP9Z2h9iN7a67kq1VRETqn1wHfG0PWnmtF5p9lwj4QyuPjwXmu/sUM+u9vl/g7kOJbn0ymUytn10I3OHDD6vH0Z9/PibLmUH37rDrrnFdw4bw0EPJ1ioiIvVfrgO+DGiXddwWmFvzIjPbl+iGP9rdF1WePgQ43sz6A1sCzc3sfnc/O8c1591NN8E990T3O8Auu8SqcUcdFeu+V7XWRURENlWux+AnA53MrKOZlQCnA2OyLzCz9sBI4PvuPr3qvLv/zN3bunuHyp97Pi3hPnp0hHdFRRyvWBHPot9xB0yfHkE/dGiMrSvcRUTkm8hpC97dy83sUuBp4jG5Ye4+1cwurnx/CPBLoCVwp8XSaeXunsllXfniDjNnVi8De+utsULcqlWxROz8+bDTTnDLLUlXKiIiaWPuBTtsvY5MJuOlpaWJ1rB4cYyfV4X6J5/E+Y4do1Veta67iIhIXTCzKbU1jLWSXR348stY8vWZZ2Dy5Gi5N28eW6teey307Qu77ZZ0lSIiUkwU8N/Q0KHQqFEsMtOkCdx5Z3S/33BDjK937x4z3kVERJKgCNoECxfG3ugzZsD118e5Bx+MYD///Aj6uXNhyy2TrVNERKSKAr4WX38d67lXjaO//np0u7dqBT/5SQT76NGx1nsVhbuIiNQnCvhKs2fDo49GoI8fD8uXRxd7z55w443R7Z7JQIMGcX12uIuIiNQ3RRvwX30Fjz8e+6C3bw8vvQRXXAF77AEXXBCB3rs3bL3eRXJFRETqr6IJ+JUr4eWXI7B79IBFi+DMM+HPf47tVI8/Hj7+OFaRExERKXSpDXh3mDq1em33F1+MFeNOOw1GjIAOHWJsfd994/qtt1ZrXURE0iNVAT9nDvzP/8RSr888A/PmxfnOneHCC6Pb/fDDq6/ff/9EyhQREcm5VK1kZ5ZxKGXrraF//1hgpm/fGGMXERFJo6JZya5BA7jmGvj5z5OuREREJDm53k0u70pKYotVERGRYpaqgG/TJlac69kz6UpERESSlaqA33FHhbuIiAikLOBFREQkpGwWvX0FTEu6jjxrBSxMuog80v2mm+433YrtfiE/97yLu7eueTJts+in1faoQJqZWWkx3bPuN910v+lWbPcLyd6zuuhFRERSSAEvIiKSQmkL+KFJF5CAYrtn3W+66X7TrdjuFxK851RNshMREZGQtha8iIiIoIAXERFJJQW8iIhICingRUREUkgBLyIikkIKeBERkRRSwIuIiKSQAl5ERCSFFPAiIiIppIAXERFJIQW8iIhICingRUREUkgBLyIikkIKeBERkRRSwIuIiKSQAl5ERCSFEgl4MxtmZvPN7N31vG9m9iczm2lmb5tZt3zXKCIiUsiSasHfC/TbwPtHA50qXwOBv+ShJhERkdRIJODdfQKweAOXDADu8zAJ2NbMdspPdSIiIoWvvo7BtwE+zTouqzwnIiIim6Bh0gWsh9Vyzmu90Gwg0Y1Ps2bNDujcuXMu6xIREalXpkyZstDdW9c8X18Dvgxol3XcFphb24XuPhQYCpDJZLy0tDT31YmIiNQTZvZJbefraxf9GOCcytn0BwFfuPu8pIsSEREpFIm04M1sONAbaGVmZcANQCMAdx8CPAn0B2YCy4Hzk6hTRESkUCUS8O5+xkbed+BHeSpHREQkdeprF72IiIh8Cwp4ERGRFFLAi4iIpJACXkREJIUU8CIiIimkgBcREUkhBbyIiEgKKeBFRERSSAEvIiKSQgp4ERGRFFLAi4iIpJACXkREJIUU8CIiIimkgBcREUkhBbyIiEgKKeBFRERSKLGAN7N+ZjbNzGaa2bW1vL+NmT1mZm+Z2VQzOz+JOkVERApRIgFvZg2AwcDRQBfgDDPrUuOyHwHvuXtXoDfwBzMryWuhIiIiBSqpFnwPYKa7z3L3VcAIYECNaxzY2swM2ApYDJTnt0wREZHClFTAtwE+zTouqzyX7Q7gO8Bc4B3gcndfk5/yRERECltSAW+1nPMax98D3gR2BvYD7jCz5ut8kNlAMys1s9IFCxbUfaUiIiIFKKmALwPaZR23JVrq2c4HRnqYCXwEdK75Qe4+1N0z7p5p3bp1zgoWEREpJEkF/GSgk5l1rJw4dzowpsY1s4E+AGa2A7AnMCuvVYqIiBSohkn8UncvN7NLgaeBBsAwd59qZhdXvj8EuAm418zeIbr0r3H3hUnUKyIiUmgSCXgAd38SeLLGuSFZ388Fjsp3XSIiImmglexERERSSAEvIiKSQgp4ERGRFFLAi4iIpJACXkREJIUU8CIiIimkgBcREUkhBbyIiEgKKeBFRERSSAEvIiKSQgp4ERGRFFLAi4iIpJACXkREJIUU8CIiIimkgBcREUkhBbyIiEgKJRbwZtbPzKaZ2Uwzu3Y91/Q2szfNbKqZvZjvGkVERApVwyR+qZk1AAYDfYEyYLKZjXH397Ku2Ra4E+jn7rPNbPskahURESlESbXgewAz3X2Wu68CRgADalxzJjDS3WcDuPv8PNcoIiJSsJIK+DbAp1nHZZXnsu0BtDCz8WY2xczOyVt1IiIiBS6RLnrAajnnNY4bAgcAfYAmwEQzm+Tu09f6ILOBwECA9u3b56BUERGRwpNUC74MaJd13BaYW8s1Y919mbsvBCYAXWt+kLsPdfeMu2dat26ds4JFREQKSVIBPxnoZGYdzawEOB0YU+Oa0UAvM2toZk2BA4H381yniIhIQUqki97dy83sUuBpoAEwzN2nmtnFle8Pcff3zWws8DawBrjb3d9Nol4REZFCY+41h74LVyaT8dLS0qTLEBERyRszm+LumZrntZKdiIhICingRUREUkgBLyIikkIKeBERkRRSwIuIiKSQAl5ERCSFFPAiIiIppIAXERFJIQW8iIhICingRUREUkgBLyIikkIKeBERkRRSwIuIiKSQAl5ERCSFFPAiIiIppIAXERFJocQC3sz6mdk0M5tpZtdu4LruZlZhZifnsz4REZFClkjAm1kDYDBwNNAFOMPMuqznut8AT+e3QhERkcKWVAu+BzDT3We5+ypgBDCglusuAx4B5uezOBERkUKXVMC3AT7NOi6rPPcfZtYGOBEYkse6REREUiGpgLdaznmN40HANe5escEPMhtoZqVmVrpgwYI6K1BERKSQNUzo95YB7bKO2wJza1yTAUaYGUAroL+Zlbv7qOyL3H0oMBQgk8nU/CNBRESkKCUV8JOBTmbWEZgDnA6cmX2Bu3es+t7M7gUerxnuIiIiUrtEAt7dy83sUmJ2fANgmLtPNbOLK9/XuLuIiMi3kFQLHnd/Eniyxrlag93dz8tHTSIiImmhlexERERSSAEvIiKSQgp4ERGRFFLAi4iIpJACXkREJIUU8CIiIimkgBcREUkhBbyIiEgKKeBFRERSSAEvIiKSQgp4ERGRFFLAi4iIpJACXkREJIUU8CIiIimkgBcREUkhBbyIiEgKJRbwZtbPzKaZ2Uwzu7aW988ys7crX6+YWdck6hQRESlEiQS8mTUABgNHA12AM8ysS43LPgIOd/d9gZuAofmtUkREpHAl1YLvAcx091nuvgoYAQzIvsDdX3H3JZWHk4C2ea5RRESkYCUV8G2AT7OOyyrPrc8PgKdyWpGIiEiKNEzo91ot57zWC82+SwT8oet5fyAwEKB9+/Z1VZ+IiEhBS6oFXwa0yzpuC8yteZGZ7QvcDQxw90W1fZC7D3X3jLtnWrdunZNiRURECk1SAT8Z6GRmHc2sBDgdGJN9gZm1B0YC33f36QnUKCIiUrAS6aJ393IzuxR4GmgADHP3qWZ2ceX7Q4BfAi2BO80MoNzdM0nUKyIiUmjMvdah74KUyWS8tLQ06TJERETyxsym1NYA1kp2IiIiKaSAFxERSSEFvIiISAop4EVERFJIAS8iIpJCCngREZEUUsCLiIikkAJeREQkhRTwIiIiKaSAFxERSSEFvIiISAop4EVERFJIAS8iIpJCCngREZEUUsCLiIikkAJeREQkhRILeDPrZ2bTzGymmV1by/tmZn+qfP9tM+uWRJ0iIiKFKJGAN7MGwGDgaKALcIaZdalx2dFAp8rXQOAveS1SRESkgCXVgu8BzHT3We6+ChgBDKhxzQDgPg+TgG3NbKd8FyoiIlKIkgr4NsCnWcdllec29xoRERGpRcOEfq/Vcs6/wTWY2UCiCx/gazN791vWVmhaAQuTLiKPdL/ppvtNt2K7X8jPPe9S28mkAr4MaJd13BaY+w2uwd2HAkMBzKzU3TN1W2r9Vmz3rPtNN91vuhXb/UKy95xUF/1koJOZdTSzEuB0YEyNa8YA51TOpj8I+MLd5+W7UBERkUKUSAve3cvN7FLgaaABMMzdp5rZxZXvDwGeBPoDM4HlwPlJ1CoiIlKIkuqix92fJEI8+9yQrO8d+NFmfuzQOiit0BTbPet+04dj7twAACAASURBVE33m27Fdr+Q4D1b5KiIiIikiZaqFRERSSEFvIiISAop4EVERFJIAS8iIpJCCngREZEUUsCLiIikkAJeREQkhRTwIiIiKaSAFxERSSEFvIiISAop4EVERFJIAS8iIpJCCngREZEUUsCLiIikkAJeREQkhRTwIiIiKaSAFxERSSEFvIiISArlNODNbJiZzTezdzdyXXczqzCzk7POXWlmU83sXTMbbmZb5rJWERGRNDF3z92Hmx0GLAXuc/e913NNA+AZYCUwzN0fNrM2wL+ALu6+wsweBJ5093s39PtatWrlHTp0qMtbEBERqdemTJmy0N1b1zzfMJe/1N0nmFmHjVx2GfAI0L3G+YZAEzNbDTQF5m7s93Xo0IHS0tJvUKmIiEhhMrNPajuf6Bh8ZUv9RGBI9nl3nwP8HpgNzAO+cPdx6/mMgWZWamalCxYsyHXJIiIiBSHpSXaDgGvcvSL7pJm1AAYAHYGdgWZmdnZtH+DuQ9094+6Z1q3X6aEQEREpSjntot8EGWCEmQG0AvqbWTnQCPjI3RcAmNlI4GDg/qQKleIycSKMHw+9e0PPnklXIyKy+RINeHfvWPW9md0LPO7uo8zsQOAgM2sKrAD6ABpcl7yYOBH69IGVK2GLLeCllyLkJ02Cli2hQwdo1CjpKkVENiynAW9mw4HeQCszKwNuIFrnuPuQ9f2cu79qZg8DrwPlwBvA0FzWKuIOf/sbzJoFq1bF8Zo10ZLv2RNOPhnmzIGGDWHXXWGPPeLVqVP19zvvHH8UiIgkLdez6M/YjGvPq3F8A/EHgUjOLVsGF18M998PAwdCSUmEfElJdNMDPPggTJ8erxkz4utzz8GKFdWfc/rpMHx4fP/rX8MRR8DBB8cfCzESJSKSH0mPwYskbvp0OOkkmDoVfvUr+PnP4bzz1h2DP/jgeGVbsyZa9VWh3759nF+6FG68Mf5AOPhgKCuD/fZbt8W/xx6w++6w1VZ5vGERKQo5Xegm3zKZjOs5eNkcI0dGmJeUwD/+AUcdVXefvXp1vJo2jYC/5ZbqHoBPP1372p13jrC/7jro2zf+QCgrg91203i/iGyYmU1x90zN82rBS1FavRp+9jP4wx+gRw946KHq1nddadSoOpzbtoU776x+b/lymDmzOvCregCqvPwy9OsHEyZAr17x9ZFH1h73b9cOGjSo25pFJD0U8FJ05s2D006L2fGXXAJ//CM0bpzfGpo2hX33jVdt9t0X/v532GefOP7gAxg2LFr2VRo3ju797G7/U0+FrbfOff0iUv+pi16Kzs9/DoMGwdChcNZZSVez6dzh3/9et9U/fXr0BqxeDQsXxqN8v/sdPPxwPPK3xRbw+usxX6BTJ9hmm6TvRETqkrropahVheNOO8ENN8A558CeeyZd1eYxi/p32gkOP3zt98rLYfbsCHeA1q3j/qoe2fvFL+DJJ+P7HXaofbLfbrvBltqzUSQ11IKXovDjH8OYMfDWW8XZgp0+PZ4SqGrxV70++6z6mj33jKEAgDvugO23jy5/iNa/nu8XqZ/Ugpei9v3vxwp0zZsnXUkyqlrpNX3xRYT+jBnRy1Fl6NAY/z/11Djfpg1su+3aLf6qXoCddtIz/iL1kVrwklr33w/vvRePp8nmcYevv44u+9Wro4u/qtU/c2a8V2WrrSLoL7wwJi26w+TJ0Llz8f5BJZJPasFL0fj6a7jySvjLX+Cww+I437PkC51Z9Xh8o0Zw223V71VUxDP6NSf7VXXhf/YZHHgg/PnPcOml8MknMe8he9x/992hWbP835dIMVHAS6rMng2nnAKvvQY//Wm03hvq3/I61aAB7LJLvPr2Xff95s1jvsPee8fxnDnw7LOxzn+2tm3XDv3/+q8YRhGRuqH/9UlqjBsHZ54Za8g/8kgEhuRf06Zw3HHVx1VL9S5dWr24T/ZkvwcfhCVLYinfDh3ij4OrropZ/7vvHhP/5syJPwLatNFkP5FNpYCXgrdmDdx8c3QD77VX9YpvUr9stVWE+H77rfveokXVXfbbbhvXbL99HN93H9x6a3zfpEn14j41J/u1aqXJfiLZNMlOCtrixXD22fDUU/F1yBCN7abN/Pnw7rvrPuI3a1Y8/19l6dL4Zz9iRAzVXH11nC8v1zCNpFsik+zMbBhwLDDf3ffewHXdgUnAae7+cOW5bYG7gb0BBy5w94m5rFcK06xZMaHuoovUgkuj7bePbXePOGLt86tXxwS+qs17qv6wGzcuZvFXBXzfvjBtWu2t/l131QRMSa+ctuDN7DBgKXDf+gLezBoAzwArgWFZAf834CV3v9vMSoCm7v75hn6fWvDFwT264Y87Lv7nvHq1dlyTtWW32u+8MwK/aux/wYLq67bYIsb9+/ePWf8QEzTbto0d/kQKQSIteHefYGYdNnLZZcAjQPeqE2bWHDgMOK/yc1YBq3JSpBScKVNipvwdd8CPfqRwl3Vld8lfcsna7y1ZsnZ3/4wZMT+gynHHwfHHw113xfyO006Lln52y3+HHdRbJPVfoiNTZtYGOBE4gqyAB3YFFgD3mFlXYApwubsvy3+VUl8sWxbdsJkMjB0LRx6ZdEVSiFq0iC2Ce/RY9z332Dp4223jeMmSWCxpzJh4OqPK1luv3d3fv3/tnyeSpKQfOBkEXOPuFTXONwS6AX9x9/2BZcC1tX2AmQ00s1IzK12Q3fcmqTJ6NHTsCJMmxfH3vqe90KXumcXiSFXb+LZsGWv4L18ecz3Gjo2u/PPOi1n7kybBr34FL78c18+aFXMGHnssjufNg5EjY5LgihWJ3JIUsaTnlmaAERZ9Xa2A/mZWTky4K3P3Vyuve5j1BLy7DwWGQozB57xiyavy8lgm9bbb4IADYMcdk65IilGDBvEHZseO8cdltq+/rp7Nv8UWMGAAtG8fxxMmwOmnx/dm0K7duhP99tgj5gFopr/UtUT/lXL3jlXfm9m9wOPuPqry+FMz29PdpwF9gPeSqVKS8tlncMYZ8MILMUN+0CBtZyr1T+PG1TPxO3SIsfsqxx0Xc0ayH++bPh0eeCA2+qkycSIcdBC8+GK0/n/xi9j1cOXK+GyN98s3kevH5IYDvYFWZlYG3AA0AnD3IRv58cuABypn0M8Czs9hqVLPvPxy7GS2eDHcey+ce27SFYlsvqZNoVu3eGVzh4ULqwO/S5c4/847sZbDzTfH8bXXwt13V7f0s1v9e+wB222X3/uRwqKFbqRecYc//SmWKu3QIR6HqxoPFSkGa9ZUL8f7xBPwzDPVs/4/+ig2+6nSsmWs3jh+fLTy33gDSkrinBQP7SYnBeGii6KL84QTouW+zTZJVySSX9lr7R9zTLyqrFoVIZ+9nv/y5dVd+NdcA59/Hs/yQzxGWlGx9rh/x456tLRYKOClXjnmmFhr/Kc/1bijSE0lJbDnnvGqzaBB8NVX1cezZsUiP4sWVZ+rmjBYFfiHHx5/UEP0oOm/u/RQwEviRoyIsfZLLokZyCLyzVSN5Vd56qn4umjRumv5z5gRXftLlkTAu8cCPldcAdddF70FDzxQPe7furXCv9Ao4CVR7tXbhV58sbYCFcmFli3jddBBa593jy5+iEA/5xzo2jWOZ82CCy6ovnabbWp/xK9zZ23wVF9pkp0koqwsxgZ32SV2AWvcWOOCIvVJRQV8/PG6rf7p02O3vqroGDIk5s58+GGsV/GTn0Tor1gRf7BrM5/c0yQ7qTeeey4W/6ia/Zu9DriI1A8NGsBuu8Xr6KPXfm/Figj06dOrHwH89NNY0vfii+N4xAi48ML4I762R/zat9dqlLmmFrzkzZo18JvfwPXXxyShkSPjL30RSY+qiXpvvAGjRq099p89AbCkJP54eOqp+CPggw9g/nw45BAF/+ZSC14StWRJLFbz2GPRer/rLrXcRdKoaiLe/vvHq4p7rE6Z3dU/bVpM3oNY0OeOO6rnBNxySyz8U3Pcv2ojINk4Bbzk3Jtvwkknxbjdn/4El16q2bgixcYs9pLYccfY0Kemn/wkZvNXTbT9/HN49VX45z+rx/sh/iCoCvyuXeHyy+N8RUW0/CdOjKG/3r2hZ89c31X9pi56yal77onH31q2jG04i/0/OBHZPF9/HTP6a67nP2NG/LHw+utxXa9e0e0/cWI8EVBSEvN9iuH/Oeqil7wbNy4eszniCBg+PLbRFBHZHI0bw3e+E6+aVq2q/v6kk+Cll+JcRUV8HT++OAJ+ffTUsdS51avja9++sVDGuHEKdxGpeyUl1d9fcUXsYVFSEl31JSXRTV/MFPBSp158MWbIf/hhjLmdeaZmxIpIfvTsGd3yN91UPN3zG6IueqlTu+wCu+6qFelEJBk9eyrYq+h/w/KtLVgQfzG7xxavzz4bm1mIiEhychrwZjbMzOab2bsbua67mVWY2ck1zjcwszfM7PFc1inf3KRJsZLVzTfHM6siIlI/5LoFfy/Qb0MXmFkD4DfA07W8fTnwft2XJd+WeyxKcdhhsYb8xImw775JVyUiIlVyGvDuPgFYvJHLLgMeAeZnnzSztsAxwN25qU6+qaVL4ayz4LLL4HvfgylT1l6xSkREkpfoGLyZtQFOBIbU8vYg4GpgzUY+Y6CZlZpZ6YIFC3JQpWT74AM48MBYXermm2H0aGjRIumqRESkpqQn2Q0CrnH3iuyTZnYsMN/dp2zsA9x9qLtn3D3TumpRY8mJhx6C7t1jQ4inn4brrtNseRGR+irpx+QywAiLhclbAf3NrBw4EDjezPoDWwLNzex+dz87uVKLW0UF/OEPsPfeEfRt2yZdkYiIbEiiAe/u/3mYyszuBR5391HAKOBnled7A1cp3JMxdy40aRLd8GPGxE5O2atHiYhI/ZTTgDez4UBvoJWZlQE3AI0A3L22cXepR1asgIMOikUj/vlPLTcrIlJIchrw7n7GZlx73nrOjwfG101FsincY5nZJk3gtttiS0YRESksmiIla/nii9iV6eGH4/jMM2GvvZKtSURENp8CXv7j7bchk4HHHovlZ0VEpHAp4AWA++6L8fbly2MP5f/+76QrEhGRb0MBX+RWroSLL4Zzz40FbF5/HQ45JOmqRETk21LAF7GPP4ZeveCvf4VrroFnnoEddki6KhERqQtJL3QjCXnuOTj1VCgvh0cfhRNOSLoiERGpSwr4ItW8Oey2G/zjH7D77klXIyIidU1d9EVk4UK46674vnt3ePVVhbuISFop4IvI4MGxxetHH8VxbAEgIiJppIBPOffY/Q1i97fJk6Fjxw3/jIiIFD4FfIotXx6Pv2UysGQJNGoE++yTdFUiIpIPCviUmjEjFq65/3744Q9hm22SrkhERPJJs+hT6NFH4bzzosU+diwcdVTSFYmISL6pBZ8i5eVw9dXwX/8FnTvHqnQKdxGR4pTTgDezYWY238ze3ch13c2swsxOrjxuZ2YvmNn7ZjbVzC7PZZ1p8O9/Q58+8LvfwSWXwIQJ0L590lWJiEhSct1Ffy9wB3Df+i4wswbAb4Cns06XAz9x99fNbGtgipk94+7v5bLYQrVkCXTrBp9/Dn//O5x9dtIViYhI0nIa8O4+wcw6bOSyy4BHgO5ZPzcPmFf5/Vdm9j7QBlDA16JFC7jqKujbV7PkRUQkJDoGb2ZtgBOBIRu4pgOwP/BqfqoqDF9+CWecAa+8Esf/7/8p3EVEpFrSk+wGAde4e0Vtb5rZVkTr/gp3/3I91ww0s1IzK12wYEEOS61fKipiEt27G5zdICIixSrpx+QywAiLNVNbAf3NrNzdR5lZIyLcH3D3kev7AHcfCgwFyGQynoeaE/X449EV36IFvP02NG6cdEUiIlIfJdqCd/eO7t7B3TsADwOXVIa7Af8HvO/uf0yyxvri66/hRz+C446LNeVB4S4iIuuX0xa8mQ0HegOtzKwMuAFoBODu6x13Bw4Bvg+8Y2ZvVp67zt2fzGG59dbs2XDKKfDaazGZ7rLLkq5IRETqu1zPoj9jM649L+v7fwHa6wwYNw7OPBNWrYKHH4aTTkq6IhERKQRJT7KT9VizBm66Cfr1g512gtJShbuIiGy6pCfZSS0WL47Fap56Kr4OGQLNmiVdlYiIFBK14OuhX/wCnn0W7rwT7rtP4S4iIptPLfh6wh2WLoWtt4ZbboHzz4993EVERL4JteDriSuvhMMPh5UrY+92hbuIiHwbasHXE336QPPmsYe7iIjIt6WAT9Do0TBnTmzvetxx8RIREakL6qJPQHk5/OxncMIJMYmuvDzpikREJG0U8Hn22Wdw1FFw220wcCCMHw8N1Y8iIiJ1TNGSRy+/DKeeGs+533MPnHde0hWJiEhaqQWfB+5w++3Quzc0aQKTJincRUQktxTwOfbVV3D66XDFFdC/fyw527Vr0lWJiEjaKeBzbPFieOGFGHN/9FHYdtukKxIRkWKgMfgcefFF6NULdtkFZs6MZ9xFRETyRS34HHjxxRhv//vf41jhLiIi+ZbTgDezYWY238ze3ch13c2swsxOzjrXz8ymmdlMM7s2l3XWlYqK+HrYYXDvvbGPu4iISBJy3YK/F+i3oQvMrAHwG+DpGucGA0cDXYAzzKxL7sr89p57Djp3hhkzwAzOPVfLzoqISHJyGvDuPgFYvJHLLgMeAeZnnesBzHT3We6+ChgBDMhNld/OmjVw662xeE2jRnEsIiKStETH4M2sDXAiMKTGW22AT7OOyyrP1StLlsRys9ddB6edBq+9BnvumXRVIiIiyU+yGwRc4+4VNc5bLdd6bR9gZgPNrNTMShcsWFDnBa7PG2/AAQfA2LHw5z/DAw/AVlvl7deLiIhsUNKPyWWAEWYG0Arob2blRIu9XdZ1bYG5tX2Auw8FhgJkMpla/wioa8OGxQ5wrVrFjPmePfPxW0VERDZdogHv7h2rvjeze4HH3X2UmTUEOplZR2AOcDpQL+akX3IJ/OUvsX/78OHQunXSFYmIiKwrpwFvZsOB3kArMysDbgAaAbh7zXH3/3D3cjO7lJhZ3wAY5u5Tc1nrptpnH/j5z+HGG6FBg6SrERERqZ2556VXOy8ymYyXlpbW+ec+8QSsWgUnnljnHy0iIvKtmNkUd8/UPJ/0GHy9t2YN3HJL7Nl+wgnxjLuIiEh9p4BfjwULogt+u+1g5MhYblbhLiIihSLpx+TqpUmToFs3uPDCON5hh9jHXUREpFAo4LO4w+DBsZZ8o0Zw/fVJVyQiIvLNKOArLVsGZ58Nl14ay85OmRKteBERkUKkgAemTYMDD4QRI+Dmm2HMGGjRIumqREREvrmin2T3yCNw/vnQuDE8/TQceWTSFYmIiHx7Rd2Cf+wxOPlk2GsveP11hbuIiKRHUQZ81do+/frB//5vrCffrt2Gf0ZERKSQFF3A/+tfMd6+cGHMlL/iCigpSboqERGRulV0Ad+kSSw7u2RJ0pWIiIjkTlEE/BdfwP/9X3x/wAEx3t6pU7I1iYiI5FLqA/7ttyGTgYsvhunT49wWqb9rEREpdqmOuvvug4MOikVsXngB9tgj6YpERETyI6cBb2bDzGy+mb27nvcHmNnbZvammZWa2aFZ711pZlPN7F0zG25mW27q7125Mlrs554bE+reeAMOPXTjPyciIpIWuW7B3wv028D7zwFd3X0/4ALgbgAzawP8GMi4+95AA+D0TfmFH38MvXrBX/8K11wDzzwTm8WIiIgUk5yuZOfuE8yswwbeX5p12AzwrOOGQBMzWw00BeZu7Pd9/DHsu29s6/roo7F/u4iISDFKfKlaMzsRuBXYHjgGwN3nmNnvgdnACmCcu4/b2GctWhTh/s9/KtxFRKS4JT7Jzt0fdffOwAnATQBm1gIYAHQEdgaamdnZtf28mQ2sHL8vhZghP3NmfmoXERGprxIP+CruPgHYzcxaAUcCH7n7AndfDYwEDl7Pzw1194y7ZyBWpevdO19Vi4iI1E+JBryZ7W5mVvl9N6AEWER0zR9kZk0r3+8DvL+xz2vTBp57Dnr2zGXVIiIi9V9Ox+DNbDjQG2hlZmXADUAjAHcfApwEnFM5kW4FcJq7O/CqmT0MvA6UA28AQzf2+3bcUeEuIiICYO6+8asKRCaT8dLS0qTLEBERyRszm1I1TJ2t3ozBi4iISN1JVQvezL4CpiVdR561AhYmXUQe6X7TTfebbsV2v5Cfe97F3VvXPJn4c/B1bFpt3RRpZmalxXTPut900/2mW7HdLyR7z+qiFxERSSEFvIiISAqlLeA3+ihdChXbPet+0033m27Fdr+Q4D2napKdiIiIhLS14EVERAQFvIiISCop4EVERFJIAS8iIpJCCngREZEUUsCLiIikkAJeREQkhRTwIiIiKaSAFxERSSEFvIiISAop4EVERFJIAS8iIpJCCngREZEUUsCLiIikkAJeREQkhRTwIiIiKaSAFxERSSEFvIiISAop4EVERFKoYV18iJkNA44F5rv73uu5pjcwCGgELHT3wyvPXw78EDDgLncfVHn+fyrPL6j8iOvc/ckN1dGqVSvv0KHDt70dERGRgjFlypSF7t665vk6CXjgXuAO4L7a3jSzbYE7gX7uPtvMtq88vzcR4j2AVcBYM3vC3WdU/uj/uvvvN7WIDh06UFpa+s3vQkREpMCY2Se1na+TLnp3nwAs3sAlZwIj3X125fXzK89/B5jk7svdvRx4ETixLmoSEREpZvkag98DaGFm481sipmdU3n+XeAwM2tpZk2B/kC7rJ+71MzeNrNhZtYiT7WKMHEi3HprfBURKUR11UW/Kb/nAKAP0ASYaGaT3P19M/sN8AywFHgLKK/8mb8ANwFe+fUPwAU1P9jMBgIDAdq3b5/j25BiMHEi9OkDX38NjRvDc89Bz55JVyUisnny1YIvA8a6+zJ3XwhMALoCuPv/uXs3dz+M6OafUXn+M3evcPc1wF3EOP063H2ou2fcPdO69TpzDEQ2S3k5jB8Pq1bBmjWwYkUcA7z6Knz1VZLViYhsunwF/Gigl5k1rOyKPxB4HyBrwl174L+A4ZXHO2X9/IlEd75IznzwAey/PzRqBCUlsMUW0YLv3RtWroTDD4cWLeCgg+Daa2HsWAW+iNRfdfWY3HCgN9DKzMqAG4jH4XD3IZVd8WOBt4E1wN3uXhXYj5hZS2A18CN3X1J5/rdmth/RRf8xcFFd1CpSm4ceggsugC23hG7dolt+/PgI9549YfVqeOIJeOGFOP/HP8JvfgMNGkD37nFd795wyCGw1VaJ3oqICADm7knXUGcymYzrMTnZHKtXwzXXwP/+b7TMH3oI2rbd+M8tWxZj9VWB/9pr0b0/ZAhcdBEsWABvvAG9ekGTJjm/DREpYmY2xd0zNc/na5KdSL0zdy6ceiq8/DJcdhn8/vfRNb8pmjWDI4+MF0Tgv/wy7LNPHD/xBJx/PrzzDuy9N7z5ZoT+wQfHz4qI5JoCXorS+PFw2mmwdCn84x9wxhnf7vOaNYOjjqo+Pvlk2Hln6NIljgcPhrvvjvH9Hj2qu/QPPhiaNv12v1tEpDbqopeiM2QI/OhH0KkTPPII7LVX7n/nV19FC3/8+HiVlkJFRQT+gQdG2B9xBHz3u7mvRUTSZX1d9Ap4KTovvxwt6r/+FbbeOpkavvoK/vWvtQO/WzeYPDnev+ee+MOjR60Ph4qIVFPAS1F76y14/nm48sqkK6ndl1/GnIDOnWOyXosW8IMfwKBBMRHw1lvhsMNiIuCWWyZdrYjUJ5pkJ0Xt7rvh0UfjUbhttkm6mnU1bx4vgIYNoawsnr0HeP99uPHGWHinceMI+d69ozv/wAMV+CJSO7XgJbVWroR586Bjx/j+yy9h++2Truqb+fzz6NKveizvjTfAPQK/Z88I/AsugHbtNvZJIpI26qKXovLxx3DKKRGM774bQZgmn38OL70UYf/CC/EY3ptvwr77xvG//gX/7//pkTyRYqAueikaY8fCWWfFLPW//S194Q6w7bZw3HHxAliypHro4aWXYuGen/0sjgcPhsWLo0u/R49Nf9ZfRApbvtaiF8m5igr4n/+B/v1jNbrSUhgwIOmq8qNFi1g7H+CXv4Q5c2IsH+DFF+Ncr17xh0HfvnDzzfE0wapVydUsIrmlFrykwsKFcPbZ8PTTcO65cOedxb2ATPa9P/ggLFoULfuqMfzrr6++7pBDYqGf889PpFQRyRG14KXgTZ4MBxwQ4TV0aDxDXszhXpuWLeGEE+D22+ORwYULYeTIeBTv3/+O8XuIR/QGDIhhDhEpbHW1m9ww4FhgvrvvvZ5regODiF3mFrr74ZXnLwd+CBhwl7sPqjy/HfBPoAOxm9ypWTvNiQDw4Ydw6KGw007R5ZxZZ5qJ1KZlSzjxxHhBPIIH/5+9O4+/es7//397tKo0iqKFhFFka3lXKvROSLKMJUQiS/LD2MZoMrbBYBg+ZE0ShhANjbJGK6r3u0hJKtG+Sfv+7vn743He3/MuRcv7fV7nvM79ermcy/u8lnN6HOr9OM/t8fRVBz/84CsOwGvp/+UvPn6fm+tfpMqWjSRkEdlJxdWC7wecur2LZlYFeBo4M4RwBNAxcf5IPLk3A44BTjezQxMv6wEMDSEcCgxNHIsAvkQM4JBDoFcvGD9eyX13FI7fH3CAJ/WOHf14yRIfz//b33w53t57Q/v2vlXumDHe4heR9FQsCT6EMAJY+hu3XAQMDCHMSty/KHH+cODLEMKaEMImYDiQaFNwFvBS4vlLwJ+KI1bJfDNneoGX/Hw/7tbNE48UHzP/2aaNLzNcuNDH8rt0gVmzoEcPL7hTtapPaly4MNp4ReTXUjUGXw+oambDzCzfzLokzk8CTjCzfcysInAaUFiqY78QwnyAxM8MLVEixa1yZW85FnYjS8nbd19v1T/1FEye7OP2b74Jl1zi2+Dus4/f9/e/+30xKq8hkrFSNYu+DNAEABoF9gAAIABJREFUaAtUAL4wsy9DCFPM7CHgY2AV8DWwU51+ZtYN6AZQp06dYg1a0semTb45TLduUK2at94LW5mSevvt54m8sCu/0J57+lK8wv83bdtChQrJ7XEbNYLSpVMdrUh2SlWCn4NPrFsNrDazEfiY+/chhBeAFwDM7J+JewEWmlnNEMJ8M6sJLNrWG4cQegO9wSvZlfDnkAgsWOB7t48YATVqwLnnKrmnqx5FZsqE4JvnDB0Kgwf7uT/8wTfNKaylf8wxSvgiJSVVXfTvAsebWZlEV3xzYAqAme2b+FkHOAfon3jNIODSxPNLE+8hWWbkSG/1jRsHr7ziyV0yg5l36X/3ne+U99prcOGF8P33PjO/SRPv2n/ySb8/BC9WJCLFo7iWyfUHcoFqZjYHuAtfDkcI4dlEV/wHwERgM9AnhDAp8fK3zWwfYCNwbZGlcA8Cb5rZFcAsEjPvJTuE4OVW//pXOPhg+OgjOOqoqKOSXVWzphfT6dTJj+fN84I7w4b5ZkDgk/lOOAHeesu79tev9yV5pVStQ2SXaLMZSTsrVvjOaG+/Deec44VrCrdSlfj67jv497+9rO4BB8Czz0LPnlt26R91lBK+yNa02YxkhEmTvBt+xgx45BHfEU3j7dnhsMPg+eeTx0cc4V/whg2DdxMDdFWrQuvWycI7Rx6phC+yPUrwklbuvttb8J9+6i03yV7HH+8P8LX3w4cnu/XfecfP77+/bw1cujQsWuQrLJTwRZwSvERu/XpP6tWrey359et9zFakUJ06vub+kkv8eNYsT/QLFiRn4Z9+uq/Xf+89P54xw8f3lfAlWynBS6RC8D3NV62CUaNUkU52TJ06XlWvqD//GSpV8uerV3uXf5UqW3bpN2igIR/JHkrwEikzuOYaT/Rqacnu6Nw5+dzMx/OHDfNdBt9+289Xr54supObC4cfroQv8aVZ9JJymzfDP//pa6CvuSbqaCTuQvBx+sLx+88+g9mz/drLL3u3/88/+xj+YYcp4Uvm2d4serWZJKWWLvUu+Tvu8OI1IiXNzMfiu3aFl16Cn37y8fkXXoCTTvJ73n7bu++nTfPj777zR4zaP5KF1EUvKZOfD+ed59uPPv00dO8edUSSjcy8eNLBByfPdejgyf/QxGbVDzzgrfv99kuuwc/NhXr11MKXzKEueilxIXhr6brrfJbzgAG+3atIuvrhB1+q+dln3q0/b56fr1kzOX7fpk3yC4FIlLbXRa8ELyVq7Vq49lqvRnfyyV6PvFq1qKMS2XEhwPTpyfH7YcNg/nxo2RJGj/Z73n3XN86pWzfCQCVraQxeUu6HH6BFC0/ud94J77+v5C6Zx8xb6ldd5V9Q586FqVPh//7Pr69Z49vmPv20H69fD336+JeCGLWfJANpDF5KTEEBLF/uW4WedlrU0YgUDzMfiy9UoQJ88w3ssYcfjxvnXwYAatdOjt/n5vq4v8bwJVWKpQVvZn3NbJGZTfqNe3LN7Cszm2xmw4ucvylxbpKZ9TezPRLn7zazuYnXfGVmShEZYNMm6N/fWy6HHupbgyq5S5yZQf36cOCBftyqFUyZ4i36Vq18J8Qrr4Q//tHv6dIF+vb1FSUiJalYxuDN7ARgFfByCOHIbVyvAnwOnBpCmGVm+4YQFplZbWAU0CCEsNbM3gSGhBD6mdndwKoQwiM7GofG4KP36qtecOSTT3zLT5FsF4IvuSs6hr94sX8JOOwwr+A4bRpcfDGUKxd1tJKJSnQ3uRDCCDOr+xu3XAQMDCHMSty/aKsYKpjZRqAiMK84YpLUWrUK9twTLrrIlxYpuYs4M6+Yd/jhyaqNU6Z4qx98XP/NN+HSS/34pZf8Z25usldAZFekapJdPaCqmQ0zs3wz6wIQQpgLPALMAuYDy0MIHxV53XVmNjExBFA1RbHKTggBHn/cux9//NF/mRUWDxGRXzPbsib+U0/BV18lSzU/+yxcdpnPyC8s0PPyy77BjsjOSFWCLwM0AToA7YA7zKxeImmfBRwE1AIqmVlhRelngEOAhnjy//e23tjMuplZnpnlLV68uIQ/hhS1ciVceCHceKOva69SJeqIRDKPmW97W2j0aJ+098QT0Lgx/O9/3ro/8ECfpHf55TBkSHTxSuZIVYKfA3wQQlgdQlgCjACOAU4CZoYQFocQNgIDgZYAIYSFIYSCEMJm4Hmg2bbeOITQO4SQE0LIqV69eko+jMC330KzZvDWW/Dgg/Df/yrBixSHUqXgyCPh+uu9hO6iRTBxoveUNWzoa+4//dTv3bABrr5aZZ9l21KV4N8FjjezMmZWEWgOTMG75o81s4pmZkDbxHnMrOiO4GcD252hL6n1+uue3Jcu9cl0t92mneBESkqpUnDUUb4d7sCBPkHvnnv82g8/eGXIOXP8+OuvfYneq6/6en3JbsUyyc7M+gO5QDUzmwPcBZQFCCE8G0KYYmYfABOBzUCfEMKkxGvfAsYDm4AJQO/E2/7LzBoCAfgRuLo4YpVdt2ED3Hqrdx22bOkTg2rXjjoqkexSqlRy3/vDDoMlS3yHRvDiOm+95YV2wOfGFF2HX6tWFBFLVFSqVnZIQQGceCKMGOFj7v/6F5QtG3VUIrK1ggLv0i/cHnf4cC84BV6bIjcXHnkE/vCHCIOUYqVa9LLbnnzSN4s5//yoIxGRHVWY8AvX4E+a5C39UqXgvvs8+T/8cNRRyu4o0XXwEk+bN3tL/cgj4fTTfTc4EckspUtDo0b+uPlmX9pauERvwQL4+efkvWefDTVqeCu/dWt/LplLCV62a8MGn8Dz44+e4EUk8xWthf/kk8nnmzb549VXfS0+eHGewvH71q29iJVkDnXRy69MnOhrbvfaC5Yt85/aIEMkO2zaBBMmJMfwR470mhfgBXruukvDdOlG28XKDunXz4vW3HabH1epouQukk3KlIGmTX3FzODBvhx2zBh46CH/4l+xot+Xn+/Dd/n5fhyjtmJsqIteAFi3zgtr9Onjs+X/8Y+oIxKRdFCmjNe9aNYM/vrX5PmCAq/AV7j0rlcveP75Lbv0q1WLImIppAQvzJwJ550H48dDz56e3EuXjjoqEUlnzZrBBx8kjwuTfd++ybH9o45KJvwTTlDCTzWNwWe5wYN9e9cQ4JVX4Iwzoo5IRDLZxo2Ql5dcljd6NKxZ49datfIxfTOfxKvtcYuHlsnJFgoK4O67fR1sw4Ze8/rgg6OOSkQyXdmy0KKFP3r29EQ+bpwn+zVrknN6jj0WcnKgd6J26cqVULlyZGHHkhJ8lnrqKU/ul1/u3WkVKkQdkYjEUbly3nJv1Sp5LgQfFqxb14+XL/fu+yOP3LJLv6o2Cd8t6qLPMhs3+jfs9evhvffg3HOjjkhEst3SpfD0096t//nnPunXzHsXiyZ87Vi5bSpVK7z0km/t+sUX+ociIulp/XoYOzY5hv/5537ODAYN8qJbK1Z4pU39HnMlug7ezPqa2SIz2+6WrmaWa2ZfmdlkMxte5PxNiXOTzKy/me2ROL+3mX1sZtMSP9VZs5vq1fPdp2L0nU5EYqZ8eTj+eLjzTt/3ftkyT/R33QVNmvg9L78M++wD8+b58ezZyQ11vvgCHnjAf2a7YmnBm9kJwCrg5RDCkdu4XgX4HDg1hDDLzPYNISwys9rAKKBBCGGtmb0JDAkh9DOzfwFLQwgPmlkPoGoI4bbfikMt+F+bOtWXstxwQ9SRiIgUj2++gQ8/hL/8xY87dfLtq+vVgxkzvHVfrhwMHeqT/eKuRFvwIYQRwNLfuOUiYGAIYVbi/kVFrpUBKphZGaAikPhOxlnAS4nnLwF/Ko5Ys8lbb/ks1fvv33JDCRGRTHbUUcnkDvDnP8Mdd/jY/aZNvkpowwZv+WezVJWqrQdUNbNhZpZvZl0AQghzgUeAWcB8YHkI4aPEa/YLIcxP3Dcf2DdFsWa8jRvhllugY0eflTp+vHdniYjEUYsWvuz3tddgjz28UFe5cj45L5ulaplcGaAJ0BaoAHxhZl8Ci/GW+kHAMmCAmXUOIfxnR9/YzLoB3QDq1KlT3HFnnHnz4IILYNQoLz37yCMqJiEi2aFFC++WHzbMk3s2dM//llQl+DnAkhDCamC1mY0AjklcmxlCWAxgZgOBlsB/gIVmVjOEMN/MagKLtvXGIYTeQG/wMfgS/hxpbfhwT+4rV/o32U6doo5IRCS1CovsSOq66N8FjjezMmZWEWgOTMG75o81s4pmZngLf0riNYOASxPPL028h2xDCPDww9C2rS8bGTtWyV1EJNsVSwvezPoDuUA1M5sD3AWUBQghPBtCmGJmHwATgc1AnxDCpMRr3wLGA5uACSRa48CDwJtmdgX+RaBjccQaR8uX+05OZ5/tGz2o3KOIiKjQTQb77js45BCvTDd/PtSoob3bRUSyTYkuk5PUmzULGjeGe+/145o1ldxFRCRJm81kmBA8kdepA//+t3fLi4iIbE0t+Azy00++4ULhKMQ113i3vIiIyNbUgs8QH3wAF1/sVZoWL446GhERSXdqwae5ggKv0HTaabD//t56b98+6qhERCTdqQWfxpYsgc6dfVOFLl3gmWegYsWooxIRkUygBJ+mxo2D886DBQvguefgqqs0S15ERHacuujTUN++cNxxntBHj4Zu3ZTcRURk5yjBp6G99vKys/n5vt2riIjIzlKCTxPTpsHrr/vzc8+FwYO1xauIiOw6Jfg0ceedcPPNsHq1H6tLXkREdocm2UVo0yZYtgyqVYOnn4YVK6BSpaijEhGROCiWFryZ9TWzRWY26TfuyTWzr8xsspkNT5yrnzhX+FhhZjcmrt1tZnOLXDutOGJNFwsW+Dh7hw6e6KtWhQMPjDoqERGJi+JqwfcDngRe3tZFM6sCPA2cGkKYZWb7AoQQpgINE/eUBuYC/y3y0sdCCI8UU4xpY+RIOP983+b1ueegjPpRRESkmBVLCz6EMAJY+hu3XAQMDCHMSty/aBv3tAVmhBB+Ko6Y0lEI8Oij0KaN79k+ZgxccknUUYmISBylapJdPaCqmQ0zs3wz67KNey4E+m917jozm5gYAqha8mGWnBUroGNHuOUWOPNML2Rz1FFRRyUiInGVqgRfBmgCdADaAXeYWb3Ci2ZWDjgTGFDkNc8Ah+Bd+POBf2/rjc2sm5nlmVne4jTdhWXSJGjaFN55Bx5+GN5+29e6i4iIlJRUjf7OAZaEEFYDq81sBHAM8H3ientgfAhhYeELij43s+eB97b1xiGE3kBvgJycnFAy4e+6yZOheXPvkh86FFq3jjoiERHJBqlqwb8LHG9mZcysItAcmFLkeie26p43s5pFDs8GtjtDP501aAC33goTJii5i4hI6hTXMrn+wBdAfTObY2ZXmFl3M+sOEEKYAnwATATGAn1CCJMSr60InAwM3Opt/2Vm35jZRKANcFNxxJoKs2f79q4//ugFa+6+G2rW/L1XiYiIFJ9i6aIPIXTagXseBh7exvk1wK+KsoYQMnZ++YYNPu4+bRrUrRt1NCIiko1UqraYbN4MAwb4UrhDDoHp0+Hkk6OOSkREspUSfDH45Rdf+nb++TBkiJ8rVy7amEREJLuphtpuGj/ed3+bO9fryZ8Wq4K6IiKSqdSC30UhQJ8+0LIlFBR4+dlrrtEucCIikh6U4HfB2rVwxRVw1VW+9G38eF/rLiIiki6U4HfSjBnQogW8+KLv4T5kiG/3KiIikk40Br+Trr4aZs2CwYM13i4iIulLCX4HbNoE69dDpUo+7g5a3y4iIulNCf53bN4Mp58OFSrAwIFK7CIikhmU4H9HqVJwxhneetcMeRERyRRK8NsQAvTqBQceCGedBddeG3VEIiIiO0ez6LeyahV06gQ33OD7touIiGSi4tpNrq+ZLTKz7W7pama5ZvaVmU02s+GJc/UT5wofK8zsxsS1vc3sYzOblvhZtThi/S1TpkCzZl5T/sEHoV+/kv4TRURESkZxteD7Aadu76KZVQGeBs4MIRwBdAQIIUwNITQMITQEmgBrgP8mXtYDGBpCOBQYmjguMW++CU2bws8/wyefwG23+fi7iIhIJiqWFBZCGAEs/Y1bLgIGhhBmJe5ftI172gIzQgg/JY7PAl5KPH8J+FNxxLq1DRvgxhvhggvgmGO8Kl2bNiXxJ4mIiKROqtqo9YCqZjbMzPLNrMs27rkQ6F/keL8QwnyAxM99izuouXM9mT/+uCf5YcOgdu3i/lNERERSL1Wz6MvgXfBtgQrAF2b2ZQjhewAzKwecCfxtZ9/YzLoB3QDq1KmzU6+dPRu++w7eeMO3ehUREYmLVLXg5wAfhBBWhxCWACOAY4pcbw+MDyEsLHJuoZnVBEj83Fa3PiGE3iGEnBBCTvXq1X83kM2b4dNP/fmxx8KPPyq5i4hI/KQqwb8LHG9mZcysItAcmFLkeie27J4HGARcmnh+aeI9dlufPtC2LXz5pR9Xrlwc7yoiIpJeiqWL3sz6A7lANTObA9wFlAUIITwbQphiZh8AE4HNQJ8QwqTEaysCJwNXb/W2DwJvmtkVwCwSM+931aZNUKYMXHYZ7LmntncVEZF4sxBC1DEUm5ycnJCXl/er8/36wb/+BaNGwd57pz4uERGRkmJm+SGEnK3Px3ql97p10K0bdO0KNWtCQUHUEYmIiKRGbBP8zJnQqhU8/zz07AkffQQ7MAdPREQkFmK52cyQIdC5s8+YHzTId4MTERHJJrFqwc+f793xHTr4TnD5+UruIiKSnWI1yc4sJ0AeHTr4hjEVKkQdkYiISMnKmkl2pUr52LuSu4iIZLPYJfjy5SE3N+ooREREohWrBF+7NgwdCi1aRB2JiIhItGKV4GvUUHIXERGBmCV4ERERcUrwIiIiMRSzZXK2EpgadRwpVg1YEnUQKaTPG2/6vPGWbZ8XUvOZDwwh/KpWa9wq2U3d1lrAODOzvGz6zPq88abPG2/Z9nkh2s+sLnoREZEYUoIXERGJobgl+N5RBxCBbPvM+rzxps8bb9n2eSHCzxyrSXYiIiLi4taCFxEREZTgRUREYkkJXkREJIaU4EVERGJICV5ERCSGlOBFRERiSAleREQkhpTgRUREYkgJXkREJIaU4EVERGJICV5ERCSGlOBFRERiSAleREQkhpTgRUREYkgJXkREJIaU4EVERGJICV5ERCSGlOBFRERiSAleREQkhspEHUBxqlatWqhbt27UYYiIiKRMfn7+khBC9a3PxyrB161bl7y8vKjDEBERSRkz+2lb59VFLyIiEkNK8CIiIjGkBC+yDV98AQ884D9FRDJRrMbgRYrDF19A27awbh2ULg0jRkCLFlFHJSKyc5TgRYoYNAjGj4cNGyAEKCiAYcM8wTdtCtWrQ/Pm/mjaFPbZJ+qIRUS2TQleBE/ot94KTzwBV14J5cr5uXLlIDcXNm6Eo4+GsWPhgw88+QP88Y/QrJkn/GbNoGFD2GOPSD+KiAgAFgp/U8VATk5O0DI52Vlz5sD553vX/I03wr/+BXl53nLPzf119/zKlZCfD2PGeMIfMwbmzvVrPXvC/ffD6tXw9ttwyilQo0aqP5GIZBMzyw8h5PzqvBK8ZLNPP4ULL4S1a+GFFzzR74q5cz3Z16sHRxzh4/atW8N770GHDvDVVzBgQLKlr6QvIsVlewleXfSSlTZv9pb67bdD/fre2j788F1/v9q14eyzk8etWsGkSXDggX6cnw8PPeRj+gB16iS79ps3h8aNoVKlXf/zRUS2pha8ZJ1ly+DSS31C3YUXwvPPw557lvyfu2YNTJjgXfqF3fs//ujXSpeGI4/0HoW99/YYK1f28yIiv0UteJGEBx6AIUN8Qt1114FZav7cihW9Zd+qVfLcwoUwbpwn/G+/hapV/fyNN8LIkTBjhh+PGwc1a3pPQariFZHMpha8ZI1ly6BKFW9Jf/st5Pzq+276eO89n/zXvbsf16sH06Z5ki8cx2/e3D/DH/4QbawiEi214CWr9egB77zjLeHKldM7uQOcfvqWx6++umXX/jvv+HkznzvQrJnPATjzzNTHKiLpSQlessKpp/p4dsWKUUeya5o29cd11/nx0qW+lK8w6Q8eDNWqeYJftw7atfN1/aef7hMKzdS1L5JtlOAltgYPhsmT4a9/9fXsublRR1R89t7b19ifcoofhwDr1/vzRYuSs/UBPv/cW/dFC/I0a+bvISLxpQQvsVNQAHffDffd58vPbrgBypePOqqSZZasoFenDowalbxWuTKccYa39N9/f8sqfEXH8xs18sp9IhIPmmQnsbJ4MVx0EXzyCVx+OTz5JFSoEHVU6WPFimTXfmEVvvnz/dq33/p4/hdfwPTpvoSwbNlo4xWR36dJdhJ7X34JHTt6ku/TB664IuqI0s8f/gAnnugP8NZ8YRW++vX93CuvwOuvQ+fOfvx//wc//5xs7e+7bzSxi8jOUYKXjBcCPP003HQT7L+/t0AbNYo6qsxg5v/N9t8/ea5XL5+3UDgpb/RoGDjQJ+sB1K275Xh+48aZO3lRJM6U4CWjrV4N3brBa6/5jPGXX04Wi5FdU7q0J/FCAwb4f+fx45Pd+mPGwJtvJu/v3Bn69fPjmTN9HoCq8IlESwleMtrKlTB8uO/g1qMHlCoVdUTxVKkSHH+8PwotWOB1BcaO9Qp74NvqNmgAf/6z195fv95XMzRvnrxHRFJDCV4y0qef+m5tNWrAd9+lppa8bKlGDZ+df8YZyXMFBfDcc76jHsDXX8O55/rzWrV+XYWvcuXUxy2SLTSLXjJOXp4XfXnqKfj//r+oo5Hfsn69b7BT2LU/dqzP0Acf42/QwBP+rbfu3m5+ItlMs+gl423c6Mu2cnKgf38455yoI5LfU748HHusPwr9/HNyg52xY31Xvxtv9GtvvOGT/AYO9Nn6a9f6+n5V4RPZeUrwkhGGD4euXb0G+9FH+xptyUz77OOlg0891Y+LdiKWKeNfCvbZx49vvtmTfdFZ+02baiKlyI5Qgpe0FgI88gj87W9eea2M/sbGTtHW+bnnJsfsAU46yVvxY8f6DnuF6tVLJvwWLaBJk9TFK5IpNAYvaWv5crjsMm+1d+wIL7ygSVnZbPnyX1fhW7DAk3vhP/snnvCCPe3aRRurSCppDF4yysSJ3pL78Ud47DGvJ69x2Oy2117Qtq0/wHt35syBJUuSx//8p38ZbNcONm3yTXYaNUq29qtXjy5+kVQr0QRvZgcALwM1gM1A7xDC41vdY8DjwGnAGuCyEML4HXmtxNMrr8DVV0OVKvDZZ3DccVFHJOnIDA44wB+Fx3PmwJo1frxwIcyaBUOGJKvwHXTQr6vwaa8CiauSbsFvAm5JJOzKQL6ZfRxC+LbIPe2BQxOP5sAziZ878lqJmZtv9hZ7bq7PlK9RI+qIJJOUKeP19sEL63z9Naxa5VX4Crv2P//cZ+sX3v/KKz5pc9kymDcPDjtMBZMkHko0wYcQ5gPzE89XmtkUoDZQNEmfBbwcfDLAl2ZWxcxq7uBrJWYaN/Y66Pffrwl1Ujz23BNOOMEfhebP92Q/diw0bOjn3n/fdyIcP9679SdMgJ9+8pZ+rVrRxC6yO1L2K9TM6gKNgDFbXaoNzC5yPCdxbv4OvBYz6wZ0A6hTp07xBSwp8+GHPo568cXJHcxESlLNmnDWWf4o1Lo1vPgiHHmkH/fr55P2wDfjKVqFr0kTVU+U9JeSWfRmticwHLg/hDBwq2uDgQdCCKMSx0OBv4YQ8n/vtVvTLPrMEwK0b+/do59/rq5RSR9r18JXX205a/+HH/xaqVJejrdFC3j2WU0AlWhFNovezMoCbwOvbidBzwEOKHK8PzBvB18rGernn70yXY0avhPcHnsouUt6qVDBE3iLFslzS5ZsWYVv6tRkcj/nHC/Q8/zzfrxokc/aV/KXqJT0LHoDXgCmhBAe3c5tg4DrzOx1fHLd8hDC/B18rWSgcePgvPO8WMnHH8Pee0cdkciOqVbNe5zat//1tSOPTNZpKCjwwkwVK/66Cl+VKqmNWbJXiXbRm9lxwEjgG3ypG0BPoA5ACOHZRCJ/EjgVXybXNYSQt73XhhCGbO/PUxd9egsBevf2rURr1oS33vK68iJxs369F2YaM8YfU6cmr9Wvn0z47dr5FwGR3bG9LnpVspOUWLMGrrkGXn7Za5D/5z/JeuMicbdsmfdcFY7ljxnjXfiPPgo33eSz+h980HdHrF8/6mgl06iSnURm2jSvSjdpEtxzD/z97xpvl+xSpQqcfLI/wHuzZs3yLnzwFv7zz/tKEvC6+089lWzpN2vmwwMiO0MJXkrUO+/ApZf6mvb331eNcBHwiXcHHpg8zs2FFSuSE/LWrPGqfB9+mNxt7+CDt1yq16iRT04V2R510UuJ+eQTb7E0bQoDBmz5C01Eft/KlZCfn+zaHzvWEz9AuXK+GmXPPX3vhvLl1b2frdRFLykTgrdETjwRevWCq67yXz4isnMqV/bWfW5u8ty8eZ7op01LFtvp2RNmzoTJk/34xRd9dUqzZj6hVbKTWvBSrMaMge7dfQyxdu2ooxHJDlOnwuLFvjFTCJ7UFy70awccsOVSPVXhix+14CUl9trLJ9CtWKEEL5Iq9esnu+fNvDU/YcKWVfjeftuvlyrla/avuca/jIOv2y9dOprYpeQowctuW7HCl71dc43vxJWXp+pdIlGqUAFatvRHocWLtxzLL9xCd+FCOOQQn8XfqROsXg1Ll3r9ff07zmxK8LJbJk/2JXDTp0OrVnDMMfqlIJKOqleHDh38UdSmTXD55f7lHLy65NlnexnporP2c3K8h04yhxK87LLXXvMJdJUrw9ChntxFJLPUrp3cNQ98+V2vXsmW/rvv+nkz/xJQmPQ7dVLZ3XSnSXay0zZsgFtugSefhOOPhzfe0Exdkbj65ZdfV+FbvDi5mc6rr/pSvkceUQGYG/mqAAAgAElEQVSrqGiSnRSL2bOhY0f/R37LLfDAA1C2bNRRiUhJqVoVTjnFH+Cz9OfM8eQOPkw3dGgyuXft6sm/sGu/aVOVpY6KErzssE8+8W659eu9cM1550UdkYikmpkvvSv0z3/C/fcnj6tX9xb/++8nq/D98Y9bLtVr2FBV+FJBXfSyQwoKfP3spk2+3EYVs0Tkt6xc6Stqis7cnzvXr515ZnJs/+23vZVfp050sWY6ddHLLvnlF++C33NPGDTIu9oqVYo6KhFJd5UrQ5s2/ig0d64n+sLZ+EuXek/gAw9Ajx5eevexx5It/f32iyb2uFCCl+1au9b/kbVo4du86hu2iOyO2rV9CV6hKlXgm298nB98PP/BB73HEHz/iq2r8BXuwCe/TwletqtCBbj5ZmjcOOpIRCSOCqvqFTrhBFi+3KvwFe3aHzDAr5cu7ff36+fj+GvX+qY7qsK3bUrwsoW1a+H6632mfLt2Xp1ORCRVKlXymvrHHZc8t3Dhlkv19t3Xzz/zDNx1l6/uqVLFN+D57juYNMk36GnRIpKPkDaU4OX/mTHDx8O++son0WnvdhFJB/vtB6ef7o+imjaFG25IFtzp1g1GjfLZ++XK+fK9bE7yKksgAPzvfz6+9dNPMHgw3Hpr1BGJiPy244+H++5LHh95pNfYLyjwglzDhkUWWlpQgs9ymzb5XtJnnulrVcePh9NOizoqEZGdd9FFUL68j8mXK+fd9NlMXfRZbNEiL1zz6afetfX44yo+ISKZq0UL75YfNkxj8KAEn7W+/NJ3gVu6FF58ES67LOqIRER2X4sWSuyFlOCz1Pr1Xohi8GBfbiIiIvGiMfgssmpVcj1p69a+lETJXUQknpTgs8hDD/kklJkz/biM+m9ERGJLCT4LrFzpP3v29MknBx0UaTgiIpICSvAxtmED3Hgj5OTAihVeerZVq6ijEhGRVFCCj6m5c30Xp8cf93XtFSpEHZGIiKSSRmFj6NNP4cILYc0aeOMNOP/8qCMSEZFUUws+RjZv9q0WTz4ZqlXzzRmU3EVEspNa8DGxbBlceikMGgQXXAB9+sCee0YdlYiIRKVEW/BmdoCZfWZmU8xsspndsI17zMyeMLPpZjbRzBoXuXaqmU1NXOtRkrFmsmXLfKOYIUPgiSegf38ldxGRbFfSLfhNwC0hhPFmVhnIN7OPQwjfFrmnPXBo4tEceAZobmalgaeAk4E5wDgzG7TVawXfKvGii6B9e2jZMupoREQkHZRoCz6EMD+EMD7xfCUwBai91W1nAS8H9yVQxcxqAs2A6SGEH0IIG4DXE/cKsG4dXHut790OcO+9Su4iIpKUskl2ZlYXaASM2epSbWB2keM5iXPbOy/4uvZ334Xhw6OORERE0lFKJtmZ2Z7A28CNIYQVW1/exkvCb5zf+r27Ad0A6tSps5uRpr9Ro+DYY2HffWHyZNhrr6gjEhGRdFTiLXgzK4sn91dDCAO3ccsc4IAix/sD837j/BZCCL1DCDkhhJzq1asXX+BppqAA7rwTjj8eevXyc0ruIiKyPSU9i96AF4ApIYRHt3PbIKBLYjb9scDyEMJ8YBxwqJkdZGblgAsT92adJUt8At2990LXrtC9e9QRiYhIuivpLvpWwCXAN2aWmA5GT6AOQAjhWWAIcBowHVgDdE1c22Rm1wEfAqWBviGEySUcb9r58kvo2BEWL/a17VdcEXVEIiKSCUo0wYcQRrHtsfSi9wTg2u1cG4J/Acg6IcDTT8NNN0Ht2vD559C48e+/TkREBFSqNi2tXg2dO8N118Epp0B+vpK7iIjsHCX4NHTrrfD663D//V56du+9o45IREQyjWrRp5ENG6BcOfjHP+C88+DEE6OOSEREMpVa8GnijjugbVvYuNF3glNyFxGR3aEWfJpo0AB++cUn14mIiOwuteAjNHw4vPqqP+/UCZ580rvoRUREdpcSfARCgIcf9i75hx+GTZuijkhEROJGCT7Fli+Hc86Bv/4Vzj4bRo6EMhooERGRYqYEn0ITJ0JODrz3Hjz2GLz5JlSuHHVUIiISR2o7psgrr8DVV0OVKvDZZ3DccVFHJCIicaYWfAlbvx6uuQa6dIHmzWH8eCV3EREpeUrwJWzWLJ8pf9tt8PHHUKNG1BGJiEg2UBd9Cfn6azj6aDj0UPj+eyV2ERFJLbXgS8CIEdCoEbz2mh8ruYuISKopwRejwip0xx0Hjz7qy+BERESioARfTMaNg2bNYPZsKFUKbrwRKlaMOioREclWSvC7KQR47jlvtS9aBEuXRh2RiIiIEvxuWbMGLrsMunf33d/Gj4djjok6KhERESX4XTZtGrRo4QVs7rkHBg+GffaJOioRERGnZXK74J134NJLvYb8++9Du3ZRRyQiIrIlteB3Us+ePju+fn3vkldyFxGRdKQEv5MqV/bSsyNHwoEHRh2NiIjItqmLfgeMHOk15U86CXr0ALOoIxIREfltSvC/Y/NmuOkmKFsW2rZVchcRkcygBL8dK1Z4Mq9cGQYOhL32UnIXEZHMoTH4bZg82avSdevmx3XqeIIXERHJFErwW+nf35P7smVewEZERCQTKcEnbNgA118PF10EjRvDhAnQunXUUYmIiOwaJXh8g5jWreHJJ+GWW+DTT6FmzaijEhER2XVZP8nuk0+gUydfBjdgAJx3XtQRiYiI7L6sbsEPGQKnnAL77efbvSq5i4hIXGR1gj/xRPj732HMGC89KyIiEhclmuDNrK+ZLTKzSdu5XtXM/mtmE81srJkdWeTaTWY22cwmmVl/M9ujOGKaMAFOPRWWL4c99oB//AMqVSqOdxYREUkfJd2C7wec+hvXewJfhRCOBroAjwOYWW3gz0BOCOFIoDRwYXEEtGoVfP89zJ1bHO8mIiKSnko0wYcQRgBLf+OWBsDQxL3fAXXNbL/EtTJABTMrA1QE5u1qHGvXejU6gOOPh6lToUGDXX03ERGR9Bf1GPzXwDkAZtYMOBDYP4QwF3gEmAXMB5aHED7alT9gxgxo2RI6dvSWO3hdeRERkTiLOsE/CFQ1s6+A64EJwCYzqwqcBRwE1AIqmVnnbb2BmXUzszwzy1u8ePEW1/73P2jSBH76CQYNgnr1SvSziIiIpI1IE3wIYUUIoWsIoSE+Bl8dmAmcBMwMISwOIWwEBgItt/MevUMIOSGEnOrVqwOwaRP07AlnngmHHAL5+dChQ2o+k4iISDqINMGbWRUzK5c4vBIYEUJYgXfNH2tmFc3MgLbAlB15z0WLoF07eOABuOoqGD0aDjqoZOIXERFJVyVayc7M+gO5QDUzmwPcBZQFCCE8CxwOvGxmBcC3wBWJa2PM7C1gPLAJ77rv/Xt/3k8/wRFH+Ez5vn2ha9cS+FAiIiIZwEIIUcdQbMxyglkeL74Il14adTQiIiIlz8zyQwg5W5+PepJdsStVCubt8oI6ERGReIhdgi9XDnJzo45CREQkWrFK8LVrw9Ch0KJF1JGIiIhEK1YJvkYNJXcRERGIWYIXERERpwQvIiISQzFbJmcrgalRx5Fi1YAlUQeRQvq88abPG2/Z9nkhNZ/5wBBC9a1PlmihmwhM3dZawDgzs7xs+sz6vPGmzxtv2fZ5IdrPrC56ERGRGFKCFxERiaG4JfjfrVcfQ9n2mfV5402fN96y7fNChJ85VpPsRERExMWtBS8iIiIowYuIiMSSEryIiEgMKcGLiIjEkBK8iIhIDCnBi4iIxJASvIiISAwpwYuIiMSQEryIiEgMKcGLiIjEkBK8iIhIDCnBi4iIxJASvIiISAwpwYuIiMSQEryIiEgMKcGLiIjEkBK8iIhIDCnBi4iIxJASvIiISAyViTqA4lStWrVQt27dqMMQERFJmfz8/CUhhOpbn49Vgq9bty55eXlRhyEiIpIyZvbTts6ri15ERCSGYpXgFyyAL76IOgoREZHoxSrBz50LbdsqyYuIiMQqwQOsWwcffhh1FCIiItGKXYIPAfr1g2+/jToSERGR6MQqwdeuDU8+CWvXQrNm8PrrUUckIiISjVgl+Bo14NprYcIEaNgQOnWCG26ADRuijkxERCS1YpXgC9WqBZ99BjfdBE88Abm5MGdO1FGJiIikTiwTPEDZsvDoo/Dmm/DNN9C4MUyfHnVUIiIiqRHbBF+oY0cYNw4uuAAOOijqaERERFIj9gke4LDDoFcvKF3a18pfdhn88kvUUYmIiJScrEjwRX35JQwaBAsXRh2JiIhIycm6BH/uuTBzprfqQ4Bhw6KOSEREpPhlXYIH2Gsv/zloELRpA1de6WvnRURE4iIrE3yh00+H22+HF16AVq3ghx+ijkhERKR4ZHWCL10a7rsP/vc/77Zv0gTeey/qqERERHZfVif4QqefDvn5vozujDPg73+HgoKooxIREdl1SvAJBx8Mo0fDFVfA/fdDu3aweHHUUYmIiOwaJfgiKlSAPn18TH70aOjSJeqIREREdk2ZqANIR5dfDo0aQaVKfrxhg5e+NYs2LhERkR2lBL8djRr5zxC88l2ZMvDSS0ryIiKSGZTgd8BRR3liV3IXEZFMoQT/O8zgb39LHn/0ESxf7pvYiIhIevn8cxg+3LcJb9Ei6miipQS/k3r18rXyN90EDz3kY/MiIhKtBQvgxBNhxgxf5lyuHAwdmt1JXrPod9Lbb8P118Njj/lfpnnzoo5IRCT7hABjxsCAAX68776weTNs2uQJfsMG7TWiBL+TypWDJ56A116D8eOhcWPvDhIRkZK3dKn/Dj76aDj2WLj1Vk/spUrBiy9C+fJepbRcOe+mz2ZK8LuoUycYOxaqVIG2beHhh/0bpYiIFK8Q4LPP4OKLoVYtuOEGr1vSuzdMnOjJHbw7fuhQuPdedc8DWIhRVsrJyQl5eXkp/TNXrvTqdwMGwJ/+BP36JXerExGRXbdkiRce69MHpk/3BlXnzr4D6DHHRB1d+jCz/BBCztbn1YLfTZUrwxtv+Jj8++/7t0kREdk1BQXwyy/+fNYs6NHDW+2vvOJznnr1UnLfUWrBF6MFC6BGDX/+9df6SygisjM2b/ax9Zwc7w0F38b74IMjDSvtpVUL3sz6mtkiM5u0netmZk+Y2XQzm2hmjVMd464oTO6jRkHDhvCf/0Qbj4hIOtuwwVcmde/u4+ylSvnzs89O3qPkvuuiWgffD3gSeHk719sDhyYezYFnEj8zwrHHepf9uef6cQiqgiciUuj7731c/aWXYNEi2H9/7wGtWROuuy7q6OIjkhZ8CGEEsPQ3bjkLeDm4L4EqZlYzNdHtvjJl4MYbfZbnihXQqhV88EHUUYmIRGftWu/VbN0a6teHRx+Fli29cNiPP3pyl+KVrpPsagOzixzPSZzLOMuWwerVcNppcPfdPoFERCRbLF/uxcFq1YJLLoE5c+Cf/4TZs+G//4UOHXzduhS/dE3w2+rQ3uZsQDPrZmZ5Zpa3ePHiEg5r59WpA1984X+x77nH/zIvWRJ1VCIiJWflSi8EBlCxorfS27f3tenTpvn+Hmqxl7x0rUU/BzigyPH+wDaLwoYQegO9wWfRl3xoO69iRZ8R2qqVf5Nt0gTeeguaNo06MhGR4nfJJZCf713vZcv6mLv27Ui9dG3BDwK6JGbTHwssDyHMjzqo3WEG3brB6NH+/Ljj4NlnVf1ORDJbYenYRo282x3g9tu9+FdhhTkl92hE0oI3s/5ALlDNzOYAdwFlAUIIzwJDgNOA6cAaoGsUcZaEnBz/Ztu5M1xzjW9t2LevT8wTEckEIfgeHM8/78vc1q/3HslFi+CAA9Q7mS4iSSshhE6/cz0A16YonJTbZx8YPBjuuw/mz1dyF5HMsHChDzcWLR171VUqHZuulFoiUqoU3Hlnsov+66+9YlPRAg8iIukgBN/oZcAA3471hBP899d55/lyYElP6ToGnzUKC+A8+KBPwFu9Otp4RETAx9Ofe86fm0H16l7f47vvvHv+kkuU3NOdWvBpol8/n3FaqZJ/Q166FPbdN+qoRCSbbNzorfVy5Xylzy23QLt2ULcuPP541NHJzlILPk2UL+/VnQDuustr2Y8cGW1MIpIdpk2D227zkrH9+/u5rl192LBu3UhDk92gBJ+GLrwQ9twT2rTxco5aSicixW3tWnj1VcjNhXr14N//9tKxhx7q16tUUXLPdErwaeioo2DcODjzTO8i69jRa9qLiOyuiRPhz3+G2rV9ue7s2VuWjm3ZMuoIpbgowaepvfby9aUPPwzvvOPrSidtc3NdEZEdc801vpztued8bF2lY+NNCT6NmcFf/uL/CJcvh+bNvUtNRGRHzJjhFTQLt+no0MG3sp43z8faTzwxWW1O4kf/azNA69YwYYLXsO/cGZ55JuqIRCRdLV0Ks2b583Xr4LXXkhu/nH66L3XbZ5/o4pPUUYLPEDVrekv+nnu8uISISKEQYNgwbwDUqgU9evj5I47w6nPt2kUankRECT6DlC3r1aOqV/f1quecAx9/HHVUIhKVhQvhoYd8FnybNr4t65VX+pK3QpUqRRefREuFbjLUkiU+OaZwbE1EskNBAXz0kdeDHzTIC2Mdf7xKx8qvKcFnqJo1fVe6cuX8+IMPoFkz2HvvaOMSkZL12GNw663J0rFXXpkskiVSlLroM1hhcl+2DC64wCfh5edHG5OIFK9Fi6B9exg40I8vusg3fZkzx5fRKrnL9ijBx0CVKj4WX1AArVp5152q34lkrmnTvFcOfMb78uWwZo0f16rlXfGFX/BFtkcJPiaaNfOlMK1b+/7MV1zhpShFJDOsW+d1Ltq08UlzV10FmzdD6dLw+ec+Q15kZyjBx0i1ajBkiE+2efFFaNHCC12ISPr65hsvHVurlifxWbO8dOzYsSpCI7tHf31ipnRpXys/eLD/omjSxGfaikj6WLXKh9KaN4ejj1bpWCkZSvAxddpp3mX/xz96q+Dnn6OOSCS7hZAcNps82bvgV61S6VgpOVomF2N168KoUb571D77+C+YFSt8IxsRSZ0QfJe2o46C3r19zsy4cd7DZhZ1dBJX+q4Yc3vs4b9MwLsBGzSAn36KNiaRuAsBhg+Hnj392AzOOAOOOy55nJOj5C4lSy34LHLssXDWWXDAAVFHIhJPCxfCSy/5+Pq0ad5bdu21vvd6YbIXSRW14LNIw4bw9NM+xjdnDlx9NaxcGXVUIpmtoMDXrJ97Luy/v9eB328/T/Tz5nlyF4mCWvBZavhwb2WMGAFvv+1d9yKy41auhEcfhb59fcVKtWpwww1eOvaww6KOTkQt+Kx18cXwySe+d3SzZvD661FHJJL+Nm6E77/35+XKeY/YYYfBm2/C3LnwyCNK7pI+1ILPYm3a+FK688+HTp3giy+8trVKYIpsW6dO/m9m+nQoX95/Vq4cdVQi26YWfJarXRuGDfNdqZ54AnJzfXxeJNutWwevvQYnnQTz5/u5P/8ZevVK3qPkLulMCV4oW9aLbbzxhpfNbNzYK2qJZKNvvvGx9Fq1fChr5kx/AJxwAnTooGI0khn011T+n/PP9/rX1ar5T5FsUVg69thjvXTss8966dhPPvHlbi1bRh2hyM7TGLxs4fDDvcJWhQp+PHYsHHooVK0abVwiJSEEuO46ePllT/INGnhvVufO/kVXJJOpBS+/UqmSd0GuXeuFcbp2jToikeKzdKnPegevJLd6NXTsCKNHw6RJPh9FyV3iILIWvJmdCjwOlAb6hBAe3Op6VaAvcAiwDrg8hDAp5YFmsQoVYODA5C+7jRt9vF4k04SQ3Fv9+eehRw8vFXvwwdCvX9TRiZSMSFrwZlYaeApoDzQAOpnZ1qVWegJfhRCOBrrgXwYkxVq08C76EOCSS3wHrHXroo5KZMcsXAj/+hfUr++TSAGuuMKXuh18cLSxiZS0qLromwHTQwg/hBA2AK8DZ211TwNgKEAI4Tugrpntl9owpVAIcMghPhGpVavkrGKRdLO90rGFPVHVqkGjRtHGKJIKUSX42sDsIsdzEueK+ho4B8DMmgEHAvunJDr5lVKl4P77YdAgmDHDl9INHhx1VCJJs2fDPfd4y7x9ey/DfMMNMGUKjBwJp5wSdYQiqRVVgt/WJolhq+MHgapm9hVwPTAB2PSrNzLrZmZ5Zpa3ePHi4o9UtnDGGd69WbcunH463HGHt5hEonTrrXDggZ7gVTpWxEWV4OcARTct3R+YV/SGEMKKEELXEEJDfAy+OvCrjuEQQu8QQk4IIad69eolGbMkHHwwfP45XH453HcfnHoq6LuVpNLcufC3v8Evv/hx06Zw++3eu/Thhz4rXiWXJdtFleDHAYea2UFmVg64EBhU9AYzq5K4BnAlMCKEsCLFccp2VKgAL7zgY/IjR3qX/dSpUUclcbZuHSxa5M8XLfJ9E0aN8uPzz4d774WDDoouPpF0E0mCDyFsAq4DPgSmAG+GECabWXcz65647XBgspl9h8+2vyGKWOW3XXGFt+abNYM6daKORuJo0qRk6dhbb/VzjRr5XutnnBFtbCLpzELYeug7c+Xk5IS8vLyow8hqK1Z4S+ruu71gjsiuWLXKl7U9/zyMGePd7eecA1df7RsiiUiSmeWHEHK2Pq9KdlKshg71XekmTow6Esk0IXhp5G7doGZNuPJK/8L46KM+5t6/v5K7yM5QLXopVmef7ROd9k8saPz2W6/vLfJ7nnjCy8RWrAgXXOAJvkULLycrIjtPLXgpdoXJfdgwOPJIuOUWL3MrUtTPP3t1xCFD/PhPf4JnnvGx9b59fQc3JXeRXacELyWmZUvfqevRR+HEE/0Xt2S3hQuTM9/32gvy8rxADfg69u7d/byI7D4leCkx5cp5t+trr3lxnMaNYfjwqKOSVCssHXveed6706mTb/xSpgxMnuwT50Sk+CnBS4nr1MknT1WpAm3b+vrlGC3ekO3YunTs8OG+3O2jj7z0MSR/ikjx0yQ7SYkjjoBx43zd/F//6mvn+/VTd2zcbNwI773nBZA++MBb6ief7CVjzzwTypePOkKR7KEELylTubKvbW7Z0guWnHWWT8STzFdQ4Hutjxnj69Vr1YKePb2csarLiURDCV5SysyXQjVtmuyeDUGzpTNVCNChg28l3KuXbyX80UfQpo2PsYtIdDQCJpFo1crXOAP06OGzpzdvjjYm2TGTJnmXO/gXs6OPhkMPTR6ffLKSu0g60D9DiVQI3pIvXVoTrtJZYenYPn3gyy99hcSFF/qs+AcfjDo6EdkWJXiJlBk88EByVv2ECb5W+tRTo41L/P9JXp7Xg+/f35P84Yd7XYNLLoFq1aKOUER+i9pMkhYKx+D/8Q847TRfXqUu+2isXQtPPgkNG/ougf/5j69hHz3a163fdJOSu0gmUIKXtPLqq946vPtun7z1889RR5QdQkhWGjSDO++EsmW9dOz8+fDiiyodK5Jp1EUvaaViRV8f36oVXH+9V7976y2fdS8lp0sXX+I2dSrssYe31GvWjDoqEdkdasFL2jHzLUNHj/bnxx0Hzz2n6nfFpaAAPvwQzj8fFi/2c507w+23+zVQcheJAyV4SVs5OZCf7xvVdO8Ol10Ga9ZEHVXmmj3b5zgcfLBPYvz0U2+pA7RrB5dequVtInGiBC9pbZ99YPBgn3T3yivwySdRR5RZNm6E//7X5zPUrQt33QX16/uSt7lzITc36ghFpKTo+7qkvVKlfNLX+efDYYf5udmz4YADoo0rnYXg/8369IEFC1Q6ViQbqQUvGaMwuU+c6JXT+vWLNJy0s25dsofDDL791pe5/e9/8NNPcO+9Su4i2UQteMk49evDLbfA6adHHUl6KKzl/9hj3kqfMcPH2QcMUHVAkWymf/6SccqXh/vv92IrGzZ4EZaRI6OOKrVWrYK+fb2e/9tv+7muXeHjj32sHZTcRbKdfgVIRluwAL7+2ncve+yxeC+lCwHGjYOrr/Yx9SuugOXLvY4/QI0acNJJSuwi4vSrQDJanTpeL/3MM+Hmm30i3ooVUUdVvJYtg6eegkaNfEz9lVfg3HOTpWPPPjvqCEUkHSnBS8bbay/vpn74YV8S1qxZcn13pvvHP7zozHXXeUtdpWNFZEcpwUssmMFf/gJDh3qLt1kzeO21qKPaeT//7HutF/ZC1KnjY+v5+f7o3t2/0IiI/B4leImV1q19y9nGjeHii73lu3Fj1FH9toICH0sHnwF/660+WQ68et/TT/vnERHZGUrwEjs1a3oZ1ltugR9/TE5CSzdz5ngX/CGHeFIH31Tn++99jF1EZHdoHbzEUtmy3tW9aZPPKp8923dKO+mkaOPauNFL7z7/PHzwge95f9JJcNppft3Mi/iIiOwuJXiJtcLNU+64A959F2bOhCpVUh/HjBleNrZfv2Tp2L/9zZe6qbqciJQEJXjJCk895RPUqlTx9eSrVkHlyqn5s597zv/s0qV905crr4T27bVzm4iULI3BS1aoVAmOPdafP/UUHH20z0ovCcuWwU03+TwAgLZt4b77YNYs70U44wwldxEpeZEleDM71cymmtl0M+uxjet7mdn/zOxrM5tsZl2jiFPip2lTn7neqpV3mxdH9btVq7yiHkDFil4HvvD4j3+E22/3bnkRkVSJJMGbWWngKaA90ADoZGYNtrrtWuDbEMIxQC7wbzMrl9JAJZaaN4fx4+GEE+Cqq3wcfO3anX+fELyKXmHp2D/9ySfNlSvnY+433VT8sYuI7KioWvDNgOkhhB9CCBuA14GztronAJXNzIA9gaXAptSGKXFVrRq8/77vmf7ii75py4wZO/baoqVjmzb10rHnnAP/+U+yslz58iUXu4jIjogqwdcGZhc5npM4V9STwOHAPOAb4IYQwuat38jMuplZnpnlLV68uKTilRgqXRruuceXrc2aBU2a+N7p2xKC71jXpcuWpWOfftpLx/br513+Kh0rIukiqqk+2/Exo/YAACAASURBVPo1uPVIaDvgK+BE4BDgYzMbGULYYiuREEJvoDdATk5OjPcSk5Jy2mk+4e6883zTmsLW+bBhXhmvZUsYNcq79P/wBy8de+WVqi4nIuktqgQ/BzigyPH+eEu9qK7AgyGEAEw3s5nAYcDY1IQo2eSgg3x3tttug+rVfeb72rU+233ECG+dv/aafwGoVCnqaEVEfl9UXfTjgEPN7KDExLkLgUFb3TMLaAtgZvsB9YEfUhqlZJU99oDHH4fp02HDBj9XUOAt+VKloFMnJXcRyRyRtOBDCJvM7DrgQ6A00DeEMNnMuieuPwvcC/Qzs2/wLv3bQghLoohXskturs+E37DBf+bmRh2RiMjOs1Aci4DTRE5OTsjLy4s6DImBL77wlnturs+wFxFJV2aWH0LI2fq86mmJbEOLFkrsIpLZVKpWREQkhpTgRUREYihWY/BmthKYGnUcKVYNyKbJh/q88abPG2/Z9nkhNZ/5wBBC9a1Pxm0Mfuq2JhrEmZnlZdNn1ueNN33eeMu2zwvRfmZ10YuIiMSQEryIiEgMxS3B9446gAhk22fW5403fd54y7bPCxF+5lhNshMREREXtxa8iIiIoAQv8v+zd9/xUdXZ/8dfhwAWVEApIsWgxoIVjBQLVlQsC6ioiGLhK4uKdS2ga1sbyrpWxLordrGCrisqihWQxIIgAgEUokgRQURayOf3x5n8EkNCElJu5s77+XjMY+beuTc581By5tPOR0QklpTgRUREYkgJXkREJIaU4EVERGJICV5ERCSGlOBFRERiSAleREQkhpTgRUREYkgJXkREJIaU4EVERGJICV5ERCSGlOBFRERiSAleREQkhpTgRUREYkgJXkREJIaU4EVERGJICV5ERCSGlOBFRERiqG7UAVSlJk2ahPT09KjDEBERqTHZ2dlLQghNi5+PVYJPT08nKysr6jBERERqjJn9UNL5KumiN7NjzWyGmeWY2eAS3jczuz/x/hQz61DWvWa2rZm9a2azEs+NqyJWERGRVFDpBG9macBwoDvQDuhjZu2KXdYdyEg8BgAjynHvYGBcCCEDGJc4FhERkXKoihZ8RyAnhDAnhLAWeAHoUeyaHsBTwU0EGplZizLu7QGMTLweCfQsK5Cff4YJEyr/gURERJJdVST4lsD8Ise5iXPluWZj9zYPISwASDw3KyuQH3+EI45QkhcREamKBG8lnAvlvKY89278l5sNMLMsM8sCWL0a7r23Ij9BREQkfqoiwecCrYsctwJ+Kuc1G7t3YaIbn8TzopJ+eQjh0RBCZgghE6BOHRg1CgYNgjVrNvETiYiIJLmqSPCTgQwza2tm9YHTgTHFrhkD9EvMpu8MLE90u2/s3jHA2YnXZwOjywqkZUsYPx6uvBKGD4dDD4X588u6S0REJH4qneBDCHnAIGAsMB0YFUKYZmYDzWxg4rK3gDlADvAYcOHG7k3cMxToZmazgG6J443afns45BAYNgxeeQW+/Rbat4d3363spxQREUkuFkKFhrxrtczMzFC00M3MmXDyyTBtGvzjH3Dttd6FLyIiEhdmll0wTF1UrNPdrrvCxInQty/cfjvMnh11RCIiIjUj1gkeoEEDeOop+OoryMjwc/PmRRuTiIhIdYt9ggcw89Y8wHPP+evPP482JhERkeqUEgm+qKOP9ln2++8fdSQiIiLVJ+USfJMmcOutkJbmpW27d4ecnKijEhERqVopl+CLmj0bJk2CzEwYXeYqexERkeSR0gn+oIPgiy9gl12gZ08YMgTy8qKOSkREpPJSOsEDpKfDJ5/AgAEwdKiP0S9cGHVUIiIilZPyCR5g883hkUfgP//xneg6dIDPPos6KhERkU2nBF/EOed4YZwttvA69g88EHVEIiIim0YJvph994WsLDjuOFi8OOpoRERENk3dqAOojRo1gtdeg4Iy/Z99Bo0bwx57RBuXiIhIeSnBl6JgU5r8fLjgAthsM19SZxZtXCIiIuWhBF+GOnXgrbdg5UpP7qtWeZGc+vWjjkxERKR0GoMvh5YtC2vZX3ABHH44/PhjtDGJiIhsjBJ8BR13HHz9NbRvD++/H3U0IiIiJVOCr6BTT4XJk72mfbduXhwnPz/qqERERP6sUgnezLY1s3fNbFbiuXEp1x1rZjPMLMfMBpd1v5mlm9kqM/sq8Xi4MnFWtT328O1mTz3Vy9v26gXLlkUdlYiISKHKtuAHA+NCCBnAuMTxn5hZGjAc6A60A/qYWbty3D87hLBf4jGwknFWua228r3l77/fJ+Htvz989VXUUYmIiLjKJvgewMjE65FAzxKu6QjkhBDmhBDWAi8k7ivv/bWWGVx8MXz0EaxZA126wPjxUUclIiJS+QTfPISwACDx3KyEa1oC84sc5ybOlXV/WzP70sw+NLNDKhlnterSxXelO/ts33pWREQkamUmeDN7z8ymlvDoUda9BT+ihHOhjHsWAG1CCO2BK4DnzGybUuIbYGZZZpa1OMLass2awcMPe9f9ypVw5pkwd25k4YiISIorM8GHEI4KIexVwmM0sNDMWgAknheV8CNygdZFjlsBPyVel3h/CGFNCOGXxOtsYDawaynxPRpCyAwhZDZt2rQ8n7naTZ8Ob78Ns2dHHYmIiKSqynbRjwHOTrw+GxhdwjWTgQwza2tm9YHTE/eVer+ZNU1MzsPMdgIygDmVjLXGZGZ66/2oo/z4ww9h/fpoYxIRkdRS2QQ/FOhmZrOAboljzGwHM3sLIISQBwwCxgLTgVEhhGkbux/oCkwxs6+Bl4GBIYSllYy1Rm29tT9PneqV77p3hyVLoo1JRERSh4VQ1nB48sjMzAxZWVlRh7GBJ56Aiy7ycfqXXoJOnaKOSERE4sLMskMIG0zxViW7GtC/v285W7cuHHIIPPRQ4Va0IiIi1UEJvoZ06ADZ2XD00d6aP+ssn20vIiJSHZTga1DjxjBmDNx6q1fB69QJZsyIOioREYkjJfgaVqcOXHcdjB0LCxfCCSdAXl7UUYmISNzUjTqAVNWtm1e/+/FHH5tfv953patXL+rIREQkDtSCj1Dr1tC5s7++5RY44giNy4uISNVQC76W2HVXWLwYttwy6khERCQO1IKvJc44A4YP9x3qpk2Du+/WUjoREdl0SvC10MiRcOWVcPLJsHx51NGIiEgyUoKvhe68E+65B954w+vaT5kSdUQiIpJslOBrITO47DL44AOfdNe5Mzz9dNRRiYhIMlGCr8UOPtiX0nXqBP36wQUXwJo1UUclIiLJQAm+ltt+e3j3XbjmGnj4YU/6P/wQdVQiIlLbKcEngbp1YehQeO01mDkTxo+POiIREanttA4+ifTs6Qm+eXM//uor2GcfL38rIiJSlFJDkilI7vPmwYEHwvXXRxuPiIjUTpVK8Ga2rZm9a2azEs+NS7nuWDObYWY5Zja4yPneZjbNzPLNLLPYPUMS188ws2MqE2cctW7thXEuvtiPVRRHRESKqmwLfjAwLoSQAYxLHP+JmaUBw4HuQDugj5m1S7w9FTgJ+KjYPe2A04E9gWOBhxI/RxLM4NxzfRJeXh4cfzw88ogSvYiIuMom+B7AyMTrkUDPEq7pCOSEEOaEENYCLyTuI4QwPYRQ0o7oPYAXQghrQghzgZzEz5ESrFrliX3gQDjnHPjjj6gjEhGRqFU2wTcPISwASDw3K+GalsD8Ise5iXMbsyn3pKytt4b//hduvtkL4nTuDLNmRR2ViIhEqcwEb2bvmdnUEh49yvk7rIRzZXUkl/seMxtgZllmlrV48eJyhhQ/derADTfA//7ne8xnZsLrr0cdlYiIRKXMBB9COCqEsFcJj9HAQjNrAZB4XlTCj8gFWhc5bgX8VMavLfc9IYRHQwiZIYTMpk2blvVxYu+YY7z63W67Qa9eXiAnLy/qqEREpKZVtot+DHB24vXZwOgSrpkMZJhZWzOrj0+eG1OOn3u6mW1mZm2BDODzSsaaMnbcET7+2Evb3nUXHHUULFsWdVQiIlKTKpvghwLdzGwW0C1xjJntYGZvAYQQ8oBBwFhgOjAqhDAtcV0vM8sFugD/NbOxiXumAaOAb4G3gYtCCOsrGWtK2WwzeOgheOopaNjQx+lFRCR1WIjRuqrMzMyQlZUVdRi1Tgi+rG7BAnj1VbjwQj8WEZHkZ2bZIYTM4udVyS4FFCTzRx+Fq6/WZjUiIqlACT6F3HADTJ4M6el+/OOPkYYjIiLVSAk+hZhBu0QNwaeegl13heeeizYmERGpHkrwKapbN+jQAfr29Xr2a9dGHZGIiFQlJfgU1aIFvP8+/O1v8OCD0LUrzJ9f9n0iIpIclOBTWL168M9/wksvwbffQvv28O67UUclIiJVQQleOOUUyMryVv0xx8Ctt0J+ftRRiYhIZSjBC+AT7iZOhDPOgOuvh8suizoiERGpjLpRByC1R4MGvhvdwQfDoYdGHY2IiFSGWvDyJ2a+r/wee3gFvL/+FR5/POqoRESkotSCl1KtXg1z58IOO0QdiYiIVJQSvJRqiy18f/mCUreffQbNm8POO0cbl4iIlE1d9LJRaWlQpw6sXw/9+8P++8OYsjb7FRGRyCnBS7mkpXlrfpddoEcPuPZayMuLOioRESmNEryUW3o6fPIJDBgAd9zha+YXLYo6KhERKYkSvFTI5pvDI4/Af/7jY/Lt2/uziIjULkrwsknOOQcmTPCJeIceCvff78vqRESkdqhUgjezbc3sXTOblXhuXMp1x5rZDDPLMbPBRc73NrNpZpZvZplFzqeb2Soz+yrxeLgycUr12G8/L3F73HFw+eUwZUrUEYmISIHKtuAHA+NCCBnAuMTxn5hZGjAc6A60A/qYWWJXcqYCJwEflfCzZ4cQ9ks8BlYyTqkmjRrBa6/52Py++/q5X3+NNiYREal8gu8BjEy8Hgn0LOGajkBOCGFOCGEt8ELiPkII00MIMyoZg0SsTh3o0sVfv/uuT8bTuLyISLQqm+CbhxAWACSem5VwTUug6E7juYlzZWlrZl+a2Ydmdkgl45Qa0q6d705X0JoXEZFolJngzew9M5tawqNHOX+HlXCurOlYC4A2IYT2wBXAc2a2TSnxDTCzLDPLWrx4cTlDkurSsiU88YRvXPP77z4ZLzc36qhERFJPmQk+hHBUCGGvEh6jgYVm1gIg8VzSquhcoHWR41bAT2X8zjUhhF8Sr7OB2cCupVz7aAghM4SQ2bRp07I+jtSgKVPg5ZehQwd4//2ooxERSS2V7aIfA5ydeH02MLqEayYDGWbW1szqA6cn7iuVmTVNTM7DzHYCMoA5lYxVatiBB8LkydCkCXTrBkOHQn5+1FGJiKSGyib4oUA3M5sFdEscY2Y7mNlbACGEPGAQMBaYDowKIUxLXNfLzHKBLsB/zWxs4ud2BaaY2dfAy8DAEMLSSsYqEdhjD/j8c+jdG4YMgV69YNmyqKMSEYk/CzGqTpKZmRmysrKiDkNKEAI8+CBccQW0aQOvvOLr6EVEpHLMLDuEkFn8vCrZSY0wg4svho8+gjVrfFndk09GHZWISHwpwUuN6tIFvvjCx+c//DDqaERE4qtu1AFI6mnWDN55B9at8+PvvoPNNoO2baONS0QkTpTgJRJpaf4IAc49F5Yvh6lTvSqeiIhUnhK8RMoMnnkGFi/25L5+vZ9PS4s2LhGRZKf2kkRu552hc2d/feON0L07LFkSbUwiIslOCV5qlbZtfaZ9hw4waVLU0YiIJC8leKlV+vf3nejS0uCQQ+Chh3ycXkSkLPn5vjrnjjtgwoSoo4mexuCl1unQAbKzoV8/uOgiT/iPPOIb2IhI6lm3DhYuhJ9/hgULNnzccYfvZPn3v8OwYd4oqF8fxo0r3Mo6FSnBS6207bYwZozXr7/+evjqK3j1Vdi1xC2HRCQZrVrlCbphQ9huO9958qGH/Mv97rvD22/76yVLSu7Ja9oUtt/eV+EArF7trfj8fFi7FsaPV4IXqZXq1IFrr4WOHaFPH8jMhNGj4fDDo45MREoTgifYtDT47Td4882SW90LFhQm5vvv90qXv/3mLfCOHT3Bt2rl+1e0aLHho3lzqFfvz7+7d294+GFP7vXrw2GH1fjHr1VUi16Swvz5cOmlMGKE/8MWkZqVn+8t6YLkXLS7/IAD4KyzvEW+3Xa+Guaaa+D77wsLWG2xhSfm7bffMFkfeCDstlvhbpOVqYcxYYK33A87LHVa76XVolcLXpJC69beRQ+Ql+c7011xhf9xEJFNt24d/P47NG7sx88846+PP95b4126eNf5woX+b6+4hg29tXzWWZ7EL73UW+DgLfDp0/3f6TbbeN2LjamKQldduqROYi+LErwknW++8XG6/faDvn2jjkakdsvKgrlzS5+gtmSJt6A/+cSvv/NOr01x/PGekHfc0bd9LqmbfPvtYcst//z77rij8HXdut7VLtFQgpek0749zJoFO+zgx1Onwp57lt06EEl2Ifg4dfEkvXIl3HCDXzNwoLeaCzZzuugi+Pxzf123rg9xtWjhibtzZ39dNAmPH++t7QIvvlgjH02qgRK8JKWC5D5njo//de8O//mPdxeKJJv8fP+Cagbffus7Lp55pr93zz3wyiuFyXzVqg3v32YbX21i5j1bTZsWvjdihE94a9ECmjQpuxt8u+2q7nNJtJTgJam1bQu33w5XXeWz7F95BfbZJ+qoRAr9+ivk5JQ+k3zBAh/fnjvXx6xffdWT9SmnwOabw5o1PsZd0Nou6VF0fHvgwD///g4dav4zS+1QqVn0ZrYt8CKQDnwPnBpC+LWE644F7gPSgMdDCEMT54cBJwJrgdnAuSGEZYn3hgD9gfXAJSGEsWXFo1n0qevjj+G002DZMi+Kc9ZZUUckcfbHHxsm6b/8BdLT4f334fLLPVHvvLO3wK+44s/3N226YZK+7DLfSnnRIp/0lp6u3RWlfKprFv1gYFwIYaiZDU4cX1PsF6cBw4FuQC4w2czGhBC+Bd4FhoQQ8szsTmAIcI2ZtQNOB/YEdgDeM7NdQwjrKxmvxNQhh3i35umne2GMzz6De+/1feZFKuKPP2DixMKJZd984xPHiibz337b8L4WLTwpb721j28XLPk68URP9Btbv11Us2b+EKmsyib4HsBhidcjgfEUS/BARyAnhDAHwMxeSNz3bQjhnSLXTQROKfJzXwghrAHmmllO4ueourCUavvt4b334Lrr4K67vNztSy/5H1tJXcXXb5f2uPxyL7by009w5JEwcqR/WVy92jc+atEC9t4bjj665G7ygrHrAw7wKowFdtnFHyI1rbIJvnkIYQFACGGBmZX0vbMlML/IcS7QqYTrzsO7+wvumVjsnpYlBWBmA4ABAG3atKlQ8BI/dev6Mp/OneGcc6BrV5g5Uy35OFq37s9Lv7bbDg4+2BN6r17eZd6/v1/TsoS/Hg0bFibnLl289Q3Qpo13s++9tx8fcADMnl1jH0ukypSZ4M3sPWD7Et66rpy/o6TFS38a+Dez64A84Nny3vP/T4bwKPAo+Bh8OWOSmOvVC/baC2bM8OQegj80ppkcfvjBE3hBy/fGG/1c8fXbRZ1yiif4OnV8LsYff/j5Zs28FGrxFvcWW5T8u+vXVzlkiYcyE3wI4ajS3jOzhWbWItF6bwEsKuGyXKB1keNWwE9FfsbZwAnAkaFwxt9G7xEpj4wMfwA88YRPenrxRR8jlZoVgtcd31gXedOmMGqUX3/SST5W/dZbfvzssz6bvEULXzlx4IEbFlwp2oFXsAYcvFfn4otr7rOK1BaV7aIfA5wNDE08jy7hmslAhpm1BX7EJ8+dAf9/dv01wKEhhD+K/dznzOxf+CS7DODzSsYqKczM/9AXr7ollVN0fHvJEh+7Bv9C9c03PtERoFs337qzuIL65EXHsMGHWYpuDzxrlgoZiVRUZRP8UGCUmfUH5gG9AcxsB3w53HGJGfKDgLH4Mrl/hxCmJe5/ENgMeNf8X+/EEMLAEMI0MxsFfIt33V+kGfRSGf37w3nneZL46Sf43/8Kj2VDBftvt2rlx++/763iktZvry/yL3PtWp8hPmtWYfU08PkQxx23Yau7tPrkRxXrN9R/J5GK025yknKGDPF95vv18ypfqdSqL2n9dtHHY495V/ewYXD11b4cbOut/fU//1ny+u2ij44dvadERGqOdpMTSbjtNu8avukm+PJLr35XMFafjIqOb2+/ve8ENmMGPPooXHKJLxN89lm44AJYsWLD++vWLdzCc+VKP3fMMT7LvGBS4k03ecVAJW+R5KEWvKSst9/23ejy8nzNc8+eUUf0Z/n53v1drx4sXgxvvll6y3v1ar/n2WfhjDO8st8xx8DYsV4EaNIkf6+09dtaXSCSvEprwSvBS0r74QdfXpWV5d3Qt91W/a3U4uu3iz66dYPeveHHH73lPWIEnH++V+nbf3+/v1Gj0rvIDzrIu9gL/llr7Fok/tRFL1KCHXf0fbAvu8yr333+OTz/vHdZV9TKlb7TV5MmfvzQQ76O++ijvbb4gQeWvH4bPBE3bepLwMBfX3ON7wwGvh3unDkeV2nrt4v/PBFJbWrBiyQ89ZTvxPWPf3hLePx4OOwwr3IG8NFHMG9e6d3kK1Z43fGCMqUtW/o2to8/7i3qk0/2oisltbybN9f4tohsGnXRi5TDrFm+m1e3bt4ar1PHW/hduvhEvJwcv27LLUtO1HvvDccf79csW+bLwDS+LSLVSV30IuWQkQEvv+zrucFb3uPHe4IfNaowsW+9ddnd4I0aVXu4IiKlUoIXKeaww7we+dq1/nzYYX6+ffsooxIRqRgleJFiunTxsqrFx+BFRJKJErxICbp0UWIXkeSm6T8iIiIxpAQvIiISQ7FaJmdmK4AZUcdRw5oAJZROiS193njT5423VPu8UDOfeccQQtPiJ+M2Bj+jpLWAcWZmWan0mfV5402fN95S7fNCtJ9ZXfQiIiIxpAQvIiISQ3FL8I9GHUAEUu0z6/PGmz5vvKXa54UIP3OsJtmJiIiIi1sLXkRERFCCFxERiSUleBERkRhSghcREYkhJXgREZEYUoIXERGJISV4ERGRGFKCFxERiSEleBERkRhSghcREYkhJXgREZEYUoIXERGJISV4ERGRGFKCFxERiSEleBERkRhSghcREYkhJXgREZEYUoIXERGJISV4ERGRGKobdQBVqUmTJiE9PT3qMERERGpMdnb2khBC0+LnY5Xg09PTycrKijoMERGRGmNmP5R0Xl30IiIiMaQEL1KCCRPgjjv8WUQkGcWqi16kKkyYAEceCWvXQv36MG4cdOkSdVQiIhWjFrxIMePHe3Jfvx5Wr/ZjEZFkowQvkrBkCZx4IjRr5i13M6hbFw47DPLy4NNPIYSooxQRKR8leBFg0iTo0AHefRe23NK75W+7DT780LvnX38dDj4YOnWCF1/0hC8iUpspwUtKCwEeeggOOQTS0ryV3qePJ/UhQwrH3o87DkaMgGXL4PTTYZdd4L77YMWKaOMXESmNErykrJUr4ayz4KKL4OijITsb9t+/5Gu33BIGDoTvvvPWfOvWcNll/jx4MPz4Y83GLiJSFiV4SUkzZ3p3+3PPwa23wpgxsO22Zd9Xpw706AEffwwTJ/oXg2HDoG1buOGG6o9bRKS8lOAl5bz+OmRmwsKFMHYsXHedJ+6K6tQJRo2CnBy44ALYeWc/v3IlvPOOJuSJSLS0Dl5Szvr1sOeenpxbt678z2vb1sfjCzz9tCf8zz+HAw6o/M8XEdkUSvCSEhYs8C71Xr3g5JP9eVNa7eVx7rnQokVhcr/xRmjQAAYMgEaNqud3iogUpy56SQnXXgvnnQfLl/txdSV3gM0283F68G76L7+Ea67x3oIrroAfStwWQkSkainBS2yF4MvaAP71L/jkE2jYsGZjMPMJfF9+CT17wgMP+Fh9nz6gjQ9FpDopwUssLV/uXfFHH+1lZxs39nH3qOy3n4/Nz53rrfi33vIu/MMOgzffhPz86GITkXhSgpfYmTLFZ8mPGeMt5Xr1oo6oUKtWcNddMH8+3H03zJkDf/mLP4uIVCUleImVp5+Gzp19qdoHH8Dll3s3eW2zzTbekp892+PcZRc/P2DAn2fki4hsKiV4iYU1a3xpWr9+0LEjfPGFl5+t7erVg0MP9dd5eT7bf+lSP87P9y8AIiKbQglekt68eZ7MH34YrroK3nsPtt8+6qgqrm5deOMNuOkmP37jDcjIgJNOgs8+izQ0EUlCSvCS1ObM8V3gvvsOXnnFx7frJnl1h4Ihhc6dvcrehx/CQQf5xjevvOKFekREyqIEL0mtbVtf356V5S3dOGneHG65xXsoHnwQFi2CU06BXXeF4cN9noGISGmU4CXpLF0KZ5zhS87MvNW+665RR1V9GjTwHe9mzoSXX4ZmzWDQIGjTxtfVi4iURAleks6yZfD++z6RLpWkpfna/gkTfN/6Qw8tHI5YtQq+/Tba+ESkdkny0UpJFSH4Dm1HHw077eSzyxs0iDqq6Bx4ILz6auHxU0/5fvVffw377BNdXCJSe6gFL7XeH3/4Bi7HHutd1JDayb0kJ58MI0bA3nv78T33+F7369ZFG5eIREcJXmq1WbN89vhTT/nysbhNpKsqTZp4C97M188/9xz07et17+++G377LeoIRaSmKcFLrfX6615yNjfXa7ffeKOPQ8vG1akDkyb5OvqddoIrr/Sd7K66ykvkikhqUIKXWicvz7dX7dXLZ8d/8YV3z0v51akDJ5wA48fD5Mlw3HHebb/TTnDWWfDVV1FHKCLVTQleapWff4Zu3Xzp28CBvsXrjjtGHVVyy8yE55+HnBxfXvfaa9C+PXz/fdSRiUh1UoKXWuX88717eeRInzS22WZRRxQf6eneis/NhRdf9GOAIUP8WETiRcvkJHIh+GYxm2/uhVt+g9QOAQAAIABJREFU+01LvapTo0Zw6qn+eu1aGDvW/xucdppP0Fu+HBo3jjZGEak8JXiJVAg+Jrxypa/rLmhVSs2oXx+ys/0LFsDbb0Pv3tC/P1x2mY/Zi0hyUhe9RMoMOnXypXASDTPvPQFfVte7t+/Ml5HhLf3PP482PhHZNBVK8GZ2rJnNMLMcMxtcwvtmZvcn3p9iZh3KutfMtjWzd81sVuK5ceJ8NzPLNrNvEs9HVOaDSu3ywgswZoy/vvhiuPrqwl3UJDq77QZPPul1/q+6yqsHduoEXbv6f6/8/KgjFJHyKneCN7M0YDjQHWgH9DGzdsUu6w5kJB4DgBHluHcwMC6EkAGMSxwDLAFODCHsDZwNPF3hTye1ztq1cMkl0KcPPPpo1NFIaVq2hKFDfd38vff6jnY9esAee2hCnkiyqEgLviOQE0KYE0JYC7wA9Ch2TQ/gqeAmAo3MrEUZ9/YARiZejwR6AoQQvgwh/JQ4Pw3Y3Mw0pzqJ5eb6BikPPABXXOHLtaR223pruPRSX2L3wgt+/FPiX+WaNbB4cbTxiUjpKpLgWwJF62DlJs6V55qN3ds8hLAAIPHcrITffTLwZQhhTQXilVpk3Dhfez11Krz0kpdPrVcv6qikvOrW9Vn2kyf7kAp4Odw2beC776KNTURKVpEEX9IIaSjnNeW5t+RfarYncCfw11LeH2BmWWaWtVjNiVonPx9uv913gWvWDLKy4JRToo5KNpVZ4Ra1Bx3kcyd2282Pn3wSPv7YV0aISPQqkuBzgdZFjlsBP5Xzmo3duzDRjU/ieVHBRWbWCngN6BdCmF1SUCGER0MImSGEzKZNm1bg40h1+/VXH7e97jpv/U2aVJgMJPntuivcfLMn/fXr4R//8Ml4nTvDqFFeclhEolORBD8ZyDCztmZWHzgdGFPsmjFAv8Rs+s7A8kS3+8buHYNPoiPxPBrAzBoB/wWGhBA+3YTPJhGbNQs++MDH3J99FrbaKuqIpLqkpfnwy0MPwdKl/oUuIwPuvx9+/z3q6ERSU7kTfAghDxgEjAWmA6NCCNPMbKCZDUxc9hYwB8gBHgMu3Ni9iXuGAt3MbBbQLXFM4vpdgOvN7KvEo6TxeallCtZNd+zo9c4HDdISuFSw5ZZwwQU+Jv/aaz4T/9JLfSe7a6+FBQuijlAktViI0YBZZmZmyMrKijqMlPb883DGGfD++3D44VFHI1GbONEnVL76qo/dz50LO+wQdVQi8WJm2SGEzOLnVclOqkRBAZSTT/Zu2q5do41HaofOnX3VxMyZ8M9/Fib3u+/2rWxFpPoowUulvfmmb0m6dKnXNr/gAh+TFSmw886Fy+tWr/biOQWVDEOAdeuii00krpTgZZOtXw9//zuceKIfazKVlMfmm3vhnBtv9ONx46BtWxg2zHeyE5GqoQQvm2TxYjjmGLjtNvi//4PPPvOiJyLlsdlm0LChv956a18+efXVPiHvb3/z0rgiUjlK8FJhEyZ4VbpPP4UnnoDHHivcjUykojp18lZ8drb3Bt13n29Te8YZ8MUXUUcnkryU4KXcQvA17V27egvss8/gvPOijkriokMHr5cwZ47vRf/mm7D//nDEEb4qQ0QqRgleymX9eujb13eC697dS862bx91VBJHbdr4jPv5831cfuZMr4EPXh1v9epo4xNJFkrwUi5pab7E6fbb4fXXoXHjqCOSuGvYEK680tfOX3KJn3vxRUhP91a+iGxc3agDkNrtpZdgxx29Kt0//xl1NJKK6tUr3Hlw552hZ09P8uBL7fbc08+LyJ+pBS+lWrXKZzbffXfUkYi4zp3h4YehTh1fOz9ggNe8P+UUn/wpIoWU4GUDCxbA2rWwxRY+u/npp6OOSGRD9erBl1/CkCE+Ce/AA30L29de8zkjIqlOCV7+5IMPYL/9/I8m+HKl+vWjjUmkNC1aeC2GefN857oFC+Ckk2D33b1k8h9/RB2hSHSU4AXwJXB33glHHQXbbgv9+0cdkUj5bbWVl8KdNcvnjWy3HVx0kc/IX7Qo6uhEoqEELyxbBr16weDBPpb5+efQrl3UUYlUXFpa4Xj8J5/4vgjNEptMP/kkTJ8eaXgiNUoJPsV9/bVvFPPf//oGIC+84KVDRZKZmY/H33KLH69c6cVzhg/34xD8IRJnSvApbORIn5W8apVv3Xnppf6HUSRuGjTw7vvrr/fjjz+GAw7wL7R5edHGJlJdlOBT1COPwDnnQJcuXu/7oIOijkikejVtCs2b++tVq2DFCujTx9fQ33uvH4vEiRJ8ijrtNBg6FN55p/CPnkiqOOYYH48fM8aL5lx+ue9kd8018OOPUUcnUjWU4FPI22/DscfCmjXQqJH/MaurWoaSourU8d3rPvzQJ5Yee6xXa0xPh7PPhm++iTpCkcpRgk8hq1fDzz/DL79EHYlI7VIwHp+T48vrXnkFRo/29/LzNSFPkpMSfMwtWVL4h6pnT98Fbocdoo1JpLZq29bH4+fPL9zg5uWXYd99ITc32thEKkoJPsY+/9z32D7zzMJWu7rkRcrWuDFss42/3morr+jYooUff/wx/PprdLGJlJcSfAyFACNGwMEH+zjjBx94ZS8RqbjjjvMtktPSfP5Kr14+Ie+yy+D776OOTqR0SvAxs3Il9OsHF17oZWe/+MIL2YhI5W22Gbz3nte7Hz7cl9iddhpMnhx1ZCIbUoKPkZkzoVMnePZZ+Mc/4M03va68iFSd/faDp56CuXPhyit9dUrHjnDoofDGGz4pT6Q2UIKPiVde8Zb6zz/D2LFesauO/uuKVJtWrXyDpvnz4V//8u76v/zF93FYujTq6ESU4GPh11/h/PNhjz28S75bt6gjEkkd22zjhXJmz4bnn/eWfEHP2Ztv+koWkShYiNECz8zMzJCVlRV1GDXml1/8D4mZbxqz++4+Rigi0fvtN9h+ey+aM2JE1NFInJlZdghhg9lWasEnqfnzYa+94J57/HjffZXcRWqTbbaB7GwYMsSPJ0zwWhSffKLCOVIzlOCTVKtW0LcvHH101JGISGn22APatPHX8+b5GvpDDvFNnl5+GdavjzY+iTcl+CSyfLnvADdnjnfL//Of3ooXkdrvtNM8yQ8f7uPyvXtDRgY88AD8/nvU0UkcVSjBm9mxZjbDzHLMbHAJ75uZ3Z94f4qZdSjrXjPb1szeNbNZiefGifPbmdkHZva7mT1YmQ8ZB9984/Wyn3nGu/pEJPk0aOA1KmbM8JUvLVp4Sdw2beC662DBgqgjlDgpd4I3szRgONAdaAf0MbN2xS7rDmQkHgOAEeW4dzAwLoSQAYxLHAOsBq4Hrqz4x4qXZ57x9e0rVnhVur59o45IRCojLc2L5Xz6qT8OPxzuuEOT8aRqVaQF3xHICSHMCSGsBV4AehS7pgfwVHATgUZm1qKMe3sAIxOvRwI9AUIIK0MIn+CJPiWtWeM7W511lrfev/zSx+9EJD4OPNBb8zNnwqWX+rnRo6F7d1i0KNrYJLlVJMG3BOYXOc5NnCvPNRu7t3kIYQFA4rlZBWKKrXnzoGtXeOghuOoqGDfOl9yISDztskvhnhErVsCyZYXr6adNg3XrootNklNFEryVcK74Yo/SrinPvZvEzAaYWZaZZS1evLgqfmTk3nnHd4GbPt2/2d91l3aBE0klZ54Jn33m/+5Xr4YjjvAd7e6+2yfbipRHRRJ8LtC6yHEr4KdyXrOxexcmuvFJPFeoUyqE8GgIITOEkNm0adOK3FprTZ/uk2+ysnycTkRSjyWaRfXrw7//7S38K6/0neyuvNJrYYhsTEUS/GQgw8zamll94HRgTLFrxgD9ErPpOwPLE93uG7t3DHB24vXZwOhN/CxJ7ZdffI0s+KzayZNh112jjUlEolenDhx/vE+wzcqCE06Ae+/1Fn3fvl6eWqQk5U7wIYQ8YBAwFpgOjAohTDOzgWY2MHHZW8AcIAd4DLhwY/cm7hkKdDOzWUC3xDEAZvY98C/gHDPLLWHWfmz89a9w8sm+3asZbL551BGJSG2z//7w3HNe9/6SS2DMGD935JHqupcNqRZ9hEKAtWu9xOwPP8DChb7tpIhIeSxbBo895uP1r77qjYMJE3wOj0pXp47SatErwUfkjz+84MXSpfD669raVUQq79dfvYz1eed5hTxJDdpsphbJyfFa1E895d+0RUSqQqNGvob+kkv8ODvbX8+ZE21cEg0l+Bo2erSPmeXmwn//CzfdpNa7iFQNMzjqKK9xDz4p7+GH/bh3b5g0Kdr4pGYptdSQvDwYPNi3i8zI8G/W3btHHZWIxNlf/wrffw9XXw3vvQedO8PBB/uwoHayiz8l+BqwcCF06wZ33un/4D75BNLTo45KRFLBDjt4nfv58+G+++DHH6FXL9/KdsQInw8k8aQEX81mzvRx9kmTYORI7y7TEjgRqWlbbeXj8bNmwYsv+nj9hRfC0KFl3yvJSQm+mqWn+05REydCv35RRyMiqa5uXTj1VG90fPSRJ3mAsWNhwACfiS/xoARfDVas8G/KS5d6mclnnoF99ok6KhGRQma+O2XBJlYzZsD48d7SB9+bPkarqFOSEnw1mDULnnjCS0uKiCSDSy6Bb7+FevW8AFdmJnTqBKNG+SRhST5K8FXoyy/9uUMHmDvXS8+KiCSLortWXn+9V8o77TTf6Oa++7x3UpKHEnwVWLvWv/126OBbvQI00672IpKk6teHgQPhu+98SV3r1nDZZf48eLDPxJfaTwm+knJz4dBDvSzkFVf4hDoRkTioUwd69PCdLidOhKOPhmHDoG1bOPts+P33qCOUjVGCr4Rx46B9e5g61cep7r7bx69EROKmYDx+1ixv3c+eDQ0a+HuzZmlCXm2kBL8J8vPh9tv922yzZr53e+/eUUclIlL9dtoJ7r/fW/VmPk7foQNce23UkUlxSvAV9Ouv3mV13XU++WTSJNh996ijEhGpWWb+vOWWPkTZt68ff/MN3HWXJ36JlhJ8BZ1yiheEeOABePbZwjWjIiKpqH59OOcc2GsvP37rLbjmGp+Qd8UV8MMPkYaX0pTgyyk/35+HDYMPP4RBgwq/wYqIiLvmGl8y3LOnN4R23hn69PGd7aRmKcGXIT8fzj8fLr3Ujzt08L3cRUSkZPvtB08/7fvQX365b419wAFw2GHw5puFDSapXkrwZahTxzdlaNhQs0RFRCqidWvv9czN9VVGc+bAiSdqg5uaYiFGWSszMzNkVVE/0JtvQpMmvn9yCOqOFxGprHXr4KWXvAZ+69Y+3PnRRz5WX7DkTirOzLJDCJnFz6sFX8z69fD3v/u3zNtv93NK7iIilVevHpxxhid3gPff9y20C0rkam/6qqUEX8TixXDMMXDbbdC/v++ZLCIi1ePmm32Dm80289b9nnv6Hh6ffRZ1ZPGgBJ8wcaJPoPvkE3j8cX9ssUXUUYmIxFvDhv68di2ceaZvWXvQQXDggfDqq96rKpsm5RN8CPDgg9C1q3cfTZjgrXcREak5DRrALbfAvHn+N3nhQm/N77YbDB8OK1dGHWHySekE//vvXn3p4ou9az4722vLi4hINBo0gIsugpkz4eWXfbLzoEHQpo3Pj1q9OuoIk0dKJ/hPP/XNE267DUaPhsaNo45IREQA0tK8BT9hgg+ddu3qf6fr1/f3ly6NNr5kUDfqAKIwe7ZXVzrmGJgxw1+LiEjtY+Zj8gcd5K33OnVgxQr/uz14sFfOk5KlXAt+5EjfHCY724+V3EVEksPmmxe+vuIKOOoofz1zJjz3nM/EnzAB7rjDn1NdyrXge/b0zQ/23jvqSEREZFNsvTVcf33h8ZNPelK//HLf8TM/37vyx41L7dLiKdGC//BDOP54795p2BBuuKFwHEdERJLbrbfCG2/4BL28PF9at3atL7lLZbFO8CH4vsRHHuk1kBcujDoiERGpanXqwAkn+Bbem2/uE/Tq1/fNbVJZbLvoly/3PYpffx1694YnnvBuHRERiacuXbxbfvx4T+6p3D0PFWzBm9mxZjbDzHLMbHAJ75uZ3Z94f4qZdSjrXjPb1szeNbNZiefGRd4bkrh+hpkdU944p0yBzEzfMOaee7zkrJK7iEj8dekCQ4YouUMFEryZpQHDge5AO6CPmbUrdll3ICPxGACMKMe9g4FxIYQMYFzimMT7pwN7AscCDyV+Tql+/tnH1zt39qpHH3wAl12mzWJERCT1VKQF3xHICSHMCSGsBV4AehS7pgfwVHATgUZm1qKMe3sAIxOvRwI9i5x/IYSwJoQwF8hJ/JxS/fijlzrcfXf48ks4+OAKfDoREZEYqUiCbwnML3KcmzhXnms2dm/zEMICgMRzswr8PsxsgJllmVmWH3v1o+bNK/DJREREYqYiCb6kju5QzmvKc++m/D5CCI+GEDILNrvffHM44ogyfrKIiEjMVSTB5wKtixy3An4q5zUbu3dhohufxPOiCvy+P2nZUoUNREREoGIJfjKQYWZtzaw+PgFuTLFrxgD9ErPpOwPLE93uG7t3DHB24vXZwOgi5083s83MrC0+ce/zjQW4/fZK7iIiIlCBdfAhhDwzGwSMBdKAf4cQppnZwMT7DwNvAcfhE+L+AM7d2L2JHz0UGGVm/YF5QO/EPdPMbBTwLZAHXBRCWF/ZDywiIpIKLISyhsKTR2ZmZsjKyoo6DBERkRpjZtkF89D+dD5OCd7MVgAzoo6jhjUBlkQdRA3S5403fd54S7XPCzXzmXcMITQtfjJupWpnlPQtJs7MLCuVPrM+b7zp88Zbqn1eiPYzx3qzGRERkVSlBC8iIhJDcUvwj0YdQARS7TPr88abPm+8pdrnhQg/c6wm2YmIiIiLWwteREREUIIXERGJJSV4ERGRGFKCFxERiSEleBERkRhSghcREYkhJXgREZEYUoIXERGJISV4ERGRGFKCFxERiSEleBERkRhSghcREYkhJXgREZEYUoIXERGJISV4ERGRGFKCFxERiSEleBERkRhSghcREYkhJXgREZEYqht1AFWpSZMmIT09PeowREREakx2dvaSEELT4udjleDT09PJysqKOgwREZEaY2Y/lHReXfQiIiIxpAQvIiISQ0rwIiWYMAHuuMOfRUSSUazG4EWqwoQJcOSRsGYN1K8P778PXbpEHZWISMWoBS9SxNdfe0Jfuxby82H1ahg/3t9bvz7S0EREKkQJXgQIAR54ADIzITfXW+5pabD55nDYYTB/PrRuDddcAzk5UUcrIlI2JXhJeb//DmecAZdcAt27w+23w7hxcMsthd3zq1ZBp05w992QkQHdusFLL3lLX0SkNrIQQtQxVJnMzMygdfBSEd99ByedBDNmwK23egu9zka+9v70E/z73/DYYzBvHjRrBuedB+efDzvtVHNxi4gUMLPsEEJm8fNqwUvKGjUKDjgAliyBd96BIUM2ntwBdtgB/v53mDMH3nrLW/fDhsHOO8Nf/uJd/SIitYESvKScdevg8svhtNNg773hiy981nxFpKV5d/7rr8MPP8A//gG77QZm/v7w4TB3btXHLiJSXlomJynnuuvg3nt9zH3YMJ9QVxktW8L11xce//CD/+y1a/2LxNq1nvjr1avc7xERqYjIWvBmdqyZzTCzHDMbXML7Dc3sDTP72symmdm5UcQp8VGwzO3qq32C3H33VT65l2THHT3Jn3eeHz/3HLRp418svv++6n+fiEhJIknwZpYGDAe6A+2APmbWrthlFwHfhhD2BQ4D7jazavhzLKng3nu9G37dOmjSBE45pXp/X6tW0LChv95lFx/rHzrUJ+J17w6vveaxiIhUl6ha8B2BnBDCnBDCWuAFoEexawKwtZkZsBWwFMir2TAlLpo390cUy9oOPhjGjPHW+w03wDff+Mz9HXf0rv0fStwHSkSkcqJK8C2B+UWOcxPninoQ2AP4CfgGuDSEkF/8B5nZADPLMrOsxYsXV1e8koS+/hpeeMFf9+njrxs0iC6e1q3hpps80Y8ZAx06wG23Qdu2vjxPRKQqRZXgrYRzxRcYHQN8BewA7Ac8aGbbbHBTCI+GEDJDCJlNm26w372kqCefhM6dfdx7zRo/ZyX9XxeBunXhxBPhzTc92V9/vccKvmTvhhvg558jDVFEYiCqBJ8LtC5y3ApvqRd1LvBqcDnAXGD3GopPktTq1TBgAJx7rq9RnzABNtss6qhK16YN3Hwz9Orlx+PHe8GdX37x419+gTwNTInIJogqwU8GMsysbWLi3OnAmGLXzAOOBDCz5sBuwJwajVKSyvff+3j3Y4/B4MFevKZZs6ijqphTToEff4Q99/Tjiy+G9HS48Uavhy8iUl6RJPgQQh4wCBgLTAdGhRCmmdlAMxuYuOwW4EAz+wYYB1wTQlgSRbxS+/3vfz6mnZPjxWfuuMO7wpNRixaFr884A/bZx+vip6d71/4bb2hnOxEpm2rRS1Jbv96ryN1yi1ele+UVX5YWN99/D48/Dk884ePzrVrB//0f9O/vr0UkdakWvcTSvHnwr39Bv34+3h7H5A7eer/1Vv+8r77qXfg33+xL7Z57LuroRKQ2StJOTEl1OTm+wUvbtjBliifA2jJLvjrVq+cT8nr18lr3jz8OXbv6e2PHwqRJcOWVsOWW0cYpItFTC16STnY2tGvnS+HAk3wqJPfi2rb1dfQFXfQffeRb2RasGpg1S2P1IqlMCV6STvv2vla8R/Hahynutttg6lTf6W7dOjjkEC+Ne8stvo+9iKQWJXhJCrNmeS35+fN9z/a//x223TbqqGqfrbbyZzN48EHYdVf/MtSmDfTs6asN1KoXSQ1K8FLrvfoqZGZ66dl586KOJjnUretr6t99178cXXklfPYZHHecz1249Va16kXiTgleaq28PLjqKjj5ZNh9d/jiCzjooKijSj677OI72eXmwosv+vH113urfubMqKMTkeqiWfRSKy1YAKef7hPHLroI7r67dpecTQb168Opp/pj1iwYPRoyMvy9m2+GbbaByy+PNkYRqTpqwUut89FHXpUuKwueecbHkpXcq1ZGhnfbm0EI3jsydWrh+598Avkb7N0oIslECV5qlXvugSOO8NbkpEnQt2/UEcWfmbfmH3nEj7OzfQb+Lrt4yV/tbCeSnJTgpVZZs8Zne0+eDHvtFXU0qaWgdv9ee8Hzz3uVvGuv9X3se/f2CXtq1YskD9Wil8hNnQqLF8Phh3t3MaRm4ZraaMYM353vySd969qdd4bzz4dzzoHmzaOOTkSg9Fr0SvASqRB8i9fly73kbB31KdVKq1fDa695N/6HH8IOO/iSxbS0qCMTEW02I7XKmjXw++/eUn/mGe/+VXKvvTbfHPr0gfHj4bvv4OGHPbnn50O3bjBqVNQRikhx+pMqNW7ePN8g5bzz/Lht2z/vgS612267+b704EMra9YUDq0sWgTvv6+xepHaQAleatQ77/gSuOnTfZ27JLfmzX1Z46mn+vF//uMlhXfbDYYN8y8AIhINJXipEfn5vunJscd6az0rC046KeqopKoUTIq85BJ46inYfnu4+mrf6a5PH/jgg8JWvojUDCV4qXZLl8IJJ/imJ337wsSJvgmKxM8WW8BZZ8HHH/vqiIED4e23vbbB7rt7RcIlS6KOUiQ1RJbgzexYM5thZjlmNriUaw4zs6/MbJqZfVjTMUrlZWd7l/x778FDD3nrrkGDqKOSmrDnnnDffb6pzciR0KSJV88bNKjwGrXqRapPJLXozSwNGA50A3KByWY2JoTwbZFrGgEPAceGEOaZWbMoYpVN99FHPsO6eXMvfdqxY9QRSRS22AL69fPH1KmFqyVmzPCiRiNH6v8NkeoQVQu+I5ATQpgTQlgLvAD0KHbNGcCrIYR5ACGERTUco1RSx45wwQVe51x/wAW8Sl67dv76t9+gaVOvmAfw6ae+xl6tepGqEVWCbwnML3KcmzhX1K5AYzMbb2bZZtavxqKTTZaT4/uQL1/ua6fvvde7ZkWKO+AA7+UpqIh3++1w2GH+BeCee7xynohsuqgSfEmFSIt/b68L7A8cDxwDXG9mG0zNMrMBZpZlZlmLtSYncj//7BOstM+4VNRLL8G//w2NGsEVV0DLlnDmmf7/k1r1IhUXVYLPBVoXOW4F/FTCNW+HEFaGEJYAHwH7Fv9BIYRHQwiZIYTMpk2bVlvAUrq8PBg71l8ffDDMneutM5GK2HJLOPdcmDABvvoK+veHN97wokh77um9QUuXRh2lSPKIKsFPBjLMrK2Z1QdOB8YUu2Y0cIiZ1TWzLYFOwPQajlPKsHAhHH20r2//6is/t+WW0cYkyW/ffWH4cJ+B/8QTsPXWcPnl8Oqr/n5enlr1ImWJJMGHEPKAQcBYPGmPCiFMM7OBZjYwcc104G1gCvA58HgIYWoU8UrJPv3Ul8BNmOAVzPbbL+qIJG4aNPCSxpMmwZdfFlY/HDEC9t4bfv012vhEarNIlskBhBDeAt4qdu7hYsfDgGE1GZeULQS4/35f07zjjl64Zt8NBk9EqlbRL5Bt2kCnTtC4sR8//rhPzuvSRVsNixTQdrFSIStWwP/9n+8e9pe/+BrmRo2ijkpS2dq10Lq1b3Sz114wYIBX09P/l5IqtF2sVNq33/rkuZdfhqFDfX9w/RGVqNWvD7Nnw6OP+tLMSy7x/eoLJuzFqA0jUiFK8FIu69fDySf7mOd778E112j/dqk9ttoKzj8fJk/28shnneVfRA880IePHnzQe59EUon+RMtGrV0L69ZBWho895xPdDr88KijEildhw7wyCM+A/+RR6BePW/VFxTOWbFCrXpJDUrwUqpVq7yy2LXX+nH79t71KZIMtt7ax+Ozs+G77yA93c/36QPHHRdpaCI1QgleSrXFFl64RkVrJNkV3Z64Z0/o1ctf5+V51bzPP1erXuJHs+jlT/Lz4a67vHhNhw5RRyNSvaZt/FdBAAAgAElEQVRM8XH6lSt9Gd6AAdC3L2yzTdSRiZSfZtFLmX79FXr0gCFD4Pnno45GpPrts4+P1Y8Y4ccXXujDUAUT9mLU/pEUpAQvgE+e239/ryn/wAPeihdJBdtsAwMH+rbGkyZ5tbznnvMtjvffHx5+2LvyRZKNErzw7397BbC1a30/7kGDVA1MUo+ZJ/XHH/dW/fDhvjz0vvt8FQnAjz9GG6NIRSjBp7BVq7wqXf/+Ppnuyy890YukuoYNvbv+q698z3oz+OMPL4d73XVRRydSPkrwKWrOHDjoIN+p67rrvGteu+2K/JnZn/9d3H67z8IHmDoV/vpX79oXqY2U4FNUVpbv2/7GG3DrrYVdkCJSsi23hIsuKlw2+tVX8PTTPk5/wAHetf/779HGKFKUEnwKWb/e1/sCnHqq1+8+4YRoYxJJVmee6WP1DzwAq1f7zPsddoALLvDkLxI1JfgUcvPNcMgh3nIH2HbbaOMRSXaNGvmk1ClT4NNP4aST4Mknvepjp05abirRUoJPAfn5/nzppT7m3rZttPGIxI2ZF8x58klv1d93n3fXT5zo74cA33wTaYiSgpTgYywE30XriCN8Cdx223m3oohUn8aNfXObqVN9W2WA8eO9qM6YMZGGJilGCT6mfv/dS25efLFvurF6ddQRiaQWM9/PAbwM7n33Qbdufvzwwz5hb8qU6OKT+FOCj6HvvvPxvxdfhNtug9GjVVtbJEoFrfqChJ+b68Nl++7rtSf+8x9fZy9SlSJL8GZ2rJnNMLMcMxu8kesOMLP1ZnZKTcaXrF56yZfsLFrka9uvvRbq6GucSK1y660+Vn/PPbBsGZx3ns/Av/hijdVL1YnkT7+ZpQHDge5AO6CPmbUr5bo7gbE1G2HyWbcOLr/cl7/ttZdXpTvqqKijEpHSbLstXHYZfPutl4g+4QR47DEfqz/wQHj//agjlGQXVduuI5ATQpgTQlgLvAD0KOG6i4FXgEU1GVyyWb4cDj8c7r3XWwAffgitWkUdlYiUhxl07QrPPOO17u++G5Yu9VLS4C39qVOjjVGSU1QJviUwv8hxbuLc/2dmLYFewMM1GFdS2npraN3a19zefz/Urx91RCKyKbbbDq64AqZPh+7d/dwDD/gkvUVq5kgF1Y3o95a0V1nxnZfvBa4JIay3jWxtZmYDgAEAbdq0qbIAa7sQvMV+8snQpo0KaojEiVnhjo5/+5vPq2nWzI9PPx2aN/c6+O02GNgUKRRVCz4XaF3kuBXwU7FrMoEXzOx74BTgITPrWfwHhRAeDSFkhhAym6bQbim5uXDjjb7Vq4jEV5MmXiEPfF/6tDQYMQL23NMrUz79dGF3vkhRUSX4yUCGmbU1s/rA6cCfSkCEENqGENJDCOnAy8CFIYTXaz7U2uX777313rq172J1441RRyQiNaVuXXj2WR+rHzYMFi6Efv2gZUufZDt9etQRSm0SSYIPIeQBg/DZ8dOBUSGEaWY20MwGRhFTMhg5EvbYw2faAuyyS2E3noikjqZN4corYcYMn21/9NEwfLh32XftCjNnRh2h1AYWQvGh7+SVmZkZsrKyog6jyq1e7ctpHnnEZ8s//7yPwYmIFFi0yBsBzz7rK2kaNoQJE7zIzu67Rx2dVCczyw4hZG5wXgm+dvv+e+jd2/dvHzwYbrnFu+lERMrSubM3EAq2r83PV+GrOCotwStV1GJvv+315Nevh9dfhx4lVQoQESnF6NE+Xg+wYgXsvbevvBkwAHbbLdrYpPrpu1wttH493HQTHHecF6zJylJyF5GKa94cOnTw18uW+XK7++/3LvuC4b41a6KNUaqPEnwt9Le/wc03++zYCRN8Mp38v/buM0qqKvv7+HfT5GAEBQEBCSoiorQoYiAYEBVExizGETFjDjgYxyzmhBEds8JfR1FUhMGAQqOISBIJghEzoqTu87zY1U8jAhK66lTd+n3WqtV1b91q9lWoXSftIyLro2FD36ti7ly47jqYMweOOsobERdcoIl5SaQx+CwSgs+K//xz3z/6xBM1S15E0qOkBEaM8Mm7L77oa+w7d4Zhw6BKldjRydpY1Ri8WvBZ4v77oXdvT/JNm8JJJym5i0j6VKjg+9M//7y36q+91qtilib3xx6DGTPixijrRwk+S/z66583mBARyZS6deGSS3xfevANrE45BQYN8uOSEliyJF58sm6U4COaPh1GjvTn558PL78M1avHjUlEZMMNfajwvPP8+M03faz+oovUqs8lSvCRDBkChYX+LXnZMu+O1/pUEckWW2xRVlBr002hQwffyrZ5c+/af+45teqznVJKhi1b5jNWe/XysrNvvqnCNSKS3dq2haFDfeb91Vd77+Nhh/nM/Isv9ta+ZB8l+Az6+mvo0gVuvhlOOw1Gj/ZJLSIiuaB+fbjsMpg502fbt2/vn2fNmsHJJ8eOTlakBJ8ho0d7wYlx43x7x7vv1lIUEclNBQWw//5eYXPOHLjqKthlF39t0SIv1DVvXtQQBZWqTbsQYOBAn5zStCm88Qa0ahU7KhGR8lG/PvzrX2XHY8Z4N/7uu/vEvF9/hWrVoFKleDHmK7Xg02zyZB+jOvhgb70ruYtIknXq5K36zp39+MorfSiyf3+YNStubPlGCT5N5s/3n9ttBx984DNON9ggbkwiIpnQoEHZqqCuXX3F0PXXey9m164+YW/p0rgx5gMl+DR4/31o0gT++18/3mknVaUTkfy0zz7+WThrlnflT5oEhxwCjRr5hL05c2JHmFxK8GnQpg0cf7zv3CQiIt5Nf+WVMHu2177fcUcvj9ukCdx5Z+zokkkJvpx88QUccYRvyVi1Ktx1l5d/FBGRMhUrQvfu8Mor3qq/7DLYay9/bdw4GDDAP0dl/SnBl4PXX/du+GHDvPtJRET+XqNGvsSudWs/fvtt36++tPjXnDleHEzWTbQEb2ZdzWyamc0ws4tX8vrRZjYx9XjPzHaIEefqlJT4cpCuXaFePSgq8qUhIiKy9s4915N6zZq+xPjAA70L/4orfMc7WTtREryZFQB3A/sDLYEjzazlCpfNAvYKIbQGrgYGZTbK1fvxR//LN2AAHH20T6xr0SJ2VCIiuW3DDf1nCN6AatXKW/mNG8NBB/mmXMXFUUPMGbFa8O2AGSGEmSGEJcDTQI/lLwghvBdC+Cl1+D7QIMMxrtL48d4l/+abcM89vm9yjRqxoxIRSY4KFbx+yKuveq37Sy7xXtKDDvJkf+WVqpb3d2Il+PrA8h0u81LnVuUk4NW0RrSGHngAdtvNu+ffeQdOPVVL4ERE0qlJE7jmGp/M/MILXl/kyit9DP+992JHl71ilapdWUoMK73QrBOe4Fc6um1mfYA+AFtmYOeWCROgY0d44gmoXTvtf5yIiKRUquRr6A85xGfgP/542XLku++Gn37yCnr/+59/TrdvHzXc6CyElebV9P6hZu2BK0II+6WOLwEIIVy3wnWtgaHA/iGE6X/3ewsLC0NRUVG5x/v557Bwoc/0XLLEN1ooKCj3P0ZERNbRCSfAtGneCFuyBCpXhhEj8iPJm9n4EELhiudjddGPA5qbWRMzqwwcAby0/AVmtiUwBOi9Jsk9XUpKoGdPOPFEn/RRubKSu4hItnnkEejWzZN7cbH/HDUqdlRxRUnwIYRlwBnAcGAK8GwI4VMz62tmfVOXDQA2Be4xswlmVv5N89VYtsxrJVeoAIMHw/PPa6xdRCSbdelS1girXNm76fNZlC76dCmvLvpvv4Ujj/SSswMHlkNgIiKSEWPGeMs9n8bgV9VFr/3gV/Duu3DYYb7O/dhjY0cjIiJro337/Ensf0elalNCgNtv92991ap54Zrjj48dlYiIyLpRggcWLPCNYvr180kaRUWwQ9YVxhUREVlzeZ/gJ0+Gdu18Et3118PQobDRRrGjEhERWT95PQY/cqSXPaxRw8vOduoUOyIREZHykdct+NatPcF/+KGSu4iIJEveJfgvv4QzzvAiCJtuCk89BfVXVwVfREQkB+Vdgv/gAy9c88knsSMRERFJn7xI8CUl3g0PvknBzJnQtm3cmERERNIp8Qn+55+9lvyuu8L0VEX7OnXixiQiIpJuiZ5FP2EC9Orlewjfeis0bx47IhERkcxIbAv+0Ue9XOHixTB6tE+s02YxIiKSLxKX4BctgpNP9r2Bd9vNx95Vl1hERPJNorro583zErPTp8Oll8JVV2nvdhERyU+JSvDffuuPG2+ECy6IHY2IiEg8ieuiLyiAZctiRyEiIhJX4hJ85cq+5auIiEg+S1SCr18fRozQpDoREZFEJfi6dZXcRUREIGEJXkRERJwSvIiISAJZCCF2DOXGzBYA02LHkWG1ge9jB5FBut9k0/0mW77dL2TmnhuFEP6yy0qi1sED00IIhbGDyCQzK8qne9b9JpvuN9ny7X4h7j2ri15ERCSBlOBFREQSKGkJflDsACLIt3vW/Sab7jfZ8u1+IeI9J2qSnYiIiLikteBFREQEJXgREZFEUoIXERFJICV4ERGRBFKCFxERSSAleBERkQRSghcREUkgJXgREZEEUoIXERFJICV4ERGRBFKCFxERSSAleBERkQRSghcREUkgJXgREZEEUoIXERFJICV4ERGRBFKCFxERSSAleBERkQRSghcREUmgirEDKE+1a9cOjRs3jh2GiIhIxowfP/77EEKdFc8nKsE3btyYoqKi2GGIiIhkjJnNWdl5ddGLiIgkkBK8iIhIAiWqi16kvAwdChMnwr77Qvv2saMREVl7asGLLGfMGNh5ZzjkELjiCthzTxg+PHZUIiJrTwle8t7vv8Ovv/rz+fNh+nQw8+Nly6B7d7jwQvjmm3gxioisLSV4yWsLFkDjxnDjjX584IHw8stQtSoUFECVKrDXXnDLLX7d6afD7NkRAxYRWUNK8JJ3JkyA22/357VqwXnnQbduflyhAuyxB4wYAVdfDSNHwuuvw7RpcOyx8MADMGRIvNhFRNaUhRBix1BuCgsLg9bBy8qUlMArr8Ctt3rSrlUL5syBjTdeu98zb56/p0YNeOwxePFFeOQR2GCD9MQtIvJ3zGx8CKFwxfNqwUuiLVwI994L227rY+mffebd8euS3AEaNPDkDvDbb/Djj/5lAeCLL8ovbhGR9aUEL4n05Zdw6aXQsCGcdhpsuCE89RTMnAkXXLBuyX1Fp50Gb73lE/J++glatfLu/VdfhQR1jIlIjlKCl8T54w9o2RJuuAE6d4Z33oEPPoAjjoBKlcr3zyqdbV+1Klx7rfcMdOsGbdvC889DcXH5/nkiImtKCV4S4a23fIZ7CFCtmk+GmzHDk2yHDmWJOF2qVYMzzvA/8+GHfWjg0ENhu+3g0Udh6dL0/vkiIitSgpec9dtvsGiRP58yxZe3zZ/vx4cdBk2aZD6mypXhhBNg8mR45hlv2Z9wAjRrBnffra57EckcJXjJOfPmwUUX+fj64MF+7uST4fPPYbPN4sZWqqDAv2R89JF/8ahfH156qawnYcmSuPGJSPIpwUvOKCqCo47ylvnNN8M++0BhamFI5cpQMQt3VjCDAw6Ad9/14QLwcfoGDWDYsLixiUiyZeFHokiZ4mJv+Q4c6JPlatWCs86CM8/0ynK5wqxsOd2yZV4db/vt/XjqVH+tfv148YlI8qgFL1lryBBo0cI3fpk3z4vUzJtXVjY2VzVtCs8950MMAGefDVttBaec4sMMIiLlQQlessoXX3jxGPDqc3Xretf2Z59Bv37JrBh3771w4ok+275FCzj6aJg0KXZUIpLrlOAla3zzjbdu77rLj3v18rHrXr2yc3y9vGy1lSf5WbPgnHO8/O3228PBB8PYsbGjE5FcpQQv0Sxb5q3zK67w47p1PdEdf7wfp3vterbZYgufPDhnDlx+OYweDbvsAnvv7RX4RETWhhK8ZNyvv/p4evPmXgzmySfL1rP/85+w5ZZx44tt0039S8+cOV43f9482GQTf+2bb7SWXkTWjBK8ZMzs2b41a4MGcO65PslsyBAvUlO1auzosk+tWl43f8oU2GgjT+z77guHHx47MhHJBWlP8GbW1cymmdkMM7t4Ja/3MLOJZjbBzIrMbPc1fa/khjFjvOhL06Zwxx1w0EEwbpx3Qffs6UVhZNVKhypKSjzhH3usHy9Y4GVxVTRHRFYmrfvBm1kBMB3YB5gHjAOODCFMXu6amsDCEEIws9bAsyGEbdbkvSvSfvDZ54cffGy5enVfBnbGGd6Cl/X38MNw0kn+3/OCC3x4o3r12FGJSKbF2g++HTAjhDAzhLAEeBrosfwFIYTfQtm3jBpAWNP3SnYaPNiXeoGPJw8bBnPnwvXXK7mXpxNOgNde81n4Z58NjRr5jna//BI7MhHJBulO8PWBucsdz0ud+xMz62lmU4FXgBPX8r19Ul37RfNLdxqRjJs5s2yi3I8/+n7sv/3mx126QM2a8WJLKjPYbz/43//g7behXTvo398nKfbvX7bxjojkp3Qn+JUtdPrLmEAIYWgIYRvgYODqtXzvoBBCYQihsE6dOusVrKydEMrWqTdvDk895efPPhtGjVJSz6Tdd4dXXoEPP/Skf9113qK/997YkYlILOlO8POAhssdNwC+WtXFIYTRQFMzq72275XMWbrUk/kuu3hiGTnSd3fbd19/vYLWZkSz447w7LM+8/6II3ybWoDvvvNqgCKSP9L9UTwOaG5mTcysMnAE8NLyF5hZMzOfJ2xmOwGVgR/W5L2SWT//DDfd5GO+Rx3lx/fc4+Pr116rzVKyydZb+yS8ffbx45tvhu22U7e9SD5JawHQEMIyMzsDGA4UAA+HED41s76p1+8DegHHmtlS4A/g8NSku5W+N53xyqrdfruP6y5cCJ06eddvt25qreeK886DnXaC0lGsf/8bOneG9u3jxiUi6ZPWZXKZpmVy5ScE3551u+28itpzz8HLL3ut9DZtYkcn6+PHH72F//330LGjf3Hr0iX/SgOLJEWsZXKSo6ZPhz33hIce8uNDD/Xlb0ruuW+TTbyq4MCB/v95n318PsX//Z8X0xGRZFCCF8Bbdddf71254C28F1+E00+PG5ekR40a3hszcyYMGuQFiXr2hNat4YknfCMgEcltSvB5bvp0T+ING8Ill8DkyVBc7K91767KaElXpQqcfDJMm+aJHeCYY3y8Xq15kdymBJ+HQvB16t27wzbbwIMPeq34jz+GV19Vbfh8VLGir4yYONF7bk45xSdQhuBDM6VFi0Qkd6R1Fr1klyVL4JlnfOx1wgSoXRsuuwxOO833YhepUMG/+JUaNw6OP95rH/zzn9HCEpF1oASfB0LwGdLz58OJJ3rVuQce8Hrx1arFjk6yWbt2vhvgjjv68UMPeXf+uefqS6FItlMXfcJdcUVZi6x+fRg/Hj791FtjSu6yJnbd1cfqwedo3HILNG7sczfmzIkamoishhJ8woQAb71Vtkf4Jpt4S2vpUj9u3VrrnWXd3XILTJ0KvXt7L1CzZt6FP3Vq7MhEZEVK8AmxeDE8+qivU+/SBZ5/3s+fdZZ/EFeqFDU8SZDSIZ6ZM+GMM7z2fcuWXivhww9jRycipZTgc9z8+XD11b5z2Akn+BK3hx6CQw6JHZkkXYMGcOut3k1/6aXwxhvQtq3vMCgi8SnB56jJk6FPH9/7e8AAnwT1+uvwySc+ka5q1dgRSr6oUweuucYT/T33lNW3f/RReO21qKGJ5DXNos9B55wDt93mSbx3b+jXz7tIRWLacEM49VR/HoIvx2zRArp2LTun+R8imaMEnwMWLfL91w85xD9Ed9/dJ8/17Vu2O5hINjGDoiLfUhh8El6vXnDhhV5QR3NCRNJPXfRZrHSjv8mTvdu9dOJcr17wr38puUt2q1wZNtvMn//8syf144/3SXr33AN//BE1PJHEU4LPQpMm+Tr10u7OnXaCsWM9yYvkol13hY8+8i2Ht9jC19A3aQI33ggLFsSOTiSZlOCzRAg+IWm//WD77eHJJ32MvbQVv/POGr+U3GYGBxzgs+xHjvSaDBdd5BNFL7/cd7QTkfKjBB/ZH3/4muJWrWD//X0W/L//DXPn+kQ6JXVJGjPo2NFXfYwdC506wVVXedVFESk/mmQXyQ8/wB13+Fjk9997gZrHHoPDD/exS5F8sPPOMGSIl0/ecEM/9+678Pjj/kV3003jxieSy9SCz7DFi/3nb7/Bddf5muGRI70CWO/eSu6Sn7bbzgvngG9Z+8orZXslLFwYLy6RXKYEn0G9e0PPnv68USPvhn/pJe+uVFe8iDv1VJgxA6pXh2XLvIhTz56+da2IrDkl+DT6/Xd45BH/kALYbTfYa6+yiXObbx4vNpFsVrp73dKlcOSRMGqUb127777+vPTfkIismhJ8Gnz9NVx2mc8OPvFEGD7cz596qs8aVmtdZM1UqwZXXullcG+80bvvO3WCDh18yZ0SvciqKcGXowkT4LjjvPv92mthjz1g9Gjo1i12ZCK5bYMN4IILYNYsuPtu+OorOOggn5z6zDO+yZKI/JkS/HoqKYH//hc6d/axwhde8BKy06fD0KGe5NViFykf1arBaafBZ5/B4MGwZIlXdSylFr1IGSX49dSzJ3Tv7h84N97oE+fuuAOaNYsdmUhyVaoExx7ry+veeAMKCny2fdu2/oVbRJTg19o33/j2rKXlNU86yavOzZzpXYgbbxw3PpF8UqGCD4kBfPcd1KxZtnZ+/nz45Zd4sYnElvYEb2ZdzWyamc0ws4tX8vrRZjYx9XjPzHZY7rXZZvaJmU0ws6J0x7o6S5f6zzlzvADH//7nx927+yxf7Y4lEleTJj7nZbfd/HjAAE/+l13myV4k36Q1wZtZAXA3sD/QEjjSzFbcuXwWsFcIoTVwNTBohdc7hRDahBAK0xnryhQXw4sv+tK2007zc7vs4kn+wAMzHY2IrI0+fWCffXzCa6NG0K8fzJsXOyqRzEl3C74dMCOEMDOEsAR4Guix/AUhhPdCCD+lDt8HGqQ5pr/1229w112w9dZw8MEwezbssEPZ6w2iRygif2fHHeG553y75cMP99n3W20FJ5/shXREki7dCb4+MHe543mpc6tyEvDqcscBeN3MxptZnzTE9ydz5/o69YYN4cwzfb/1Z56Bzz+HM85I958uIumwzTZecGrGDG/VP/64f3k/8kifOyOSVOlO8CtbILbShSxm1glP8Bctd7pDCGEnvIv/dDPbcyXv62NmRWZWNH8dB9o+/xyOOsrH8G6+2bv13nsPxoyBww6DitqSRyTnNWrkPXOzZ/uE2FdfLasyuWhR1NBE0iLdCX4e0HC54wbAVyteZGatgQeBHiGE/78rdAjhq9TP74CheJf/n4QQBoUQCkMIhXXq1FnjwIqLfRe3Uq++Cmef7cn+2Wd9ExgRSZ66deH6673iZIsWfu6oo6BXr7hxiZS3dLdNxwHNzawJ8CVwBHDU8heY2ZbAEKB3CGH6cudrABVCCAtSz/cFriqPoEKA3Xf3LviXXoKmTf0fe9Wq5fHbRSQXlO5WFwLsuWdZQaqSEt+rft99fRmeSK5Ka4IPISwzszOA4UAB8HAI4VMz65t6/T5gALApcI/5v7BlqRnzmwNDU+cqAk+GEF5b11i++MIrX116qRfFOOUUL39ZSsldJD+Z+Qz7UsOGeRncVq3gkks0TCe5y0KCajsWFhaGoqI/L5f/4AO49VZ4/nk/fvddX+omIrIyy5b55Nprr/UZ+Ftt5ZNvjzuubJc7kWxiZuNXtpQ8kR1Qy5Z5Qu/QAXbdFV57Dc45x2fMKrmLyOpUrAhHHw2ffOL7SWyyiff4bbWVNxYWLowdociaSVSC/+ornyjXrBkceqiXlb39dl/+dtNNvn2riMiaqFDB62CMHev17lu0gHPP9dn4990XOzqRv5eoBP/1177Ry0YbwZAhvqPbWWdBrVqxIxORXGUGe+8NI0f6EF/79mW71i1aBN9+Gzc+kVVJVIIHn0B3+OG+y1tBQexoRCRJdtvNd6vr29ePBw+Gxo19N0mRbJO4BF+5MnTsGDsKEUmy0iV1nTtD//5l20M//TRMnRovLpHlJWoWfYMGheG554pUpEZEMm7xYt+n4ocfvGjOpZd6PXyRdMuLWfR166oCnYjEUaUKfPqpr51//XXYaSfo1g3eeSd2ZJKvEpXgRURi2mwz+Pe/vbDWtddCURHssYdXyhs+vGxynkgmKMGLiJSzDTf0lvzs2b5Ud9Ys6NoV2rWDP/6IHZ3kCyV4EZE0qV7dl+p+/jk89JDPwi+tgT96NCxdGjc+STYleBGRNKtcGU480Vvz4C36Tp18VzuRdNEWCiIiGda4Mbz4IhSm5j2PHOnj9X37qjCXlB+14EVEMswMDjzQV/4AvPoqXHihl8G94gpfaieyvpTgRUQiu/FG3/lyr73gyis90Z9/vpffFllXSvAiIlmgXTvfvW7SJN/k5tZbvSv/1FN9J0yRtaUELyKSRbbbDv7zH98s6/jj4eGHfSe7YcNiRya5RgleRCQLNW0K99/vrffzz/diOeAT8saNixub5AbNohcRyWL16/95OV3//vD77/DRR2Wb3oisjFrwIiI55LXX4KmnPLn//DPstx+88orK4MpfKcGLiOSQDTaAbbf15zNm+Pa0Bx7oO9c9+ywUF8eNT7KHEryISI4qLPQk/8gjsGgRHH44tGzpx0uWxI5OYlOCFxHJYZUq+Wz7Tz+F556DGjW8LG6zZnDnndrcJp8pwYuIJEBBAfzjHzB+vFfGa9TIN7o57rjYkUksmkUvIpIgZr41bdeu8PbbULOmn//iCxg0CM49FzbZJG6MkhlqwYuIJNQee/jkO4A33oCbb4aFC/24pCReXJIZSvAiInngpJO8Fd+woR937w59+vgkPUmmtCd4M+tqZtPMbIaZXbyS1482s4mpxyxuIzgAACAASURBVHtmtsOavldERNbcZpv5z2XLfIz+scdg663hqKPgk0/ixiblL60J3swKgLuB/YGWwJFm1nKFy2YBe4UQWgNXA4PW4r0iIrKWKlaEu++G2bO9DO5//wutW0OPHr6rnSRDulvw7YAZIYSZIYQlwNNAj+UvCCG8F0L4KXX4PtBgTd8rIiLrrm5duOEG77q/8kp45x3YdVfo0gVGjFB1vFyX7gRfH5i73PG81LlVOQl4dR3fKyIi62DjjWHAAJgzB265BaZMgUMOgQULYkcm6yPdCX5lWyGs9DuhmXXCE/xFa/NeM+tjZkVmVjR//vx1DlREJN/VrOnL6GbO9Fn3G2zgrfgjj9R2tbko3Ql+HtBwueMGwFcrXmRmrYEHgR4hhB/W5r0hhEEhhMIQQmGdOnXKLXARkXxVtSq0a+fPv/kGJk6E77/340WLYPHieLHJmkt3gh8HNDezJmZWGTgCeGn5C8xsS2AI0DuEMH1t3isiIulVr57PsD/6aD+++27fq/6228rW1Et2SmuCDyEsA84AhgNTgGdDCJ+aWV8z65u6bACwKXCPmU0ws6LVvTed8YqIyF9VqOClcME3uGnWDM45x5faXXONb1sr2cdCgqZJFhYWhqKiothhiIgk3rvvwnXX+V70tWrB6adDv36w+eaxI8s/ZjY+hFC44nlVshMRkbXWoQO8/DJ89BHsv78vt2vcGM48E+bO/du3SwYowYuIyDpr0waeeQamTvWKePfdB5Mn+2sJ6iDOSUrwIiKy3lq0gIce8up4++7r5y65xJO+NraJQwleRETKTf36vmUt+Nj8hhv6JD3wAjqSOUrwIiKSFv37w733+vOJE6FlS+jYEV5/Xd33maAELyIiaVe6dn7GDNhvPy+kM3Souu/TSQleRETSrkYNOPts+PxzePBBXzt/yCHQqhU8/jgsXRo7wuRRghcRkYypUgVOOsnH4596yreuPfZYn6T36KOxo0sWJXgREcm4ihXhiCPg44/hpZe8QM7Eif5aCCqDWx6U4EVEJBozOOggGDPGK+MBvPUWNGwI48fHjS3XKcGLiEh0Zt59D7DZZtC9u4/Pg5fF/frreLHlKiV4ERHJKttv7+PxVar4LPtjj4UmTeC002DWrNjR5Q4leBERyVoVKvi6+eOO80p5zZt7wlfRnL+nBC8iIlmtaVO4/36YORPOOgteeAG22w569dI4/eoowYuISE6oXx8GDoQ5c7xK3ogRvj/9fvvBDz/Eji77KMGLiEhOqV0brr4avvgCrr8eli2DjTf214YM8dn4Y8bEjTEbWEhQQeDCwsJQVFQUOwwREYngzTd9b/oQoHJlb+G3bx87qvQzs/EhhMIVz6sFLyIiifD++57ci4thyRIYNSp2RHEpwYuISCJ06eIt94IC/9mxY+yI4qoYOwAREZHy0L69d8uPGuXJPR+651dHCV5ERBKjfXsl9lLqohcREUmgRM2iN7MFwLTYcWRYbeD72EFkkO432XS/yZZv9wuZuedGIYQ6K55MWhf9tJUtFUgyMyvKp3vW/Sab7jfZ8u1+Ie49q4teREQkgZTgRUREEihpCX5Q7AAiyLd71v0mm+432fLtfiHiPSdqkp2IiIi4pLXgRUREBCV4ERGRRFKCFxERSSAleBERkQRSghcREUkgJXgREZEEUoIXERFJICV4ERGRBFKCFxERSSAleBERkQRSghcREUkgJXgREZEEUoIXERFJICV4ERGRBFKCFxERSSAleBERkQRSghcREUkgJXgREZEEUoIXERFJoIqxAyhPtWvXDo0bN44dhoiISMaMHz/++xBCnRXPJyrBN27cmKKiothhiIiIZIyZzVnZeXXRi4iIJJASvIiISAIlKsF/8w2MGRM7ChERkfgSleC//BI6d1aSFxERSVSCB1i0CB59NHYUIiIicSUuwZvBgw/CrbdCCLGjERERiSNRCb5+fXjtNTjoIDj3XDjsMFiwIHZUIiIimZeoBF+3Luy7LwwdCjfcAEOGwM47w+TJsSMTERHJrEQl+FJmcOGFMGIE/PQTtGsHTz0VOyoREZHMSWSCL9WxI3z0EbRpA8ccA9Onx45IREQkMxKd4AG22AJGjoThw6FFCz+3cGHcmERERNIt8QkeoFIl2Htvf/7669C0KXz8cdyYRESk/I0ZA9ddp3ookLDNZtbEllvCXntB8+axIxERkfL0yCNw2mmwdClUruzzsNq3jx1VPHnRgl/eNtvAM89A9erw229w1lk+EU9ERHLXoEFw4ole7Ky4GJYsgVGjYkcVV94l+OW99x7cdx+0beuT8UREJDcsXgy33QZvvunHBx0EZ54J1apBQYG34Dt2jBpidHmd4PfdF0aP9u6c9u3h4YdjRyQiIqtTOkm6oMArlr78sh/Xqwd33OHd8ldfre55AAsJqudaWFgYioqK1vp98+fDUUf5N8ETT4S77vJvgSIiEl8I8PbbntDHjoWZM6FKFfjhB9h009jRxWdm40MIhSuez+sWfKk6dbzE7WWXeSt+t938L5CIiMSzZAk8/jgUFvrk6NGj4fjj/Twouf8dJfiUggLv1nn5ZZg928fl//vf2FGJiOSf77+Ha66BRo3g2GPhjz/g/vth7lz497+hVq3YEeYGJfgVHHAAfPghNGniNe1FRCQz/vgDTj4ZGjaEf/0LdtjBe1cnTYI+fXz1k6y5vFsHvyaaNPEZ9qXTE6ZPh402gs02ixuXiEjSlJTAtGmw7bZQtSpMmeKt9rPPhpYtY0eX29LWgjezQ83sUzMrMbO/DP6nrmloZiPNbErq2rOXe20TM3vDzD5L/dw4XbGuTNWqPtGupAQOP9xb9gmajygikhUuvdTH2H/6yTcKGz3au+OV3NdfOrvoJwGHAKNXc80y4LwQwrbArsDpZlb6v/ViYEQIoTkwInWccRUq+MS7227zv3wlJUr0IiLrat48uOSSstojxx7rRWpq1PDjCho4Ljdp66IPIUwBMLPVXfM18HXq+QIzmwLUByYDPYCOqUsHA6OAi9IV7+rsuGPZ8wEDfIb9oEFQs2aMaEREcs/Ysd5Qeu45byjVq+efrS1bqrWeLlnzXcnMGgM7Ah+kTm2e+gJQ+kUgK0bAa9b0Ure77AJTp8aORkQkey1bBs8/Dx06+Gfmyy97tbkZM7xMuKTXeiV4M3vTzCat5NFjLX9PTeAFoF8I4de1fG8fMysys6L58+evzVvXycUX+4508+fDzjv7t1ERESnz889wyy3QrBkceih88w3cfrt3zw8c6BOZJf3WK8GHEPYOIbRayePFNf0dZlYJT+5PhBCGLPfSt2ZWL3VNPeC7VcQwKIRQGEIorFOnzvrczhrr0sWX0m2/PRx2GJx7rpe7FRERuPFGOP98aNwY/u//fCXSWWfBBhvEjiy/RO2iNx+gfwiYEkIYuMLLLwHHpZ4fB6zxl4ZMaNDAdyo66ywvn9ipE3z1VeyoREQy79tvoUcPePVVPz7rLG8EjRrl5wsKooaXt9K5TK6nmc0D2gOvmNnw1PktzGxY6rIOQG+gs5lNSD26pV67HtjHzD4D9kkdZ5XKlb3b6amnYMIEnzAyblzsqERE0m/xYi9AA7DxxjBnjlegA6hb98+TkyUObTZTTiZP9m+tTzwBm28eJQQRkbT77ju491645x6oVAlmzfKfIfhSYsk8bTaTZi1b+m50m2/uM0evuAJ++SV2VCIi5WPiRN9ts2FD/3wrLIRHH4WKqcXWSu7ZRwk+Dd5/3zdEGD48diQiIuuupMQ33erSxevCP/MM/POfvkT4lVdg772V2LOZatGnwe67+z+Apk39eOZM2GqruDGJiKyNr7+GPff0NesNGsD11/tGMJtsEjsyWVNqwadJaXKfOhW22w769oVFi+LGJCKyOl98UbZNdt260L69TyKeORMuukjJPdcowadZs2a+K9L998Mee/he8yIi2ejSS+G443yGvBk89hgccYRPopPcowSfZhUretfW0KFe7KFt27K1oiIisSxdCk8/Dbvu6hPoAK6+2pf8VqkSNzYpH0rwGXLwwTB+vI9lHXAAXH45FBfHjkpE8s2PP8INN/i8oCOP9OPS9etNmsCWW8aNT8qPEnwGNWsGY8b49ohXXQXdupX9wxIRSadp0+C003yZ28UXQ4sWPt4+dSp07hw7OkkHJfgMq14dHnnEt5sdNcpnqS5bFjsqEUmqUaO813CbbeChh+Dww+Hjj2HECDjwQO2/nmRaJheBmS832XFH312pYkWvAlX6mojI+li0yMfRzeCll6CoyIvT9O2rSpv5RN/dIios9LF5gAcf9K57LaUTkfUxYYJ3w48Y4ccDBvjyt8svV3LPN0rwWeKHH/yh5SgisrY++ghee82fb7MNdO0Km27qxxttpFnx+UqbzWSR4mLfVvGrr2Ds2LLWvYjIioqLfZLcrbfC6NHQqpUvd9MwX/7RZjM5oHTP5H//G3r2hAsu0AQ8EfmzX3/1bapbtPDPidmz4aab4O23ldzlzzTJLgsNHOg/b77ZW/JPPw316sWNSUTimjUL7rzTZ8L/+ivstpuvZz/44LId3USWp78WWahKFbj7bq8D3acP7LST7+K0556xIxORGD78EHbe2Ze0HXoo9OsH7drFjkqynbros9gxx8AHH0CtWl6I4pZbypbTiUiyPf003HefP2/TBq67zlvxTz6p5C5rRgk+y22/va9h7dEDzj8f/vEP754TkeRZsKDs+Qsv+GYvIXjL/cILvdS1yJpSgs8BG2wAzz/vY/IvvgiPPho7IhEpT1OmwCmn+BatU6b4uQcegHfe0cQ5WXcag88RZnDeedClC7Ru7ee+/VaFK0RyVQjw+uu+zG34cKhaFXr39nLW4OvXRdaHWvA5pk0b76776itf93rDDbEjEpG18fvvvhfFdtt5QZqJE+Gaa2DuXD/fqFHsCCUp0pbgzexQM/vUzErM7C8L8FPXNDSzkWY2JXXt2cu9doWZfWlmE1KPbumKNRfVqeP17FUMRyR3XHutb8d6yilQrRo8/rivY+/fH2rXjh2dJE06W/CTgEOA0au5ZhlwXghhW2BX4HQza7nc67eGENqkHsPSGGvOqVTJPyy23tq7+s4807v7RCS7fPJJ2eqXb77x5a6jR/vk2WOOgcqV48YnyZW2BB9CmBJCmPY313wdQvgw9XwBMAWon66YkuqXX3xLyK5d4eqroaQkdkQiAjBkiM+ZefttP779dj+3xx6aPCfplzVj8GbWGNgR+GC502eY2UQze9jMNl7F+/qYWZGZFc2fPz8DkWafjTaC99+Ho4/2naMOPNA3rhGRzPrlF69E+eSTfty1K9xxh8+dASV1yaz1SvBm9qaZTVrJo8da/p6awAtAvxBC6Srve4GmQBvga+CWlb03hDAohFAYQiisU6fOetxNbqtRw9fM3nMPvPkmtG3rXYAikn6ffw5nn+3r1M87r2y4rHp1Hz7bYIO48Ul+Wq8EH0LYO4TQaiWPF9f0d5hZJTy5PxFCGLLc7/42hFAcQigBHgBUu+lvmMGpp/ra2RCgQweflavqdyLlLwT43/98omvz5nDvvf68qEi1KiQ7RO2iNzMDHgKmhBAGrvDa8tur9MQn7ckaaNcOxo+Hjh19tu4JJ/jSHBFZf4sXw+DBvkdEx47+hbp/f58N//jj3nsmkg3SuUyup5nNA9oDr5jZ8NT5LcysdEZ8B6A30Hkly+FuNLNPzGwi0Ak4J12xJlHt2jBsGFx+OXz8cexoRJLj9dfh+ONhyRLvIZs71ye3brFF7MhE/sxCgvpvCwsLQ5EGnv9i8WLfoW7BAnj3XZ/4IyJrpqQE+vb1AjT9+0NxsXfNd+qkSXOSHcxsfAjhL/VmsmYWvaRPlSr+84YbfIb9rFlx4xHJdiUlMG6cP69Qwb8cL1zoxwUFvrujkrtkO9WizyOXXebrb5s08eM//vBqWiLiFi708fXbb4fPPoPp06FZM1/2poQuuUYt+DxStSrst58/f/VVaNHCu+xF8t3cuXDRRb7M7fTTfVnbf/5TVhdeyV1ykRJ8ntpiC++679gRbrtNS+kkP33wARxxhPdq3Xwz7L23z4ofOxaOOspLQovkKiX4PLXDDr5e94AD4Jxz/ENuwYLYUYlkRgi+9fKuu3pvVr9+Xqzmuee8foRa7JIESvB5bKONYOhQn3z3/PO+fn7y5NhRiaTHTz+VFaAxg7328jKy8+Z5671x45jRiZQ/Jfg8ZwYXXggjRsCPP3qSf/rp2FGJlL8nn/SiT5NSJbMGDPAysrVqxY1LJF2U4AXwsfiPPvJNMY48Eq68MnZEIusuBP/SetBB8MADfu644/zveKtWcWMTyRQlePn/ttgCRo6Ec8/1Ih4iuWbRInj4YZ9jsvfePlmudAJpzZplu7qJ5AOtg5c/qVQJbllu374bb/Ta2l26xItJ5O98+61v9nLvvfDdd74H+8MPe29U1aqxoxOJQwleVumPP3zzjBkzlOAlO02Z4l9Cn3wSli71So39+qmMrAgowctqVKsGY8ZAxdTfks8+801sNt44blyS34qLPZlXreoT5p57Dvr0gbPO8m1bRcRpDF5Wq2ZN/yAtLoaePb27/qOPYkcl+WrhQth2W7jpJj/u2dOr0N15p5K7yIqU4GWNFBT4bOQlS6B9ex/fFMmEOXPgscf8eY0antR33NGPK1ZUj5LIqijByxpr395b77vvDiedBP/8p4/Ti5S3EHyfhEMPha228i74H37w10p3RRSR1VOCl7VSpw4MH+77Yj/0kJf1nDkzdlSSFEuX+oS5XXbxL5IjRsAFF/j8j003jR2dSG5Rgpe1VlAA11wDL7/se8u3bevPRdbVDz/Addd5udijj4ZffoF77vHx9euvh4YNY0cokns0i17W2QEHwIcfQq9eXjFswgQvMCKyNn7/3fdc//lnL07zwAPQtStUUPNDZL0owct6adIE3nsPhgwpS+7Fxd7KF1mVt9/2Xp8bboDq1WHgQCgshO23jx2ZSHLoO7Kst6pVfe9s8Fb8ttvCxIlxY5Ls88cfvgoDYNw4GDwY5s/34xNOUHIXKW9pS/BmdqiZfWpmJWZWuIprqprZWDP7OHXtlcu9tomZvWFmn6V+ajFMDjCDevX8IQLw1Vdw2WU+jv7kk37u1FN9+VudOnFjE0mydLbgJwGHAKNXc81ioHMIYQegDdDVzHZNvXYxMCKE0BwYkTqWLLfDDvC///kH99KlPhnvt99iRyUxjB8PvXv7xLlrr4U99oCWLf21atWgSpWo4YkkXtoSfAhhSghh2t9cE0IIpR//lVKP1N5P9AAGp54PBg5OS6CSNm+/DZdf7nvMT50aOxrJhOJin4+x554+pv5//+et9c8+g6FD/e+CiGRG9DF4MyswswnAd8AbIYQPUi9tHkL4GiD1c7NYMcq66dwZXn8dvv8edt7Za4ZLcj37rJeL7dXLl7cNHAjz5sHtt0PTprGjE8k/65XgzexNM5u0kkePNf0dIYTiEEIboAHQzsxarWUMfcysyMyK5pfO2JGs0aWLL6Vr1QoOO8z3ml+6NHZUUl5mzvTlbQDLlkH9+vDCC95iP+cc2HDDuPGJ5LP1SvAhhL1DCK1W8nhxHX7Xz8AooGvq1LdmVg8g9fO7VbxvUAihMIRQWEczdrJSgwY+Ln/mmXDrrb6V51dfxY5K1tcXX3iL/b77/PjII31Y5pBDynYgFJF4onbRm1kdM9so9bwasDdQOlr7EnBc6vlxwFp/aZDsUbky3HGHz6L+6CPfLGTUqNhRydpYsgQefxyuuMKPt9wS7r/fJ9KB9l8XyTbpXCbX08zmAe2BV8xseOr8FmY2LHVZPWCkmU0ExuFj8KVFT68H9jGzz4B9UseS4448EsaO9R3ASrf8lOz2/fe+GqJRIzj2WJ8sVzrM8s9/ere8iGQfCyH8/VU5orCwMBQVFcUOQ9bAggWeJDbZBL75xpdNabw2u3z6Kdx2G/znP7BoEey3n4+r77OPysiKZBMzGx9C+Eu9GY2USRS1avnPELxV//PPvm5aiSOukhLfLfDWW+GNN7xK4bHHwtlnl61hF5HcoAQvUZl59+/8+Uru2eDbb6F7d9hsMy9O06ePtmkVyVVK8BJdhw5lz++7zyfh3X67tx4l/QYOhPff93Xs9er55Medd/aJkSKSu9Rmkqzy1VcwaJCXNZ09O3Y0yTVuXNnGLyUl/li82I87dFByF0kCJXjJKldd5bO0p0+Htm3htddiR5Qcy5Z5NcEOHbxkbGllwfPPh+efV214kaRRgpesc/DBPuGuQQPo1s3XXRcXx44qd/38M9x8s5eLPewwX7Vw++0+1i4iyaUEL1mpWTMYM8aLqFx5JRxwgK/HljU3YwacdZZ/UbrgAmjSxDd/mT7dz5euZBCRZFKCl6xVvTo8+qhXSxs50rvsP/wwdlS54YILoEULn7TYq5f/dxs1Cnr0gIKC2NGJSCYowUtWM/OlWu++64VwatSIHVF2WrTIvwz98osft2sHl13m9eIHD/bSwCKSX5TgJScUFsKECbD11l4c5/774fffY0cVX2khysmT4YQTfLIcwKGH+oTFunXjxSYicWkdvOSM0kI448fDqad6cuvbN25MsXz8sU+Uq1TJv+zstBN88IGvXxcRAbXgJQcVFnoy69PHj3/4IW48mVJSAv/9L3TuDG3awDPP+JBFaSu+XTvt6CYiZZTgJSftvLO36OfNg222gQsv9HXeSfTbb3DXXT480b07fPYZ3HADzJ3rVeiU1EVkZZTgJafVqeNru2+6Cbp08TXeSfHttz4bvkEDOPNMrwn/9NMwc6Z/odlkk9gRikg2U4KXnFalCtx9Nzz+uJdf3XFHePvt2FGtuxC8xQ4+M/7OO32b1jFjvF784Yf7uLuIyN9RgpdEOOYYH5evVQs6dfKu69Kx6VzSs6fPgAdo1Mhr8z/zDOy6a9y4RCT3KMFLYmy/vbfiu3eH887zRPnrr7GjWr0ff/TZ8KXzB7p1g4MOKvtyom54EVlXWiYnibLhhvDCC3DLLXDxxTBlildxy7aNVKZN88Q+eLCv52/VyucQlK4MEBFZX0rwkjhmvkNau3ZeACZbknsI8OabcNttMGyYb8l69NHQrx+0bh07OhFJGiV4Saw99/QHeEIdNsxb9plO+H/8AU884Yn9009hs818h7y+fWHzzTMbi4jkj7SNwZvZoWb2qZmVmFnhKq6pamZjzezj1LVXLvfaFWb2pZlNSD26pStWSb6iIq9nX1KS+T+7a1c4+WTf5OWRR2DOHLj8ciV3EUmvdE6ymwQcAoxezTWLgc4hhB2ANkBXM1t+vvCtIYQ2qcewNMYqCTdgALz3HlSr5hPvRo1K3581fbqPpZcud+vfH956y2vpH388VK2avj9bRKRU2hJ8CGFKCGHa31wTQgipj0EqpR45uLhJckG1av7z6qu93Os115Rfi764uGzG/o8/wpNPlm1tu+++vnRPFedEJJOiL5MzswIzmwB8B7wRQvhguZfPMLOJZvawmW0cKURJmCuu8Mlt//qXL0n78cd1/10LFvhs+BYtfGIf+Jr1r78uG/8XEYlhvRK8mb1pZpNW8uixpr8jhFAcQmgDNADamVmr1Ev3Ak3xrvuvgVtWEUMfMysys6L58+evz+1InqhRAx57DO65B954A9q29R3q1sbs2XDuuV5Gtl8/qFcPDjig7PVatco1ZBGRtbZeCT6EsHcIodVKHi+uw+/6GRgFdE0df5tK/iXAA0C7VbxvUAihMIRQWKdOnfW4G8knZr7l7DvvePd6hw7w4IOrr34Xgl//j39A06ZeRvbAA2HsWD/fY42/1oqIpF/ULnozq2NmG6WeVwP2Bqamjustd2lPfNKeSLlq187Hyvfay2e6n3iiF55Z0bhxfu0ee8DIkXDRRTBrli9/0x7sIpKN0rYO3sx6AncCdYBXzGxCCGE/M9sCeDCE0A2oBww2swL8y8azIYSXU7/iRjNrg0+6mw2ckq5YJb/Vru1r5K+6yh9bbQV77w2vvOL7rv/jH7Dxxp7477sPeveG6tVjRy0isnoWcnFHjlUoLCwMRUVFscOQHFa6fK5bNy9QU6GCd7+3b+9d9JoJLyLZxszGhxD+Um8m+ix6kWzSsaNvzbpkiR+blSV9JXcRySVK8CIr6NjR68QXFPjPjh1jRyQisvZUi15kBe3bw4gR3nLv2NGPRURyjRK8yEq0b6/ELiK5TV30IiIiCaQELyIikkCJWiZnZguA1W5wk0C1ge9jB5FBut9k0/0mW77dL2TmnhuFEP5SyjVpY/DTVrYWMMnMrCif7ln3m2y632TLt/uFuPesLnoREZEEUoIXERFJoKQl+EGxA4gg3+5Z95tsut9ky7f7hYj3nKhJdiIiIuKS1oIXEREREpTgzayrmU0zsxlmdnHseNLJzBqa2Ugzm2Jmn5rZ2bFjygQzKzCzj8zs5b+/OreZ2UZm9ryZTU39f058XT0zOyf193mSmT1lZlVjx1SezOxhM/vOzCYtd24TM3vDzD5L/dw4ZozlaRX3e1Pq7/REMxtqZhvFjLE8rex+l3vtfDMLZlY7kzElIsGn9pO/G9gfaAkcaWYt40aVVsuA80II2wK7Aqcn/H5LnQ1MiR1EhtwOvBZC2AbYgYTft5nVB84CCkMIrYAC4Ii4UZW7R4GuK5y7GBgRQmgOjEgdJ8Wj/PV+3wBahRBaA9OBSzIdVBo9yl/vFzNrCOwDfJHpgBKR4IF2wIwQwswQwhLgaaBH5JjSJoTwdQjhw9TzBfiHf/24UaWXmTUADgAejB1LupnZBsCewEMAIYQlIYSf40aVERWBamZWEagOfBU5nnIVQhgN/LjC6R7A4NTzwcDBGQ0qjVZ2vyGE10MIy1KH7wMNMh5Ymqzi/y/ArcCFQMYnvCUlwdcH5i53PI+EJ7xSZtYYEW9FzAAAAkpJREFU2BH4IG4kaXcb/o+kJHYgGbAVMB94JDUk8aCZ1YgdVDqFEL4EbsZbOV8Dv4QQXo8bVUZsHkL4GvyLO7BZ5Hgy6UTg1dhBpJOZdQe+DCF8HOPPT0qCt5WcS/zyADOrCbwA9Ash/Bo7nnQxswOB70II42PHkiEVgZ2Ae0MIOwILSVbX7V+kxp57AE2ALYAaZnZM3KgkXcysPz7U+ETsWNLFzKoD/YEBsWJISoKfBzRc7rgBCeveW5GZVcKT+xMhhCGx40mzDkB3M5uND790NrP/xA0preYB80IIpb0yz+MJP8n2BmaFEOaHEJYCQ4DdIseUCd+aWT2A1M/vIseTdmZ2HHAgcHRI9jrtpvgX1o9Tn10NgA/NrG6mAkhKgh8HNDezJmZWGZ+c81LkmNLGzAwfn50SQhgYO550CyFcEkJoEEJojP+/fSuEkNjWXQjhG2CumW2dOtUFmBwxpEz4AtjVzKqn/n53IeETC1NeAo5LPT8OeDFiLGlnZl2Bi4DuIYTfY8eTTiGET0IIm4UQGqc+u+YBO6X+fWdEIhJ8atLGGcBw/EPh2RDCp3GjSqsOQG+8JTsh9egWOygpV2cCT5jZRKANcG3keNIq1VvxPPAh8An+2ZSoqmdm9hQwBtjazOaZ2UnA9cA+ZvYZPtP6+pgxlqdV3O9dQC3gjdTn1n1RgyxHq7jfuDElu4dEREQkPyWiBS8iIiJ/pgQvIiKSQErwIiIiCaQELyIikkBK8CIiIgmkBC8iIpJASvAiIiIJpAQvIiKSQP8POyrlgzQEe00AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x2160 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# okay, now combine everything together...\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from numpy import newaxis\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "sys.argv = ['mod', 'PreCar', '191288', '12', '0.01', '1', '1']\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 7:  \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "if tr_data.shape[1] > te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - te_data.shape[1]\n",
    "    for i in range(k): \n",
    "        te_data = np.append(te_data, np.zeros(shape = (te_data.shape[0], 1, te_data.shape[2]), dtype = float), axis = 1) \n",
    "        te_data_mi = np.append(te_data_mi, np.zeros(shape = (te_data_mi.shape[0], 1, te_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "if tr_data.shape[1] > tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially generated follow-ups have been attached. ')\n",
    "    k = tr_data.shape[1] - tea_data.shape[1]\n",
    "    for i in range(k): \n",
    "        tea_data = np.append(tea_data, np.zeros(shape = (tea_data.shape[0], 1, tea_data.shape[2]), dtype = float), axis = 1) \n",
    "        tea_data_mi = np.append(tea_data_mi, np.zeros(shape = (tea_data_mi.shape[0], 1, tea_data_mi.shape[2]), dtype = float), axis = 1) \n",
    "\n",
    "# on the other hand what may happen if... \n",
    "if tr_data.shape[1] < te_data.shape[1] : \n",
    "    # this means te_data have fewer follow-ups than tr_data. For this, patch it up with vectors of zero. \n",
    "    print('Test set [1] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    te_data = te_data[:, range(tr_data.shape[1]), :]\n",
    "    te_data_mi = te_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "if tr_data.shape[1] < tea_data.shape[1] : \n",
    "    \n",
    "    print('Test set [2] has fewer follow-ups than train set. Artificially curtailed excessive follow-ups to avoid critical failures. ')\n",
    "    tea_data = tea_data[:, range(tr_data.shape[1]), :]\n",
    "    tea_data_mi = tea_data_mi[:, range(tr_data_mi.shape[1]), :]\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# By default, at each landmark time and horizon, both c-index and Brier score will be computed\n",
    "# Results will be printed, and saved in a _log.txt document\n",
    "\n",
    "# here, we superseded eval_time and pred_time: \n",
    "\n",
    "\n",
    "\n",
    "if len(sys.argv) < 7: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # then, new eval and pred time would be argument argv[2] and argv[3]\n",
    "    # eval_time = float(sys.argv[2])\n",
    "    pred_time = float(sys.argv[2])\n",
    "    step = float(sys.argv[3])\n",
    "    pat1 = int(sys.argv[4])# {Left or Right}\n",
    "    grp = int(sys.argv[5])\n",
    "else: \n",
    "    # eval_time = float(sys.argv[3])\n",
    "    pred_time = float(sys.argv[3])\n",
    "    step = float(sys.argv[4])\n",
    "    pat1 = int(sys.argv[5])\n",
    "    grp = int(sys.argv[6])\n",
    "# for this patient... (in test set)\n",
    "# determine which set this is\n",
    "if grp == 1:  \n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "elif grp == 2: \n",
    "    te_id = list(tea_id)\n",
    "    te_data = tea_data\n",
    "    te_data_mi = tea_data_mi\n",
    "    idf = test2_name\n",
    "elif grp == 0: \n",
    "    te_id = list(tr_id)\n",
    "    te_data = tr_data\n",
    "    te_data_mi = tr_data_mi\n",
    "    idf = train_name\n",
    "else: \n",
    "    print(\"The user has not correctly specified which dataset the patient comes from. Assuming from test set 1. \")\n",
    "    te_id = list(te_id)\n",
    "    te_data = te_data\n",
    "    te_data_mi = te_data_mi\n",
    "    idf = test1_name\n",
    "\n",
    "# find pat_idx\n",
    "if pat1 in te_id: \n",
    "    pat1_idx = te_id.index(pat1)\n",
    "else: \n",
    "    print(\"The specified patient id was not found in the specified test set. Assuming the use of first patient in test set. \")\n",
    "    pat_idx = 0\n",
    "    \n",
    "\n",
    "\n",
    "pat1_data = te_data[pat1_idx, :, :]\n",
    "pat1_data = pat1_data[newaxis, :, :]\n",
    "pat1_data_mi = te_data_mi[pat1_idx, :, :]\n",
    "pat1_data_mi = pat1_data_mi[newaxis, :, :]\n",
    "\n",
    "\n",
    "# work out the true eval time\n",
    "# the first element is always zero...\n",
    "true_eval_time1 = [0]\n",
    "pat_time_series1 = pat1_data[0, :, 0]\n",
    "pat_time_series1 = [i for i in pat_time_series1 if not i == 0]\n",
    "\n",
    "for i in range(len(pat_time_series1)): \n",
    "    true_eval_time1.append(pat_time_series1[i]) # append time\n",
    "    \n",
    "l1 = len(pat_time_series1)\n",
    "for i in [int(j) for j in list(np.linspace(1, l1, l1))]: \n",
    "    true_eval_time1[i] = true_eval_time1[i] + true_eval_time1[i - 1]\n",
    "\n",
    "# for pred_time, let us still use the external argument\n",
    "# pred_time = float(sys.argv[3])\n",
    "steps = round(pred_time/step)\n",
    "true_pred_time = [step * i for i in range(steps)]\n",
    "true_pred_time.append(pred_time)\n",
    "\n",
    "# finally, risks\n",
    "risk1 = f_get_risk_predictions(sess, model, pat1_data, pat1_data_mi, true_eval_time1, true_pred_time)\n",
    "risk1 = risk1[0]\n",
    "# print(str(true_eval_time1))\n",
    "\n",
    "# plotting\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# first, the longitudinal data\n",
    "# first, extract continuous biomarkers\n",
    "cont_list = model_configs['cont_list']\n",
    "\n",
    "# extract x dim info\n",
    "\n",
    "x_dim_cont = input_dims['x_dim_cont']\n",
    "cont_range = range(1, 1 + x_dim_cont)\n",
    "long_data_to_plot1 = pat1_data[0, :, cont_range]\n",
    "\n",
    "\n",
    "# does this patient become HCC? \n",
    "if te_label[pat1_idx, ] == 1: \n",
    "    print('Patient Status: HCC')\n",
    "else: \n",
    "    print('Patient Status: LC')\n",
    "\n",
    "\n",
    "xMAX = max([max(true_eval_time1)])\n",
    "\n",
    "# here, a for-loop\n",
    "log_transform = model_configs['log_transform']\n",
    "cont_list = model_configs['cont_list']\n",
    "reverse_log = 'OFF'\n",
    "fig, ax = plt.subplots(x_dim_cont - 1, 1, figsize=(8, 2.5 * len(cont_list)), sharex = True, sharey = False)\n",
    "for i in range(x_dim_cont): \n",
    "    if not cont_list[i] == 'Age': \n",
    "        # determine yMAX\n",
    "        # for the ith continuous variable, the values were stored in... \n",
    "        # all_vals = tr_data[:, :, i + 1]\n",
    "        # yMAX = np.max(all_vals)\n",
    "        # if reverse_log == 'ON': \n",
    "            # yMAX = np.power(10, yMAX)\n",
    "\n",
    "        x1_plot = true_eval_time1\n",
    "        # print(str(long_data_to_plot1.shape))\n",
    "        data_to_plot1_sub = list(long_data_to_plot1[i, range(len(x1_plot))])\n",
    "        # here, we say we reverse log-transformation if needed\n",
    "        if cont_list[i] in log_transform and reverse_log == 'ON': \n",
    "            data_to_plot1_sub = [np.power(10, j) for j in data_to_plot1_sub]\n",
    "\n",
    "        x1_plot = [i for i in x1_plot]\n",
    "        data_to_plot1_sub = [i for i in data_to_plot1_sub]\n",
    "        ax[i, ].plot(x1_plot, data_to_plot1_sub, 'm.-.', color='blue')\n",
    "        ax[i, ].set_xlim((0, xMAX + 2))\n",
    "        # ax[i, ].set_ylim((0, yMAX * 1.1))\n",
    "fig.text(0.5, 0, 'Time', ha = 'center')\n",
    "\n",
    "# plt.ylabel('Predicted risk')\n",
    "\n",
    "for t in range(len(true_eval_time1) - 1): # here minus 1 since we don't want the last follow-up\n",
    "    x1_plot = [true_eval_time1[t] + i for i in true_pred_time]\n",
    "    y1_plot = list(risk1[0, t, :])\n",
    "    # then subset x_plot's part smaller than true_eval_time[1]\n",
    "    x_plot_sub_temp = [x1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    y_plot_sub_temp = [y1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    # add them to x_plot_sub and y_plot_sub\n",
    "\n",
    "    x_plot_sub = [x_plot_sub, x_plot_sub_temp]\n",
    "    x_plot_sub = [item for sublist in x_plot_sub for item in sublist]\n",
    "    y_plot_sub = [y_plot_sub, y_plot_sub_temp]\n",
    "    y_plot_sub = [item for sublist in y_plot_sub for item in sublist]\n",
    "# print(x_plot_sub)\n",
    "# print(y_plot_sub)\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.xlim((0, xMAX + 2))\n",
    "plt.ylim((0, max(y_plot_sub) * 1.1))\n",
    "plt.xlabel('Time')\n",
    "for t in range(len(true_eval_time1) - 1): # here minus 1 since we don't want the last follow-up\n",
    "    x1_plot = [true_eval_time1[t] + i for i in true_pred_time]\n",
    "    y1_plot = list(risk1[0, t, :])\n",
    "    # then subset x_plot's part smaller than true_eval_time[1]\n",
    "    x_plot_sub_temp = [x1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    y_plot_sub_temp = [y1_plot[i] for i in range(len(x1_plot)) if x1_plot[i] <= true_eval_time1[t + 1]]\n",
    "    # add them to x_plot_sub and y_plot_sub\n",
    "    plt.vlines(true_eval_time1[t + 1], 0, max(y_plot_sub) * 1.1, 'k', '--')\n",
    "\n",
    "    plt.plot(x_plot_sub_temp, y_plot_sub_temp, 'b')\n",
    "    # add a vertical line\n",
    "plt.show()\n",
    "\n",
    "fig_name = 'tv_risk_' +  idf + '_Patient_' + str(pat1) + '_horizon_' + str(pred_time) + '_.jpg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "652fb391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.30949540e-01  1.13290009e+00  3.50365452e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 6.80000000e+01  6.80000000e+01  6.80000000e+01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.32221950e+00  1.46239815e+00  1.55630262e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.67486123e+00  1.65030762e+00  1.66745305e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.60206010e+00  1.71600343e+00  1.64345278e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.30749625e+00  1.24551291e+00  1.36735611e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 7.55506109e-02  4.53268913e-02  5.30822868e-02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.35317000e-03  6.05278600e-02  9.75802900e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.20167480e-01  2.51637530e-01  7.84483960e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 2.73151100e-01  1.38266820e-01  2.21331780e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.20469801e+00 -1.14146166e+00 -6.16426399e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.20469801e+00 -1.14146166e+00  4.34292310e-06  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "+++++++++++++++++++++++++++++++++++++\n",
      "[[8.53001000e+00 1.35800100e+01 3.18900001e+03 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [6.80000000e+01 6.80000000e+01 6.80000000e+01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.10000100e+01 2.90000100e+01 3.60000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [4.73000100e+01 4.47000100e+01 4.65000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [4.00000100e+01 5.20000100e+01 4.40000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [2.03000100e+01 1.76000100e+01 2.33000100e+01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [1.19001000e+00 1.11001000e+00 1.13001000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [1.35317000e-03 6.05278600e-02 9.75802900e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.20167480e-01 2.51637530e-01 7.84483960e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [2.73151100e-01 1.38266820e-01 2.21331780e-01 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [6.24168700e-02 7.22001900e-02 2.41865320e-01 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]\n",
      " [6.24168700e-02 7.22001900e-02 1.00001000e+00 1.00000000e+00\n",
      "  1.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "log_transform = model_configs['log_transform']\n",
    "cont_list = model_configs['cont_list']\n",
    "\n",
    "print(long_data_to_plot1)\n",
    "for i in range(x_dim_cont): \n",
    "    if cont_list[i] in log_transform: \n",
    "        temp = [np.power(10, j) for j in long_data_to_plot1[i, :]]\n",
    "        # here, temp[j] == 1 means the original data was zero, so remove then\n",
    "        \n",
    "        long_data_to_plot1[i, :] = temp\n",
    "    else: \n",
    "        temp = [j for j in long_data_to_plot1[i, :]]\n",
    "        long_data_to_plot1[i, :] = temp\n",
    "print('+++++++++++++++++++++++++++++++++++++')\n",
    "print(long_data_to_plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebf91f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\utils_network.py:24: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\utils_network.py:29: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py:1259: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\Dynamic-DeepHit\\class_DeepLongitudinal.py:20: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From F:\\Anaconda3\\envs\\DDH\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from PreCar/2022-03-28_02-10-21-191288_my_aMAP_model_with_CNVs/model\n",
      "========================================================\n",
      "========================================================\n",
      "========================================================\n",
      "=\n",
      "Used variables: Gender, CNV_score, Afp, Age, Alt, Alb, Plt, Tb, Inr, NF_CT, Fragment_CT, motif_CT, Comb_CT, score\n",
      "Log-transformed variables:  Afp, Alt, Alb, Plt, Tb, Inr, Comb_CT, score\n",
      "=\n",
      "========================================================\n",
      "========================================================\n",
      "Train set internal validation\n",
      "Data: PreCar\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 1.0  eval_time 4.5  eval_time 8.0  \\\n",
      "pred_time 12: event_1       0.871458       0.870859       0.870128   \n",
      "\n",
      "                       eval_time 11.5  eval_time 15.0  eval_time 18.5  \\\n",
      "pred_time 12: event_1        0.869444        0.869286        0.868944   \n",
      "\n",
      "                       eval_time 22.0  \n",
      "pred_time 12: event_1        0.869448  \n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 1.0  eval_time 4.5  eval_time 8.0  \\\n",
      "pred_time 12: event_1       0.028564       0.034493        0.03753   \n",
      "\n",
      "                       eval_time 11.5  eval_time 15.0  eval_time 18.5  \\\n",
      "pred_time 12: event_1        0.038938        0.039471        0.040319   \n",
      "\n",
      "                       eval_time 22.0  \n",
      "pred_time 12: event_1        0.093411  \n",
      "========================================================\n",
      "========================================================\n",
      "========================================================\n",
      "========================================================\n",
      "=\n",
      "Used variables: Gender, CNV_score, Afp, Age, Alt, Alb, Plt, Tb, Inr, NF_CT, Fragment_CT, motif_CT, Comb_CT, score\n",
      "Log-transformed variables:  Afp, Alt, Alb, Plt, Tb, Inr, Comb_CT, score\n",
      "=\n",
      "========================================================\n",
      "========================================================\n",
      "Train set internal validation\n",
      "Data: PreCar\n",
      "========================================================\n",
      "--------------------------------------------------------\n",
      "- C-INDEX: \n",
      "                       eval_time 1.0  eval_time 4.5  eval_time 8.0  \\\n",
      "pred_time 12: event_1        0.85784       0.853639       0.853299   \n",
      "\n",
      "                       eval_time 11.5  eval_time 15.0  eval_time 18.5  \\\n",
      "pred_time 12: event_1        0.852068        0.851957        0.851329   \n",
      "\n",
      "                       eval_time 22.0  \n",
      "pred_time 12: event_1        0.852262  \n",
      "--------------------------------------------------------\n",
      "- BRIER-SCORE: \n",
      "                       eval_time 1.0  eval_time 4.5  eval_time 8.0  \\\n",
      "pred_time 12: event_1       0.011443       0.016683       0.022306   \n",
      "\n",
      "                       eval_time 11.5  eval_time 15.0  eval_time 18.5  \\\n",
      "pred_time 12: event_1        0.026574        0.028732        0.031994   \n",
      "\n",
      "                       eval_time 22.0  \n",
      "pred_time 12: event_1         0.10004  \n",
      "========================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# time-varying c-index\n",
    "# here, we vary the evaluation time (horizon)\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "sys.argv = ['mod', 'PreCar','191288', '1', '12', '10000']\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 6: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "data_mode = data_mode_name\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs['bin_list'], cont_list_in = model_configs['cont_list'], log_list = model_configs['log_transform'])\n",
    "\n",
    "pred_time = evaluation_info['pred_time'] # prediction time (in months)\n",
    "eval_time = evaluation_info['eval_time'] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "#####\n",
    "\n",
    "# A little treat: print name (in dict) of dataset\n",
    "def get_key(val):\n",
    "    for key, value in dataset_info.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"There is no such Key\"\n",
    "\n",
    "train_name = get_key(train_dir)\n",
    "test1_name = get_key(test_dir[0])\n",
    "test2_name = get_key(test_dir[1])\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "input_dims                  = { 'x_dim'         : tr_x_dim,\n",
    "                                'x_dim_cont'    : tr_x_dim_cont,\n",
    "                                'x_dim_bin'     : tr_x_dim_bin,\n",
    "                                'num_Event'     : num_Event,\n",
    "                                'num_Category'  : num_Category,\n",
    "                                'max_length'    : max_length }\n",
    "\n",
    "network_settings            = { 'h_dim_RNN'         : new_parser['h_dim_RNN'],\n",
    "                                'h_dim_FC'          : new_parser['h_dim_FC'],\n",
    "                                'num_layers_RNN'    : new_parser['num_layers_RNN'],\n",
    "                                'num_layers_ATT'    : new_parser['num_layers_ATT'],\n",
    "                                'num_layers_CS'     : new_parser['num_layers_CS'],\n",
    "                                'RNN_type'          : new_parser['RNN_type'],\n",
    "                                'FC_active_fn'      : tf.nn.relu,\n",
    "                                'RNN_active_fn'     : tf.nn.tanh,\n",
    "                                'initial_W'         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                'reg_W'             : new_parser['reg_W'],\n",
    "                                'reg_W_out'         : float(new_parser['reg_W_out'])\n",
    "                                 }\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "model = Model_Longitudinal_Attention(sess, \"Dynamic-DeepHit\", input_dims, network_settings)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, mod_dir)\n",
    "\n",
    "# create eval_time array\n",
    "eval_time = np.linspace(1, 22, 7)\n",
    "pred_time = [12]\n",
    "\n",
    "risk_all = f_get_risk_predictions(sess, model, tr_data, tr_data_mi, pred_time, eval_time)\n",
    "\n",
    "for p, p_time in enumerate(pred_time):\n",
    "    pred_horizon = int(p_time)\n",
    "    result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "    for t, t_time in enumerate(eval_time):                \n",
    "        eval_horizon = int(t_time) + pred_horizon\n",
    "        for k in range(num_Event):\n",
    "            result1[k, t] = c_index(risk_all[k][:, p, t], tr_time, (tr_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "            result2[k, t] = brier_score(risk_all[k][:, p, t], tr_time, (tr_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "    \n",
    "    if p == 0:\n",
    "        final1, final2 = result1, result2\n",
    "    else:\n",
    "        final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "        \n",
    "        \n",
    "row_header = []\n",
    "for p_time in pred_time:\n",
    "    for t in range(num_Event):\n",
    "        row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "            \n",
    "col_header = []\n",
    "for t_time in eval_time:\n",
    "    col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "# c-index result\n",
    "df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "# brier-score result\n",
    "df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "feat_list = model_configs['bin_list'] + model_configs['cont_list']\n",
    "\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('=')\n",
    "print('Used variables: ' + \", \".join(feat_list))\n",
    "if len(model_configs['log_transform']) >= 1: \n",
    "    logged_var = [i for i in model_configs['log_transform'] if i in model_configs['cont_list']]\n",
    "    print('Log-transformed variables: ', \", \".join(logged_var))\n",
    "print('=')\n",
    "print('========================================================')\n",
    "\n",
    "### PRINT RESULTS\n",
    "print('========================================================')\n",
    "print('Train set internal validation')\n",
    "print('Data: ' + train_name)\n",
    "print('========================================================')\n",
    "print('--------------------------------------------------------')\n",
    "print('- C-INDEX: ')\n",
    "print(df1)\n",
    "print('--------------------------------------------------------')\n",
    "print('- BRIER-SCORE: ')\n",
    "print(df2)\n",
    "print('========================================================')\n",
    "\n",
    "df1_train = df1\n",
    "df2_train = df2\n",
    "\n",
    "risk_all = f_get_risk_predictions(sess, model, te_data, te_data_mi, pred_time, eval_time)\n",
    "\n",
    "for p, p_time in enumerate(pred_time):\n",
    "    pred_horizon = int(p_time)\n",
    "    result1, result2 = np.zeros([num_Event, len(eval_time)]), np.zeros([num_Event, len(eval_time)])\n",
    "\n",
    "    for t, t_time in enumerate(eval_time):                \n",
    "        eval_horizon = int(t_time) + pred_horizon\n",
    "        for k in range(num_Event):\n",
    "            result1[k, t] = c_index(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "            result2[k, t] = brier_score(risk_all[k][:, p, t], te_time, (te_label[:,0] == k+1).astype(int), eval_horizon) #-1 for no event (not comparable)\n",
    "    \n",
    "    if p == 0:\n",
    "        final1, final2 = result1, result2\n",
    "    else:\n",
    "        final1, final2 = np.append(final1, result1, axis=0), np.append(final2, result2, axis=0)\n",
    "        \n",
    "        \n",
    "row_header = []\n",
    "for p_time in pred_time:\n",
    "    for t in range(num_Event):\n",
    "        row_header.append('pred_time {}: event_{}'.format(p_time,k+1))\n",
    "            \n",
    "col_header = []\n",
    "for t_time in eval_time:\n",
    "    col_header.append('eval_time {}'.format(t_time))\n",
    "\n",
    "# c-index result\n",
    "df1 = pd.DataFrame(final1, index = row_header, columns=col_header)\n",
    "\n",
    "# brier-score result\n",
    "df2 = pd.DataFrame(final2, index = row_header, columns=col_header)\n",
    "\n",
    "feat_list = model_configs['bin_list'] + model_configs['cont_list']\n",
    "\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('========================================================')\n",
    "print('=')\n",
    "print('Used variables: ' + \", \".join(feat_list))\n",
    "if len(model_configs['log_transform']) >= 1: \n",
    "    logged_var = [i for i in model_configs['log_transform'] if i in model_configs['cont_list']]\n",
    "    print('Log-transformed variables: ', \", \".join(logged_var))\n",
    "print('=')\n",
    "print('========================================================')\n",
    "\n",
    "### PRINT RESULTS\n",
    "print('========================================================')\n",
    "print('Train set internal validation')\n",
    "print('Data: ' + train_name)\n",
    "print('========================================================')\n",
    "print('--------------------------------------------------------')\n",
    "print('- C-INDEX: ')\n",
    "print(df1)\n",
    "print('--------------------------------------------------------')\n",
    "print('- BRIER-SCORE: ')\n",
    "print(df2)\n",
    "print('========================================================')\n",
    "\n",
    "df1_test = df1\n",
    "df2_test = df2\n",
    "\n",
    "# plot c index change with time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.ylim((0.75, 0.95))\n",
    "plt.plot(eval_time, np.array(df1_train)[0, :], 'r-.p', color = 'blue', label = 'T rain')\n",
    "plt.plot(eval_time, np.array(df1_test)[0, :], 'r-.p', color = 'red', label = 'T est')\n",
    "plt.legend()\n",
    "plt.xlabel('Time horizon (month)')\n",
    "plt.ylabel('c-index')\n",
    "# plt.show()\n",
    "plt.savefig('TV_c_index.png')\n",
    "\n",
    "\n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.plot(eval_time, np.array(df2_train)[0, :], 'r-.p', color = 'blue', label = 'T rain')\n",
    "plt.plot(eval_time, np.array(df2_test)[0, :], 'r-.p', color = 'red', label = 'T est')\n",
    "plt.legend(loc = 2)\n",
    "plt.xlabel('Time horizon (month)')\n",
    "plt.ylabel('Brier score')\n",
    "# plt.show()\n",
    "plt.savefig('TV_Brier.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1caaa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "_EPSILON = 1e-08\n",
    "\n",
    "\n",
    "\n",
    "from cmath import inf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "sys.argv = ['xx', './params/onlyBL.json']\n",
    "#time_tag = timepackage.strftime(\"%d_%b_%Y_%H%M%S%f_GMT\", sys_time)\n",
    "time_tag = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "# read in external parameters passed from the console\n",
    "with open(sys.argv[1]) as p: \n",
    "    params = json.load(p)\n",
    "new_parser = params[\"new_parser\"]\n",
    "dataset_info = params[\"dataset_info\"]\n",
    "evaluation_info = params[\"evaluation_info\"]\n",
    "model_configs = params[\"model_configs\"]\n",
    "eval_configs = params[\"eval_configs\"]\n",
    "\n",
    "params[\"new_parser\"][\"time_tag\"] = time_tag\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def recursion(dic): \n",
    "    for key, value in dic.items(): \n",
    "        if isinstance(value, np.floating): \n",
    "            dic[key] = float(value)\n",
    "        elif isinstance(value, dict): \n",
    "            recursion(value)\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "\n",
    "# ### 1. Import Dataset\n",
    "# #####      - Users must prepare dataset in csv format and modify \"import_data.py\" following our examplar \"PBC2\"\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "data_mode                   = model_configs[\"data_mode\"]\n",
    "seed                        = model_configs[\"seed\"]\n",
    "\n",
    "##### IMPORT DATASET\n",
    "\"\"\"\n",
    "    num_Category            = max event/censoring time * 1.2\n",
    "    num_Event               = number of evetns i.e. len(np.unique(label))-1\n",
    "    max_length              = maximum number of measurements\n",
    "    x_dim                   = data dimension including delta (1 + num_features)\n",
    "    x_dim_cont              = dim of continuous features\n",
    "    x_dim_bin               = dim of binary features\n",
    "    mask1, mask2, mask3     = used for cause-specific network (FCNet structure)\n",
    "\"\"\"\n",
    "dirs = dataset_info\n",
    "test_dir = []\n",
    "for key in list(dirs.keys()): \n",
    "    if key == data_mode: \n",
    "        train_dir = dirs[key]\n",
    "    else: \n",
    "        test_dir.append(dirs[key])\n",
    "    \n",
    "\n",
    "(tr_x_dim, tr_x_dim_cont, tr_x_dim_bin), (tr_data, tr_time, tr_label), (tr_mask1, tr_mask2, tr_mask3), (tr_data_mi), (tr_id), tr_feat_list = impt.import_dataset(path = train_dir, bin_list_in = model_configs[\"bin_list\"], cont_list_in = model_configs[\"cont_list\"], log_list = model_configs[\"log_transform\"])\n",
    "\n",
    "(te_x_dim, te_x_dim_cont, te_x_dim_bin), (te_data, te_time, te_label), (te_mask1, te_mask2, te_mask3), (te_data_mi), (te_id), te_feat_list = impt.import_dataset(path = test_dir[0], bin_list_in = model_configs[\"bin_list\"], cont_list_in = model_configs[\"cont_list\"], log_list = model_configs[\"log_transform\"])\n",
    "\n",
    "(tea_x_dim, tea_x_dim_cont, tea_x_dim_bin), (tea_data, tea_time, tea_label), (tea_mask1, tea_mask2, tea_mask3), (tea_data_mi), (tea_id), tea_feat_list = impt.import_dataset(path = test_dir[1], bin_list_in = model_configs[\"bin_list\"], cont_list_in = model_configs[\"cont_list\"], log_list = model_configs[\"log_transform\"])\n",
    "\n",
    "pred_time = evaluation_info[\"pred_time\"] # prediction time (in months)\n",
    "eval_time = evaluation_info[\"eval_time\"] # months evaluation time (for C-index and Brier-Score)\n",
    "\n",
    "\n",
    "_, num_Event, num_Category  = np.shape(tr_mask1)  # dim of mask3: [subj, Num_Event, Num_Category]\n",
    "\n",
    "max_length                  = np.shape(tr_data)[1]\n",
    "\n",
    "\n",
    "mode_path = \"{}\".format(data_mode)\n",
    "\n",
    "if not os.path.exists(mode_path):\n",
    "    os.makedirs(mode_path)\n",
    "\n",
    "file_path = mode_path + \"/\" + time_tag + \"_\" + new_parser[\"reference\"]\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    os.makedirs(file_path)\n",
    "\n",
    "# ### 2. Set Hyper-Parameters\n",
    "# ##### - Play with your own hyper-parameters!\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "burn_in_mode                = model_configs[\"burnin_mode\"]\n",
    "boost_mode                  = model_configs[\"boost_mode\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# INPUT DIMENSIONS\n",
    "input_dims                  = { \"x_dim\"         : tr_x_dim,\n",
    "                                \"x_dim_cont\"    : tr_x_dim_cont,\n",
    "                                \"x_dim_bin\"     : tr_x_dim_bin,\n",
    "                                \"num_Event\"     : num_Event,\n",
    "                                \"num_Category\"  : num_Category,\n",
    "                                \"max_length\"    : max_length }\n",
    "\n",
    "# NETWORK HYPER-PARMETERS\n",
    "network_settings            = { \"h_dim_RNN\"         : new_parser[\"h_dim_RNN\"],\n",
    "                                \"h_dim_FC\"          : new_parser[\"h_dim_FC\"],\n",
    "                                \"num_layers_RNN\"    : new_parser[\"num_layers_RNN\"],\n",
    "                                \"num_layers_ATT\"    : new_parser[\"num_layers_ATT\"],\n",
    "                                \"num_layers_CS\"     : new_parser[\"num_layers_CS\"],\n",
    "                                \"RNN_type\"          : new_parser[\"RNN_type\"],\n",
    "                                \"FC_active_fn\"      : tf.nn.relu,\n",
    "                                \"RNN_active_fn\"     : tf.nn.tanh,\n",
    "                                \"initial_W\"         : tf.contrib.layers.xavier_initializer(),\n",
    "\n",
    "                                \"reg_W\"             : new_parser[\"reg_W\"],\n",
    "                                \"reg_W_out\"         : float(new_parser[\"reg_W_out\"])\n",
    "                                 }\n",
    "\n",
    "\n",
    "mb_size           = new_parser[\"mb_size\"]\n",
    "iteration         = new_parser[\"iteration\"]\n",
    "iteration_burn_in = new_parser[\"iteration_burn_in\"]\n",
    "\n",
    "keep_prob         = new_parser[\"keep_prob\"]\n",
    "lr_train          = new_parser[\"lr_train\"]\n",
    "\n",
    "alpha             = new_parser[\"alpha\"]\n",
    "beta              = new_parser[\"beta\"]\n",
    "gamma             = new_parser[\"gamma\"]\n",
    "\n",
    "# SAVE HYPERPARAMETERS\n",
    "log_name = file_path + \"/\" + \"_log.json\"\n",
    "log_file = params\n",
    "\n",
    "recursion(log_file)\n",
    "\n",
    "with open(log_name, \"w\") as f:\n",
    "    json.dump(log_file, f)\n",
    "\n",
    "\n",
    "# ### 3. Split Dataset into Train/Valid/Test Sets\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "(tr_data,va_data, tr_data_mi, va_data_mi, tr_time,va_time, tr_label,va_label, \n",
    " tr_mask1,va_mask1, tr_mask2,va_mask2, tr_mask3,va_mask3) = train_test_split(tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3, test_size=model_configs[\"val_ratio\"], random_state = seed) \n",
    "\n",
    "if boost_mode == \"ON\":\n",
    "    tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3 = f_get_boosted_trainset(tr_data, tr_data_mi, tr_time, tr_label, tr_mask1, tr_mask2, tr_mask3)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2dc9e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10.0, 100.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.plot(list(range(10)), list(range(10)))\n",
    "plt.xlim((-10, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a30db80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21a22a9d348>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1758c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# this script produces the training learning curves of different models\n",
    "# two plots will be generated: c-index and total loss trend\n",
    "\n",
    "\n",
    "_EPSILON = 1e-08\n",
    "\n",
    "#### <<< Warning suppression>>> ###\n",
    "# import warnings\n",
    "# warnings.filterwarnings('deprecated')\n",
    "#### This makes the resulting log a lot nicer BUT could produce errors in very, very rare and unexpected circumstances. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time as timepackage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_data as impt\n",
    "\n",
    "from class_DeepLongitudinal import Model_Longitudinal_Attention\n",
    "\n",
    "from utils_eval             import c_index, brier_score\n",
    "from utils_log              import save_logging, load_logging\n",
    "from utils_helper           import f_get_minibatch, f_get_boosted_trainset\n",
    "\n",
    "\n",
    "\n",
    "def _f_get_pred(sess, model, data, data_mi, pred_horizon):\n",
    "    \"\"\"\n",
    "        predictions based on the prediction time.\n",
    "        create new_data and new_mask2 that are available previous or equal to the prediction time (no future measurements are used)\n",
    "    \"\"\"\n",
    "    new_data    = np.zeros(np.shape(data))\n",
    "    new_data_mi = np.zeros(np.shape(data_mi))\n",
    "\n",
    "    meas_time = np.concatenate([np.zeros([np.shape(data)[0], 1]), np.cumsum(data[:, :, 0], axis=1)[:, :-1]], axis=1)\n",
    "\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        last_meas = np.sum(meas_time[i, :] <= pred_horizon)\n",
    "\n",
    "        new_data[i, :last_meas, :]    = data[i, :last_meas, :]\n",
    "        new_data_mi[i, :last_meas, :] = data_mi[i, :last_meas, :]\n",
    "\n",
    "    return model.predict(new_data, new_data_mi)\n",
    "\n",
    "\n",
    "def f_get_risk_predictions(sess, model, data_, data_mi_, pred_time, eval_time):\n",
    "    \n",
    "    pred = _f_get_pred(sess, model, data_[[0]], data_mi_[[0]], 0)\n",
    "    _, num_Event, num_Category = np.shape(pred)\n",
    "       \n",
    "    risk_all = {}\n",
    "    for k in range(num_Event):\n",
    "        risk_all[k] = np.zeros([np.shape(data_)[0], len(pred_time), len(eval_time)])\n",
    "            \n",
    "    for p, p_time in enumerate(pred_time):\n",
    "        ### PREDICTION\n",
    "        pred_horizon = int(p_time)\n",
    "        pred = _f_get_pred(sess, model, data_, data_mi_, pred_horizon)\n",
    "\n",
    "\n",
    "        for t, t_time in enumerate(eval_time):\n",
    "            eval_horizon = int(t_time) + pred_horizon #if eval_horizon >= num_Category, output the maximum...\n",
    "\n",
    "            # calculate F(t | x, Y, t >= t_M) = \\sum_{t_M <= \\tau < t} P(\\tau | x, Y, \\tau > t_M)\n",
    "            risk = np.sum(pred[:,:,pred_horizon:(eval_horizon+1)], axis=2) #risk score until eval_time\n",
    "            risk = risk / (np.sum(np.sum(pred[:,:,pred_horizon:], axis=2), axis=1, keepdims=True) +_EPSILON) #conditioniong on t > t_pred\n",
    "            \n",
    "            for k in range(num_Event):\n",
    "                risk_all[k][:, p, t] = risk[:, k]\n",
    "                \n",
    "    return risk_all\n",
    "\n",
    "## cmd args: \n",
    "# now only one argument is needed\n",
    "# this will be something like \"PreCar\"\n",
    "# and the machine will know to find all relevant materials from the \"PreCar\" directory\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### the following codes read model training results plus needed data from Model_Training.py\n",
    "# and theoretically can be used to re-construct everything needed? \n",
    "\n",
    "'''\n",
    "saver.restore(sess, sys.argv[1])\n",
    "with open(sys.argv[2]) as p: \n",
    "    params = json.load(p)\n",
    "'''\n",
    "\n",
    "# argv[1] is the data_mode: eg if PreCar, the program will read it from the PreCar file\n",
    "# argv[2], if left empty, will choose the most recent log\n",
    "# if argv[2] is specified, will use the string to find relevant log\n",
    "sys.argv = ['xx', 'PreCar']\n",
    "data_mode_name = sys.argv[1]\n",
    "\n",
    "if len(sys.argv) < 3: \n",
    "    # this means no argv[2] is given; we use the most recent log\n",
    "    # to do so, for now lets just use max argument\n",
    "    # firstly, take out all log.json documents\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    # logs is a list of all available logs; find the most recent one...\n",
    "    target_dir = data_mode_name + '/' + max(logs)\n",
    "    print('Using the most recent _log.json by default, since no specification is given. ')\n",
    "else: \n",
    "    # assume that argv[2] has specified a keyword, use the keyword to identify logs\n",
    "    logs = os.listdir(data_mode_name)\n",
    "    matched = [i for i in logs if sys.argv[2] in i]\n",
    "    if len(matched) >= 2: \n",
    "        print('Warning: more than one log is matched with the keyword and the most recent one will be used. ')\n",
    "        matched = max(matched)\n",
    "    target_dir = data_mode_name + '/' + matched[0]\n",
    "\n",
    "\n",
    "# read log\n",
    "with open(target_dir + '/' + '_log.json') as p: \n",
    "    params = json.load(p)\n",
    "mod_dir = target_dir + '/' + 'model'\n",
    "\n",
    "# print(type(params))\n",
    "new_parser = params['new_parser']\n",
    "dataset_info = params['dataset_info']\n",
    "evaluation_info = params['evaluation_info']\n",
    "model_configs = params['model_configs']\n",
    "eval_configs = params['eval_configs']\n",
    "time_tag = params['new_parser']['time_tag']\n",
    "\n",
    "# extract train results\n",
    "\n",
    "train_results = params['train_results']\n",
    "\n",
    "val_c_idx = train_results['val_c_idx']\n",
    "c_track = train_results['c_track']\n",
    "c_track_improve_idx = train_results['c_track_improve_idx']\n",
    "total_loss = train_results['total_loss']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eval_path = target_dir + '/learning_curves'\n",
    "if not os.path.exists(eval_path):\n",
    "    os.makedirs(eval_path)\n",
    "\n",
    "\n",
    "\n",
    "# for loss curve, need how many burnins and how many keeps\n",
    "burnin = new_parser['iteration_burn_in']\n",
    "keep = new_parser['iteration']\n",
    "# the first loss corresponds to the first burnin + 1000\n",
    "l = len(total_loss)\n",
    "x_loss = [(i + 1) * 1 + burnin for i in range(l)]\n",
    "ub_total_loss = float(np.quantile(total_loss, 0.975))\n",
    "lb_total_loss = float(np.quantile(total_loss, 0.025))\n",
    "\n",
    "# for c-index we wanna show the process of plateuing... \n",
    "target = 1\n",
    "c_index = [0.5]\n",
    "for idx in x_loss: \n",
    "    if idx - burnin < c_track_improve_idx[target]: \n",
    "        c_index.append(c_track[target - 1])\n",
    "    else: \n",
    "        c_index.append(c_track[target])\n",
    "        target = target + 1\n",
    "        if target + 1 > len(c_track): \n",
    "            break; \n",
    "\n",
    "\n",
    "# c-index plot\n",
    "plt.figure()\n",
    "plt.plot(c_track_improve_idx, c_track, linestyle = '--', color = 'black')\n",
    "plt.plot(x_loss, c_index)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('c-index')\n",
    "\n",
    "\n",
    "plt.savefig(eval_path + \"/c_index.png\")\n",
    "\n",
    "plt.figure()\n",
    "plt.xlim((burnin, max(x_loss) + 1000))\n",
    "plt.plot(x_loss, total_loss, linewidth = 0.5, color = 'cyan')\n",
    "# maybe... we can add two lines that represent the 95% CI in this region\n",
    "\n",
    "plt.axhline(lb_total_loss, 0, 1, linestyle = '--', color = 'black', linewidth = 0.75)\n",
    "plt.axhline(ub_total_loss, 0, 1, linestyle = '--', color = 'black', linewidth = 0.75)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Total loss')\n",
    "plt.savefig(eval_path + \"/total_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b82ac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
